app,view,panel,classification,text,"app_version",disabled,"_key"
"GMC-001","Get execution metrics on Dashboards","Tracking,Health_Assessments",Dashboards,"","index=`gmc_setup_summary_index` search_name=splunk_internal_web_access_idx_summary_tracker earliest=-7d@d
| `get_shcluster_label(Splunk_Instance)` 
| search shcluster_label=""*"" 
| `get_dashboards_info(shcluster_label,App,Dashboard_Name)` 
| `get_identity_info(User)`
| search emp_name=""*"" AND App=""*""",0,5f62cccb668db2340e11a3a1
"GMC-002","Jobs running for > Nm and investigate if Min_Result_Count & Max_Result_Count are both zero!","Health_Assessments","Scheduled_Jobs","","index=`gmc_setup_summary_index` search_name=splunk_internal_scheduler_jobs_idx_summary_tracker Run_Time>900 earliest=-7d@d
| fields _time Splunk_Instance App Run_Time Result_Count Savedsearch_Name User 
| `get_shcluster_label(Splunk_Instance)` 
| fields - Splunk_Instance 
| stats Max(Run_Time) as Max_Run_Time Min(Run_Time) As Min_Run_Time Min(Result_Count) As Min_Result_Count Max(Result_Count) As Max_Result_Count count As Num_Executions by shcluster_label App User Savedsearch_Name 
| eval Run_Tume_Human=Max_Run_Time 
| `gmc_convert_runtime(Run_Tume_Human)` 
| `get_saved_searches_info(shcluster_label,App,Savedsearch_Name)` 
| eval dispatch_earliest_time=if(dispatch_earliest_time=1,""All-Time"", dispatch_earliest_time ) 
| lookup splunk_rest_data_macros_sh_kv_store_lookup shcluster_label app As App title As Macro_Reference OUTPUT definition 
| table shcluster_label App User Savedsearch_Name Num_Executions Min_Result_Count Max_Result_Count Min_Run_Time Max_Run_Time Run_Tume_Human savedsearch_type description author sharing cron_schedule realtime_schedule schedule_priority schedule_window updated allow_skew correlationsearch_enabled correlationsearch_label dispatch_auto_cancel dispatch_earliest_time dispatch_latest_time savedsearch_search Lookup_Reference Datamodel_Reference Macro_Reference Index_Reference Sourcetype_Reference Source_Reference Eventtype_Reference Rest_Reference",0,5f62cccb668db2340e11a3a2
"GMC-003","Jobs drifting or changing state",Changes,"Scheduled_Jobs","","index=`gmc_setup_summary_index` search_name=splunk_rest_saved_searches_sh_summary_data shcluster_label=""*"" updated>0 earliest=-7d@d
| stats list(is_scheduled) As is_scheduled list(disabled) As disabled dc(is_scheduled) As dc_is_scheduled list(updated) as updated by shcluster_label app author savedsearch_name 
| eval updated_human=updated 
| convert ctime(updated_human) 
| where dc_is_scheduled >1",0,5f62cccb668db2340e11a3a3
"GMC-004","Report on highest number of events by sourcetype enriched with sourcetype metadata","Health_Assessments",Sourcetypes,"","| metadata type=sourcetypes index=* 
| `get_sourcetype_info(sourcetype)` 
| table sourcetype totalCount firstTime lastTime recentTime author app sharing category rename SHOULD_LINEMERGE LINE_BREAKER TIME_PREFIX TIME_FORMAT MAX_TIMESTAMP_LOOKAHEAD TRUNCATE TZ KV_MODE EVENT_BREAKER_ENABLE EVENT_BREAKER DATETIME_CONFIG INDEXED_EXTRACTIONS LEARN_SOURCETYPE TRANSFORMS updated 
| sort 0 - totalCount",0,5f62cccb668db2340e11a3a4
"GMC-005","Daily Total Index Size by Cluster By Index Over Time Trellis View report","Indexes,Health_Assessments","Indexer_Cluster","","index=`gmc_setup_summary_index` search_name=splunk_internal_index_license_usage_idx_summary_tracker Index_Name=""***"" idxcluster_label=""*"" earliest=-7d@d
| fields _time search_name idxcluster_label Lic_Pool Lic_Pool_Size type Index_Name Lic_Sourcetype Lic_Source Lic_Host License_Usage 
| makemv delim="" "" Lic_Sourcetype 
| makemv delim="" "" Lic_Source 
| makemv delim="" "" Lic_Host 
| `gmc_byte2mb(License_Usage)` 
| `gmc_byte2gb(License_Usage)` 
| `gmc_byte2tb(License_Usage)` 
| where License_Usage_MB>=0 
| bin _time span=1d 
| stats 
    sum(License_Usage) AS License_Usage
    by _time idxcluster_label Index_Name 
| timechart
    sum(License_Usage) AS License_Usage
    by Index_Name fixedrange=f span=1d 
| foreach ""*"" 
    [ eval <<FIELD>>=round('<<FIELD>>'/1024/1024/1024, 3)]",0,5f62cccb668db2340e11a3a5
"GMC-006","Jobs Drifited from golden configuration",Changes,"Scheduled_Jobs","","index=`gmc_setup_summary_index` search_name=""splunk_rest_saved_searches_sh_summary_data"" earliest=-30d@d latest=-7d@d 
| fields shcluster_label app savedsearch_name savedsearch_type description author disabled is_scheduled sharing cron_schedule realtime_schedule schedule_priority schedule_window updated allow_skew acl_perms_read acl_perms_write correlationsearch_enabled dispatch_earliest_time dispatch_latest_time savedsearch_search 
| rename 
    updated as old_updated
    disabled AS old_disabled
    is_scheduled as old_is_scheduled 
    cron_schedule as old_cron_schedule 
    dispatch_earliest_time as old_dispatch_earliest_time
    dispatch_latest_time as old_dispatch_latest_time 
    schedule_priority as old_schedule_priority 
    schedule_window as old_schedule_window
    allow_skew as old_allow_skew
    realtime_schedule as old_realtime_schedule 
    savedsearch_type as old_savedsearch_type 
    savedsearch_search as old_savedsearch_search 
| stats latest(*) as * by shcluster_label app savedsearch_name 
| join shcluster_label app savedsearch_name 
    [ search index=`gmc_setup_summary_index` search_name=""splunk_rest_saved_searches_sh_summary_data"" earliest=-7d@d 
    | fields shcluster_label app savedsearch_name savedsearch_type description author disabled is_scheduled sharing cron_schedule realtime_schedule schedule_priority schedule_window updated allow_skew acl_perms_read acl_perms_write correlationsearch_enabled dispatch_earliest_time dispatch_latest_time savedsearch_search 
    | rename 
        updated AS new_updated
        disabled as new_disabled 
        is_scheduled as new_is_scheduled
        cron_schedule as new_cron_schedule 
        dispatch_earliest_time as new_dispatch_earliest_time 
        dispatch_latest_time as new_dispatch_latest_time 
        schedule_priority as new_schedule_priority
        schedule_window as new_schedule_window 
        allow_skew as new_allow_skew
        realtime_schedule as new_realtime_schedule 
        search as new_savedsearch_search
        savedsearch_type as new_savedsearch_type 
        savedsearch_search as new_savedsearch_search 
    | stats latest(*) as * by shcluster_label app savedsearch_name ] 
| where old_disabled!=new_disabled OR old_is_scheduled!=new_is_scheduled OR old_cron_schedule!=new_cron_schedule 
| convert ctime(*_updated) 
| table shcluster_label app savedsearch_name old_updated new_updated old_disabled new_disabled old_is_scheduled new_is_scheduled old_cron_schedule new_cron_schedule",0,5f62cccb668db2340e11a3a6
"GMC-007","Find users with empty LOB information",Identities,Dashboards,"","| tstats SUMMARIESONLY=TRUE ALLOW_OLD_SUMMARIES=FALSE
    count
    FROM DATAMODEL=GMC
    WHERE nodename=Search_Activity.Audit_Search
    BY host Search_Activity.Audit_Search.user1 
| `gmc_drop_dm_object_name(Search_Activity.Audit_Search)` 
| rename user1 As user 
| `get_shcluster_info(host)` 
| `get_identity_info(shcluster_label,user)` 
| `get_identity_info(user)` 
| table shcluster_label user emp_name emp_lob emp_dep 
| where isnull(emp_lob) 
| stats count by user 
| search NOT 
    [| inputlookup splunk_identities_exceptions_sh_csv_lookup 
    | fields identity 
    | rename identity As user] 
| rename user as identity 
    `gmc_comment(""| outputlookup append=true splunk_identities_exceptions_sh_csv_lookup"")`",0,5f62cccb668db2340e11a3a7
"GMC-008","Generate Random Daily License Usage Data for ML Forecasting",License,"Indexer_Cluster","","| gentimes start=1/1/2019 end=07/18/2020 increment=1d 
| fields starthuman endhuman 
| eval _time=strptime(starthuman,""%a %B %d %H:%M:%S.%N %Y"") 
| eval low = 1073741824 , high = 2147483648 , idxcluster_label=""org_idx_cluster1"", Lic_Stack_Size=53687091200 
| eval Lic_Pool=mvappend(""IDX1_Pool"",""IDX2_Pool"",""IDX3_Pool"") 
| eval License_Usage = round(((random() % high)/(high)) * (high - low) + low) 
| stats 
    sum(License_Usage) AS License_Usage 
    latest(Lic_Stack_Size) AS Lic_Stack_Size
    BY _time idxcluster_label Lic_Pool 
| eval search_name=""splunk_internal_license_rollover_summary_idx_summary_tracker"" , type=""RolloverSummary"" 
| table _time search_name idxcluster_label Lic_Pool type Lic_Stack_Size License_Usage 
| collect index=`gmc_setup_summary_index` testmode=true",0,5f62cccb668db2340e11a3a8
"GMC-009","Users Logged into the Platform Today","Access,Health_Assessments",Dashboards,"","index=`gmc_setup_summary_index` search_name= ""splunk_audit_user_login_idx_summary_tracker "" 
| makemv delim= ""| "" Splunk_Instance 
| makemv delim= ""| "" Login_Source 
| makemv delim= ""| "" OS_Name 
| makemv delim= ""| "" OS_Version 
| makemv delim= ""| "" Browser_Name 
| makemv delim= ""| "" Browser_Version 
| search Splunk_Instance=`gmc_setup_gmc_search` 
| fields _time Splunk_Instance User Login_Source Latest_Access OS_Name OS_Version Browser_Name Browser_Version 
| `get_shcluster_label(Splunk_Instance)` 
| `get_identity_info(shcluster_label,User)` 
| stats 
    latest(Latest_Access) as Latest_Access 
    latest(Login_Source) as Login_Source 
    latest(OS_Name) as OS_Name 
    latest(OS_Version) as OS_Version 
    latest(emp_name) as Name 
    latest(Browser_Name) as Browser_Name 
    latest(Browser_Version) as Browser_Version
    latest(emp_city) as emp_city
    latest(emp_region1) as emp_region1
    latest(emp_country) as emp_country
    By shcluster_label User 
| sort 0 - Latest_Access 
| `strftime_format(Latest_Access)` 
| `get_iplocation_info2(Login_Source)` 
| table shcluster_label Latest_Access Name User emp_city emp_region1 emp_country",0,5f62cccb668db2340e11a3a9
"GMC-010","Users not logging into the platform in more than (30) Days","Health_Assessments",Dashboards,"","| from lookup:splunk_rest_identities_kv_store_lookup 
| `get_instance_roles(Splunk_Instance)` 
| `get_splunk_roles_info(shcluster_label,splunk_role_map)` 
| stats 
    Values(email) As email
    Values(emp_dep) As emp_dep
    Values(emp_lob1) As emp_lob1
    Values(emp_name) As emp_name
    Values(emp_status) As emp_status
    Values(emp_title) As emp_title
    Values(emp_type) As emp_type
    Values(endDate) As endDate
    Values(emp_manager) As emp_manager
    By shcluster_label identity 
| lookup splunk_index_audit_user_login_tracker_sh_kv_store_lookup User AS identity OUTPUTNEW Latest_Access Splunk_Instance Login_Source 
| eval time_diff=now()-Latest_Access 
| eval Days_Latest_Access=30*24*60*60 
| where time_diff > Days_Latest_Access AND emp_type!= ""Service "" AND identity!= ""admin "" 
| `gmc_convert_runtime(time_diff)` 
| `strftime_format(Latest_Access)` 
| rename time_diff As  ""Time Since Latest Login "" 
| table emp_name identity Latest_Access shcluster_label  ""Time Since Latest Login "" emp_title emp_dep emp_lob1 emp_type emp_status 
| `rename_identity_fields` 
| `rename_common_fields`",0,5f62cccb668db2340e11a3aa
"GMC-011","Dashboard Accessed in the last (30) Days","Access,Health_Assessments",Dashboards,"","index=`gmc_setup_summary_index` search_name=splunk_internal_web_access_idx_summary_tracker earliest=-30d App!=""global_monitoring_console"" NOT Dashboard_Name IN (home,setup)
| fields _time User Splunk_Instance App OS_Name avg_spent Dashboard_Name Latest_Access 
| `get_shcluster_label(Splunk_Instance)` 
| `get_identity_info(shcluster_label, User)` 
| stats 
    Dc(User) As Num_Users 
    Values(emp_lob) As emp_lob1 
    Values(emp_dep) As emp_dep
    Latest(_time) As _time
    By shcluster_label App Dashboard_Name 
| table  shcluster_label App Dashboard_Name _time emp_name emp_title emp_dep emp_lob1 emp_type emp_status Num_Users 
| `strftime_format(_time)` 
| `rename_identity_fields` 
| `rename_common_fields`",0,5f62cccb668db2340e11a3ab
"GMC-012","New Dashboards Created or Updated in the last (7) Days","Dashboards,Changes,Health_Assessments",Dashboards,"","| from lookup:splunk_rest_data_ui_views_sh_kv_store_lookup 
| eval time_diff=now()-updated 
| eval Days_Latest_Access=7*24*60*60 
| where time_diff < Days_Latest_Access 
| `strftime_format(updated)` 
| `gmc_convert_runtime(time_diff)` 
| `get_identity_info(shcluster_label, author)` 
| `get_identity_info(author)` 
| table updated shcluster_label label title app sharing author emp_name emp_title emp_dep emp_lob1 emp_type emp_status time_diff acl_perms_read acl_perms_write description 
| rename time_diff As ""Time Since Latest Login"" 
| `rename_dashboards_fields` 
| `rename_common_fields` 
| `rename_identity_fields`",0,5f62cccb668db2340e11a3ac
"GMC-013","Splunk Knowledge Objects that has been created or updated in the last (30) Days","Changes,Health_Assessments",Dashboards,"","index=`gmc_setup_summary_index` search_name IN (splunk_rest_admin_eventtypes_sh_summary_data, splunk_rest_admin_lookup_table_files_sh_summary_data, splunk_rest_admin_transforms_lookup_sh_summary_data, splunk_rest_configs_conf_props_sh_summary_data, splunk_rest_data_macros_sh_summary_data, splunk_rest_data_models_sh_summary_data, splunk_rest_data_props_calcfields_sh_summary_data, splunk_rest_data_props_extractions_sh_summary_data, splunk_rest_data_props_fieldaliases_sh_summary_data, splunk_rest_data_props_lookups_sh_summary_data, splunk_rest_data_transforms_extractions_sh_summary_data, splunk_rest_data_ui_views_sh_summary_data, splunk_rest_saved_searches_sh_summary_data) NOT author IN (system, admin, splunk-system-user) updated=* earliest=-30d 
| eval time_diff = now() - updated 
| eval Days_Latest_Access = 30*24*60*60 
| where time_diff < Days_Latest_Access 
| `get_ko_type` 
| eval title = case (
    search_name=""splunk_rest_admin_lookup_table_files_sh_summary_data"", Filename,
    search_name=""splunk_rest_admin_transforms_lookup_sh_summary_data"", Lookup,
    search_name=""splunk_rest_saved_searches_sh_summary_data"", savedsearch_name,
    search_name=""splunk_rest_data_props_calcfields_sh_summary_data"", name,
    match(search_name, ""splunk_rest_data_props_fieldaliases_sh_summary_data|splunk_rest_data_props_extractions_sh_summary_data|splunk_rest_data_props_lookups_sh_summary_data""), attribute,
    true(), title) 
| stats 
    Latest(updated) As updated 
    Latest(time_diff) As time_diff
    earliest(sharing) AS start_share
    latest(sharing) AS end_share
    dc(sharing) AS share_states
    count by shcluster_label Knowledge_Object_Type app author title 
| eval sharing=end_share, sharing_change=if(share_states>1, ""From "". start_share ."" to "". end_share, ""No change""), sharing_change=if(start_share=end_share, ""No change"", sharing_change) 
| `get_identity_info(shcluster_label,author)` 
| `get_identity_info(author)` 
| `strftime_format(updated)` 
| `gmc_convert_runtime(time_diff)` 
| table shcluster_label Knowledge_Object_Type title app sharing sharing_change author emp_name emp_title emp_dep emp_lob1 emp_type emp_status updated time_diff 
| `rename_identity_fields` 
| `rename_common_fields` 
| rename Knowledge_Object_Type As ""Knowledge Object Type"", title As ""Knowledge Object Name"" app As App updated As ""Knowledge Object Update Time"" time_diff As ""Updated in the last"" author As User, sharing_change AS ""Sharing Change""",0,5f62cccb668db2340e11a3ad
"GMC-014","Jobs not written using | tstats",ES,"Scheduled_Jobs","","| from lookup:splunk_rest_saved_searches_sh_kv_store_lookup 
| where disabled=""0"" AND is_scheduled=""1"" AND shcluster_label=""es"" 
| search savedsearch_search!=""*tstats*"" 
| `get_identity_info(author)` 
| table shcluster_label app sharing savedsearch_name savedsearch_type author cron_schedule realtime_schedule schedule_priority schedule_window allow_skew savedsearch_search",0,5f62cccb668db2340e11a3ae
"GMC-015","Jobs that outputs to a summary index","Health_Assessments","Scheduled_Jobs","we need to decrease the dispatch earliest time according to the schedule. For example: if the job runs 3 times per day, set the earliest time to -9h@h and the reason we added an additional hour is so we don't miss any event although this will cause duplicates.  If the job is business critical increase earliest to a maximum of -24h@h","| from lookup:splunk_rest_saved_searches_sh_kv_store_lookup 
| makemv delim="","" actions 
| search shcluster_label=""es"" disabled=""0"" is_scheduled=""1"" AND (savedsearch_search=""* | *collect *"" OR actions=""*summary*"") 
| `strftime_format(updated)` 
| `strftime_format(next_scheduled_time)` 
| `get_identity_info(author)` 
| table shcluster_label author emp_name app sharing savedsearch_name updated savedsearch_type dispatch_earliest_time dispatch_latest_time cron_schedule next_scheduled_time actions summary_index_name savedsearch_search",0,5f62cccb668db2340e11a3af
"GMC-016","Jobs failed with stats including failure reasons and user info","Failures,Health_Assessments","Scheduled_Jobs","","| tstats SUMMARIESONLY=TRUE ALLOW_OLD_SUMMARIES=FALSE
    count As Num_Failures
    Max(Search_Activity.Audit_Search.event_count) AS event_count 
    Max(Search_Activity.Audit_Search.dispatch_time1) AS dispatch_time 
    Max(Search_Activity.Audit_Search.exec_time) AS exec_time 
    Max(Search_Activity.Audit_Search.scan_count1) AS scan_count 
    Max(Search_Activity.Audit_Search.search_et) AS search_et 
    Max(Search_Activity.Audit_Search.search_startup_time) AS search_startup_time 
    Max(Search_Activity.Audit_Search.searched_buckets) AS searched_buckets 
    Max(Search_Activity.Audit_Search.total_run_time1) AS total_run_time 
    Latest(Search_Activity.Audit_Search.search_lt) AS search_lt 
    Latest(Search_Activity.Audit_Search.search_id1) AS search_id 
    FROM DATAMODEL=GMC
    WHERE nodename=Search_Activity.Audit_Search
    index=_audit
    AND Search_Activity.Audit_Search.search_type1 = ""scheduled""
    AND Search_Activity.Audit_Search.info1 = ""failed""
    BY host Search_Activity.Audit_Search.savedsearch_name1 Search_Activity.Audit_Search.user1 
| `gmc_drop_dm_object_name(Search_Activity.Audit_Search)` 
| rename user1 As user, savedsearch_name1 As savedsearch_name 
| `get_shcluster_label(host)` 
| `get_normalized_search_id(search_id)` 
| fields shcluster_label search_id_normalized user savedsearch_name event_count dispatch_time exec_time scan_count search_et search_lt search_startup_time searched_buckets total_run_time Num_Failures 
| `get_search_jobs_info(shcluster_label,search_id_normalized)` 
| `ustime_format(search_et)` 
| `ustime_format(search_lt)` 
| `ustime_format(exec_time)` 
| `ustime_format(dispatch_time)` 
| `get_identity_info(user)` 
| `get_saved_searches_info(shcluster_label,savedsearch_name)` 
| eval total_run_time_human=total_run_time 
| `gmc_convert_runtime(total_run_time_human)` 
| stats sum(Num_Failures) As Num_Failures Max(*) as * by shcluster_label savedsearch_search 
| table shcluster_label user emp_name email savedsearch_name Num_Failures total_run_time total_run_time_human searched_buckets scan_count event_count dispatch_time exec_time search_et search_lt search_startup_time error_messages savedsearch_search",0,5f62cccb668db2340e11a3b0
"GMC-017","Jobs running for > 1h as the maximum run time over the last 7 days","LongRunning,Health_Assessments","Scheduled_Jobs","","index=`gmc_setup_summary_index` search_name=splunk_internal_scheduler_jobs_idx_summary_tracker earliest=-7d@d 
| table _time Splunk_Instance App User Savedsearch_Name Scheduled_Time Dispatch_Time Priority Window_Time Run_Time Result_Count 
| `get_shcluster_label(Splunk_Instance)` 
| stats 
    Min(Run_Time) As MinRun_Time
    Max(Run_Time) As MaxRun_Time
    Avg(Run_Time) As AvgRun_Time
    Max(Result_Count) as MaxResult_Count
    dc(_time) as Number_of_Executions
    Latest(_time) As _time
    By shcluster_label App User Savedsearch_Name 
| `get_identity_info(User)` 
| eval MinRun_Time=round(MinRun_Time,2), MaxRun_Time=round(MaxRun_Time,2), AvgRun_Time=round(AvgRun_Time,2) , MaxRun_Time_Human=MaxRun_Time 
| eval Total_Run_Time = Number_of_Executions * MaxRun_Time , Total_Run_Time_Human=Total_Run_Time 
| `get_saved_searches_info(shcluster_label,App,Savedsearch_Name)` 
| `gmc_convert_runtime(MaxRun_Time_Human)` 
| `gmc_convert_runtime(Total_Run_Time_Human)` 
| `ustime_format(updated)` 
| sort 0 - MaxRun_Time 
| where MaxRun_Time > 1800 
| table _time shcluster_label App User emp_name email Savedsearch_Name updated cron_schedule dispatch_earliest_time dispatch_latest_time realtime_schedule schedule_priority schedule_window allow_skew MaxRun_Time_Human MaxRun_Time AvgRun_Time MinRun_Time MaxResult_Count Number_of_Executions Total_Run_Time Total_Run_Time_Human savedsearch_search",0,5f62cccb668db2340e11a3b1
"GMC-018","Report on lookup file size in MB by cluster","SearchBundle,Health_Assessments",Lookups,"","index=_audit isdir=0 size lookups action=update OR action=created OR action=modified OR action=add NOT action=search path=""*/lookups/*"" NOT path IN (""*/lookups/README*"") 
| where isnotnull(size) 
| `get_cluster_label(host)` 
| stats Latest(size) As size by cluster_label file_name path 
| rex field=path ""/opt/splunk/etc/(apps|slave-apps)/(?<app1>.*?)/"" 
| rex field=path ""/opt/splunk/etc/users/(?<app2>.*?)/"" 
| rex field=path ""/opt/splunk/etc/shcluster/apps/(?<app3>.*?)/"" 
| eval app=coalesce(app1,app2,app3) 
| `gmc_byte2human(size,3)` 
| table cluster_label file_name path app size size_MB",0,5f62cccb668db2340e11a3b2
"GMC-019","Report on Search Head Memory %, CPU % And Load Average","CPU,MEM,Health_Assessments",Infrastructure,"","index=_introspection sourcetype=splunk_resource_usage component=Hostwide 
| rename data.* As *
| `get_shcluster_label(host)`
| where shcluster_label=""xyz""
    | eval cpu_pct=cpu_system_pct+cpu_user_pct, mem_used_gb=round(mem_used/1024,1), mem_perc=round(mem_used/mem*100,2)
| timechart Max(cpu_pct) As cpu_pct Max(normalized_load_avg_1min) As normalized_load_avg_1min Max(mem_perc) As mem_perc  Max(mem_used_gb) As mem_used_gb span=1m",0,5f62cccb668db2340e11a3b3
"GMC-020","Report on Search Head Memory %, CPU % and Memory Used by Cluster by App","PerProcess,Health_Assessments",Infrastructure,"","index=_introspection sourcetype=splunk_resource_usage component=PerProcess host=""sh-i-*"" 
| rename data.* As * 
| rename search_props.* As * 
| `get_shcluster_label(host)` 
| where shcluster_label=""sh123"" AND app=""App123""
| timechart Max(normalized_pct_cpu) As normalized_pct_cpu Max(pct_memory) As pct_memory Max(mem_used) As mem_used span=5m",0,5f62cccb668db2340e11a3b4
"GMC-021","Retrieves Knowledge Objects Changes from the GMC Summary Index (splunk_internal_splunkd_ui_access_ko_changes_idx_summary_tracker)",Changes,"Knowledge_Objects ","Supported arguments: Reports_Alerts, Data_Models, Event_Types, Field_Aliases, Calculated_Fields, Field_Extractions, Field_Transformations, Lookup_Table_Files, Lookup_Definitions, Automatic_Lookups, Dashboards, Macros, Sourcetypes","| from lookup:splunk_rest_data_ui_views_sh_kv_store_lookup
| fields shcluster_label,Splunk_Instance,app,sharing,title
| `get_ko_changes(shcluster_label,Dashboards,title,5)`",0,5f62cccb668db2340e11a3b5
"GMC-022","Job Changes from the GMC Summary Index (splunk_rest_saved_searches_sh_summary_tracker)",Changes,"Scheduled_Jobs","","| from lookup:splunk_rest_saved_searches_sh_kv_store_lookup 
| fields shcluster_label Splunk_Instance app sharing author savedsearch_name 
| `get_savedsearch_changes(shcluster_label,app,savedsearch_name,1)`",0,5f62cccb668db2340e11a3b6
"GMC-023","How to create a tracking table",Tracking,"Scheduled_Jobs","","index = ... sourcetype = ... field = ... earliest=-24h@h latest=+0s 
| stats
    Min(_time) As firstTime
    Max(_time) As lastTime
    By <splitby> 
| inputlookup Append=True tracking-table 
| stats
    Min(firstTime) As firstTime
    Max(lastTime) As lastTime
    By <splitby> 
| where Strptime('lastTime', %s"") >= Relative_Time(Now(), ""-30d"") 
| outputlookup Override_If_Empty=False tracking-table 
| stats count",0,5f62cccb668db2340e11a3b7
"GMC-024","Jobs created using Dashboard Schedule PDF Delivery","Health_Assessments",Dashboards,"","| from lookup:splunk_rest_saved_searches_sh_kv_store_lookup 
| `get_identity_info(shcluster_label,author)` 
| `get_identity_info(author)` 
| `strftime_format(updated)` 
| makemv delim="","" actions 
| search disabled=""0"" is_scheduled=""1"" savedsearch_name=""_ScheduledView__*"" 
| table shcluster_label app sharing savedsearch_name description updated author managedBy emp_name cron_schedule actions email_to",0,5f62cccb668db2340e11a3b8
"GMC-025","Total Number of Buckets in a Cluster using _introspection against all Indexers","Buckets,Cloud,Health_Assessments","Indexer_Cluster","","index=_introspection sourcetype=splunk_disk_objects component IN (Indexes) (host=idx-i-* OR search_group=dmc_group_indexer) earliest=-14d@d latest=-0d@d 
| rename data.* as * 
| bin _time span=1d 
| stats Max(total_bucket_count) As total_bucket_count By _time host name 
| stats sum(total_bucket_count) as total_bucket_count by _time host 
| timechart sum(eval(round(total_bucket_count/1000/1000,2))) as total_bucket_count",0,5f62cccb668db2340e11a3b9
"GMC-026","Total Number of Buckets in a Cluster using REST against all Indexers","Buckets,REST,Health_Assessments","Indexer_Cluster","","| rest /services/cluster/master/peers splunk_server=local timeout=0 
| stats sum(bucket_count) AS bucket_count_all 
| eval bucket_count = round(bucket_count_all / 1000 / 1000,2).""M""",0,5f62cccb668db2340e11a3ba
"GMC-027","Lookup Generating Jobs outputting to lookups and may not end with stats count","Lookups,Health_Assessments","Scheduled_Jobs","Adjust the heads command at the bottom to show the worst ones generating the most results however any job with stats count at the end should be fixed","index=`gmc_setup_summary_index` search_name=splunk_internal_scheduler_jobs_idx_summary_tracker earliest=-24h@h latest=-0h@h 
| `get_shcluster_label(Splunk_Instance)` 
| `get_saved_searches_info(shcluster_label,App,Savedsearch_Name)` 
| where shcluster_label=""<change this>"" 
| search savedsearch_search=""*|*outputlookup *"" 
| stats Max(Run_Time) as Max_Run_Time Avg(Run_Time) as Avg_Run_Time Min(Run_Time) As Min_Run_Time Min(Result_Count) As Min_Result_Count Max(Result_Count) As Max_Result_Count count As Num_Executions Latest(savedsearch_search) As savedsearch_search by shcluster_label App User Savedsearch_Name 
| eval Total_Max_Run_Time = Num_Executions * Max_Run_Time, Max_Run_Time_Human = Max_Run_Time, Total_Max_Run_Time_Human = Total_Max_Run_Time 
| `gmc_convert_runtime(Max_Run_Time_Human)` 
| `gmc_convert_runtime(Total_Max_Run_Time_Human)` 
| table shcluster_label App User Savedsearch_Name Min_Run_Time Avg_Run_Time Max_Run_Time Max_Run_Time_Human Min_Result_Count Max_Result_Count Num_Executions Total_Max_Run_Time Total_Max_Run_Time_Human savedsearch_search 
| eval Savedsearch_Name_encoded = Savedsearch_Name 
| rex field=Savedsearch_Name_encoded mode=sed ""s:%:%25:g s:\+:%2B:g s:\"":%22:g s:\(:%28:g s:\):%29:g s: :%20:g  s:<:%3C:g  s:>:%3E:g  s:#:%23:g  s:{:%7B:g  s:}:%7D:g  s:\|:%7C:g s:\\\:%5C:g  s:\^:%5E:g  s:~:%7E:g      s:\[:%5B:g  s:\]:%5D:g  s:\`:%60:g  s:;:%3B:g  s:/:%2F:g  s:\?:%3F:g  s/:/%3A/g  s:@:%40:g  s:=:%3D:g  s:&:%26:g  s:\$:%24:g  s:\!:%21:g  s:\*:%2A:g"" 
| eval Job_Uri = ""https://<stack>.splunkcloud.com/en-US/manager/"" . App . ""/saved/searches?app="" . App. ""&count=10&offset=0&itemType=&owner="" . User . ""&search="" . Savedsearch_Name_encoded 
| table shcluster_label App User Savedsearch_Name Min_Run_Time Avg_Run_Time Max_Run_Time Max_Run_Time_Human Min_Result_Count Max_Result_Count Num_Executions Total_Max_Run_Time Total_Max_Run_Time_Human Job_Uri savedsearch_search 
| sort 0 - Max_Result_Count 
| head 20",0,5f62cccb668db2340e11a3bb
"GMC-028","Splunk Search Head Cluster (SHC) Scheduler Skips Analysis","Skips,Health_Assessments",Scheduler,"This search excludes data model summarization and Jobs that are configured to use the continuous scheduling method i.e. realtime_schedule=0 or was disabled

What is skipped vs deferred ?
- Behavior depends on scheduling mode (real-time or continuous scheduling)
- Realtime scheduling mode searches will report a status of: completed/skipped
- Continuous scheduling mode searches will report a status of: completed/deferred,Use this example to automatically email results to users","| tstats SUMMARIESONLY=TRUE ALLOW_OLD_SUMMARIES=FALSE 
    Latest(Search_Activity.Internal_Scheduler.info2) AS info
    Values(host) as host
    FROM DATAMODEL=GMC
    WHERE nodename=Search_Activity.Internal_Scheduler
    index=_internal
    AND Search_Activity.Internal_Scheduler.info2 IN (skipped, delegated_remote_completion) 
    AND Search_Activity.Internal_Scheduler.search_type2 != ""*acceleration""
        earliest=-4h@h latest=-0h@h
    BY _time span=1s Search_Activity.Internal_Scheduler.search_id2 
| `gmc_drop_dm_object_name(Search_Activity.Internal_Scheduler)` 
| rename search_id2 As search_id , info AS status 
| lookup splunk_rest_assets_kv_store_lookup Splunk_Instance As host OUTPUTNEW Splunk_Roles 
| where Splunk_Roles=""shc_member"" OR Splunk_Roles=""shc_captain"" 
| timechart span=1h
    count(eval(status==""delegated_remote_completion"")) AS SHC_COMP_EXEC
    count(eval(status==""skipped"")) AS Skipped_EXEC
    count(eval(status==""delegated_remote_completion"" OR status==""skipped"")) AS SHC_TOT_EXEC 
| eval Skip_Ratio = round ( ( Skipped_EXEC / SHC_TOT_EXEC ) * 100, 0) 
| fields - SHC_TOT_EXEC",0,5f62cccb668db2340e11a3bc
"GMC-029","Jobs with non-ascii characters in the Job Search String","non-ascii-chars,Health_Assessments","Scheduled_Jobs","","| from lookup:splunk_rest_saved_searches_sh_kv_store_lookup 
| where shcluster_label=""stack-shc"" 
| eval savedsearch_search_rex=savedsearch_search 
| rex field=savedsearch_search_rex mode=sed ""s/[^[:ascii:]]/NON-ASCII/g"" 
| search savedsearch_search_rex=""*NON-ASCII*"" 
| table shcluster_label app savedsearch_search savedsearch_search_rex",0,5f62cccb668db2340e11a3bd
"GMC-030","Jobs with non-ascii characters in the Job Name","non-ascii-chars,Health_Assessments","Scheduled_Jobs","","| from lookup:splunk_rest_saved_searches_sh_kv_store_lookup 
| where shcluster_label=""stack-shc"" 
| eval savedsearch_name_rex=savedsearch_name 
| rex field=savedsearch_name_rex mode=sed ""s/[^[:ascii:]]/NON-ASCII/g"" 
| search savedsearch_name_rex=""*NON-ASCII*"" 
| table shcluster_label app savedsearch_name savedsearch_name_rex",0,5f62cccb668db2340e11a3be
"GMC-031","Search Head Cluster Jobs that Skipped vs Succeeded analysis using the GMC data model","SHC,Skips,Health_Assessments",Scheduler,"","| tstats SUMMARIESONLY=TRUE ALLOW_OLD_SUMMARIES=FALSE 
    `tstats_gmc_internal`
    FROM DATAMODEL=GMC
    WHERE nodename=Search_Activity.Internal_Scheduler
    index=_internal
    AND Search_Activity.Internal_Scheduler.info2 IN (success, skipped, continued, delegated_remote_completion) 
    AND Search_Activity.Internal_Scheduler.search_type2 != ""*acceleration""
    earliest=-1d@d latest=-0d@d
    BY _time Search_Activity.Internal_Scheduler.search_id2 
| `gmc_drop_dm_object_name(Search_Activity.Internal_Scheduler)` 
| rename search_id2 As search_id , info AS status 
| fields _time host app concurrency_category concurrency_context concurrency_limit dispatch_time priority reason result_count total_run_time savedsearch_id savedsearch_name scheduled_time search_id search_type skipped_count status user window_time alert_actions event_message 
| timechart span=1h 
    count(eval(status==""delegated_remote_completion"")) AS SHC_COMP_EXEC
    count(eval(status==""skipped"")) AS Skipped_EXEC
    count(eval(status==""delegated_remote_completion"" OR status==""skipped"")) AS SHC_TOT_EXEC 
| eval Skip_Ratio = round ( ( Skipped_EXEC / SHC_TOT_EXEC ) * 100, 0) 
| fields - SHC_TOT_EXEC",0,5f62cccb668db2340e11a3bf
"GMC-032","Sendresults Example Code",Sendresults,Commands,"","| search NOT email IN (""email123@doamin.com"")
| rename email As email_to
| `sendresults(""testing123@test.com"",""testing123@test.com"",""Take Action: Long Running Search Impacting Splunk Environment"",""TAKE ACTION: Please review the search(es) listed below. We recommend the search be stopped, then updated with any steps to reduce the length of time to complete. If no longer needed, the search should be deleted.  Please engage the Log Analytics team if you have any questions (add a link to how we are to be engaged)"")`",0,5f62cccb668db2340e11a3c0
"GMC-033","Jobs changed in the last N days using the GMC summary Index",Changes,"Scheduled_Jobs","","index=`gmc_setup_summary_index` search_name=splunk_rest_saved_searches_sh_summary_data shcluster_label=* is_scheduled=1 disabled=0 earliest=-30d@d 
| eval days_last_updated=round((now() - updated) / 86400 , 0) 
| stats count by shcluster_label app author savedsearch_name days_last_updated updated 
| `strftime_format(updated)` 
| where days_last_updated < 15",0,5f62cccb668db2340e11a3c1
"GMC-034","GMC Btool Configuration Analysis Summary Indexing","Btool,Health_Assessments","Configuration_Files","","index=gmc_summary sourcetype=""splunk:config:btool:web"" 
| rex ""etc/((apps|master-apps|slave-apps)/)?[^/]+/(default|local)/(?<file>\w+\.conf)\s+\[(?<stanza>.+?)\]"" 
| multikv noheader=t 
| rex ""(?<SPLUNK_HOME>.*?)/etc/(?<app_folder>apps|master-apps|system|slave-apps)/((?<app>.*)/)?(?<directory>default|local)/(?<file>\w+\.conf)""",0,5f62cccb668db2340e11a3c2
"GMC-035","GMC Job Execution Details including GMC DM in the last 24 hours","GMC,Health_Assessments",GMC,"","| tstats SUMMARIESONLY=TRUE ALLOW_OLD_SUMMARIES=FALSE 
    latest(Search_Activity.Internal_Scheduler.dispatch_time2) AS dispatch_time
    latest(Search_Activity.Internal_Scheduler.scheduled_time) AS scheduled_time
    Max(Search_Activity.Internal_Scheduler.total_run_time2) AS max_run_time
    Latest(Search_Activity.Internal_Scheduler.search_type2) As search_type
    Values(Search_Activity.Internal_Scheduler.info2) AS info
    latest(Search_Activity.Internal_Scheduler.user2) AS user
    latest(Search_Activity.Internal_Scheduler.app2) As app
    values(host) as host
    FROM DATAMODEL=GMC
    WHERE nodename=Search_Activity.Internal_Scheduler
    index=_internal
    AND Search_Activity.Internal_Scheduler.app2 = ""*global_monitoring_console""
    AND Search_Activity.Internal_Scheduler.search_type2 IN (""datamodel_acceleration"", ""scheduled"")
    earliest=-0d@d
    BY Search_Activity.Internal_Scheduler.savedsearch_name2 
| `gmc_drop_dm_object_name(Search_Activity.Internal_Scheduler)` 
| rename savedsearch_name2 As savedsearch_name 
| eval savedsearch_name=if(search_type=""datamodel_acceleration"", ""GMC Data Model"", savedsearch_name) 
| convert ctime(dispatch_time) ctime(scheduled_time) 
| `get_shcluster_label(host)` 
| `get_saved_searches_info(shcluster_label,app,savedsearch_name)` 
| `cron_descriptor(cron_schedule)` 
| table shcluster_label savedsearch_name description dispatch_as dispatch_earliest_time dispatch_latest_time cron_schedule cron_schedule_described allow_skew scheduled_time dispatch_time user info max_run_time realtime_schedule",0,5f62cccb668db2340e11a3c3
"GMC-036","GMC Macros List with details",Macros,GMC,"","| inputlookup splunk_rest_data_macros_sh_kv_store_lookup where app=""*global_monitoring_console"" 
| eval Macro_Class = case ( 
    match(title, ""_reference""), ""Gather Reference Info"", 
    match(title, ""_usage""), ""Gather Usage Info"", 
    match(title, ""^get_""), ""Gather Info"", 
    match(title, ""^rename_""), ""Fields Renames"", 
    match(title, ""^from_|^tstats_""), ""Get Data Model Data"", 
    match(title, ""^normalize_""), ""Normalize Fields"", 
    match(title, ""time""), ""Time Manipulation"", 
    match(title, ""^gmc_setup_""), ""Macros for GMC Setup Screen"", 
    match(title, ""^gmc_""), ""Various GMC Macros"") 
| fillnull value=""Other GMC Macros"" Macro_Class 
| `strftime_format(updated)` 
| table shcluster_label title Macro_Class description args updated 
| sort 0 title 
| `rename_macros_fields`",0,5f62cccb668db2340e11a3c4
"GMC-037","GMC Dashboard List with details",Dashboards,GMC,"","| inputlookup splunk_rest_data_ui_views_sh_kv_store_lookup where app=""*global_monitoring_console"" 
| eval Splunk_Tier = case ( match(label, ""IDX""), ""Indexer"", match(label, ""SH""), ""Search Head"", match(label, ""UF""), ""Forwarder"", true(), ""Other"") 
| table shcluster_label Splunk_Tier label description updated 
| `strftime_format(updated)` 
| `rename_dashboards_fields`",0,5f62cccb668db2340e11a3c5
"GMC-038","GMC App Lookups with details",Lookups,GMC,"","| inputlookup splunk_rest_admin_transforms_lookup_sh_kv_store_lookup where app=""*global_monitoring_console"" 
| `strftime_format(updated)` 
| eval Index=""GMC"" 
| lookup splunk_gmc_kb_csv_lookup Index Field_Name As Lookup OUTPUTNEW Field_Description 
| rename Field_Description As Description 
| table shcluster_label Lookup Type Description Filename Collection updated 
| `rename_lookup_fields`",0,5f62cccb668db2340e11a3c6
"GMC-039","ES Cron Schedule Statistics using cron_schedule_map.csv",Cron,"Scheduled_Jobs","This search uses an ES tabled shipped under SA-Utils/lookups/cron_schedule_map.csv","| from lookup:splunk_rest_saved_searches_sh_kv_store_lookup 
| where disabled=0 AND is_scheduled=1 AND cron_schedule!="""" AND isnotnull(cron_schedule) 
| search (NOT dispatch_earliest_time=rt* NOT dispatch_latest_time=rt* (savedsearch_name=""*Action History"" OR savedsearch_name=""*Gen"" OR savedsearch_name=""*Rule"")) 
| stats 
    values(savedsearch_name) as savedsearches 
    count by cron_schedule 
| lookup cron_schedule_map.csv cron_schedule OUTPUT c0,c5,c10,c15,c20,c25,c30,c35,c40,c45,c50,c55 
| eval c0=(c0 * count), c5=(c5 * count), c10=(c10 * count), c15=(c15 * count), c20=(c20 * count), c25=(c25 * count), c30=(c30 * count), c35=(c35 * count), c40=(c40 * count), c45=(c45 * count), c50=(c50 * count), c55=(c55 * count) 
| addcoltotals labelfield=savedsearches label=Total 
| fields + cron_schedule, savedsearches, count, c0, c5, c10, c15, c20, c25, c30, c35, c40, c45, c50, c55",0,5f62cccb668db2340e11a3c7
"GMC-040","Splunk Cloud Virtual Core (SVC) Usage Analysis","SVC,Cloud,Health_Assessments",Usage,"Calculates SVC Usage by LOB","| tstats SUMMARIESONLY=TRUE ALLOW_OLD_SUMMARIES=True
    count As Num_Searches
    Sum(Search_Activity.Audit_Search.total_run_time1) AS total_run_time
    FROM DATAMODEL=GMC
    WHERE nodename=Search_Activity.Audit_Search
    index=_audit
    earliest=-4d@d latest=-0d@d
    AND Search_Activity.Audit_Search.total_run_time1 > 0
    BY _time span=1d host Search_Activity.Audit_Search.search_id1 Search_Activity.Audit_Search.search_type1 Search_Activity.Audit_Search.info1 Search_Activity.Audit_Search.user1 
| `gmc_drop_dm_object_name(Search_Activity.Audit_Search)` 
| rename info1 AS info, search_id1 As search_id , user1 As user , search_type1 As search_type 
| fields search_id host user search_type info total_run_time Num_Searches 
| stats 
    Sum(total_run_time) As user_total_run_time
    By _time user 
| eventstats sum(user_total_run_time) As grand_total_run_time 
| eval user_total_run_time_perc = user_total_run_time / grand_total_run_time 
| bin _time span=1d 
| join _time 
    [ search index=summary source=splunk-virtual-core-usage earliest=-30d@d latest=now 
    | bin _time span=1d 
    | stats 
        Max(total_util) As Utilization 
        Max(License) As License
        By _time] 
| eval svc_usage = user_total_run_time_perc * Utilization 
| `get_lm_a_account(user)` 
| lookup splunk_rest_identities_kv_store_lookup identity as user OUTPUTNEW emp_lob2 emp_dep 
| lookup splunk_rest_identities_kv_store_lookup identity as lm_a_account OUTPUTNEW emp_lob2 emp_dep 
| lookup splunk_identities_exceptions_sh_csv_lookup identity as user OUTPUTNEW emp_lob2 emp_dep 
| fillnull value=""NO-Market-Data"" emp_lob2 
| fillnull value=""NO-Department-Data"" emp_dep 
| search emp_lob2 IN (""*"") emp_dep IN (""*"") user IN (""*"") 
| stats 
    Sum(svc_usage) As svc_usage
    Dc(emp_dep) As Num_Departments
    Dc(user) As Num_Users
    Max(License) As License
    Max(Utilization) As Utilization
    Max(_time) As Day
    By emp_lob2 
| eval svc_perc = round(svc_usage/License *100, 2) 
| `ustime_format(Day)` 
| sort 0 - svc_usage 
| table emp_lob2 Num_Users Num_Departments svc_usage svc_perc Utilization License Day 
| rename emp_lob2 As ""Market"", emp_dep As Departments , svc_usage As ""SVC Usage"", svc_perc As ""SVC Usage %"", Num_Users As ""# of Users"", Num_Departments As ""# of Departments""",0,5f62cccb668db2340e11a3c8
"GMC-041","Jobs that were disabled > 90 Days ago! (Please archive and Delete)","Disabled,Archive,Health_Assessments","Scheduled_Jobs","","index=`gmc_setup_summary_index` search_name=splunk_rest_saved_searches_sh_summary_data shcluster_label=""*"" disabled=1 
| eval days_last_updated=round((now() - updated) / 86400 , 0) 
| stats Latest(updated) As updated by shcluster_label app author savedsearch_name days_last_updated 
| `strftime_format(updated)` 
| where days_last_updated > 90
| stats count",0,5f62cccb668db2340e11a3c9
"SPL-101","Index bucket info",Buckets,Indexes,,"earliest=-30m index=_introspection component=indexes source=""/opt/splunk/var/log/introspection/disk_objects.log"" 
| dedup data.name host 
| stats sum(data.total_size) as indexSize min(data.bucket_dirs.home.event_min_time) as event_min_time max(data.bucket_dirs.home.event_max_time) as event_max_time sum(data.bucket_dirs.home.hot_bucket_count) as hot_bucket_count sum(data.bucket_dirs.home.warm_bucket_count) as warm_bucket_count sum(data.total_event_count) as total_event_count sum(data.total_raw_size) as total_raw_size sum(data.datamodel_summary_size) as DM_size by data.name 
| eventstats sum(indexSize) as totalDataSize count as indexCount 
| eval event_max_time=strftime(event_max_time,""%m/%d/%y %H:%M:%S"") 
| eval event_min_time=strftime(event_min_time,""%m/%d/%y %H:%M:%S"") 
| eval percOfTotal=('indexSize'/'totalDataSize')*100 
| fillnull value=0 
| sort - indexSize 
| eval ""Compression Rate""=(indexSize/total_raw_size)*100 
| rename data.name as ""Index Name"" event_max_time AS ""Latest Event"" event_min_time AS ""Earliest Event""",0,5f62cccb668db2340e11a3ca
"GMC-074","Report Search Duration of any type","Duration,Health_Assessments",SPL,"Report on search duration of any type","index=_audit TERM(action=search) ( TERM(info=completed) OR ( TERM(info=granted) apiStartTime ""search='search"")) NOT ""search_id='rsa_*"" 
| eval u=case( searchmatch(""user=splunk-system-user OR user=nobody OR search_id=*scheduler_*""), ""Scheduler"", searchmatch((""search_id='1*"")), ""AdHocUser"", 1=1, ""AdHocSaved"") 
| eval search_id=md5(search_id), 
    search_et=if(search_et=""N/A"", 0,
    search_et), search_lt=if(search_lt=""N/A"", exec_time, search_lt), 
    et_diff=case(exec_time>search_et, (exec_time-search_et)/60, 1=1, (search_lt-search_et)/60), searchStrLen=len(search) 
| stats partitions=10 
    sum(searchStrLen) AS searchStrLen
    count
    first(et_diff) AS et_diff
    first(u) as u
    values(search) AS search 
    BY search_id 
| search searchStrLen>0 et_diff=* count>1 
| eval et_range = case(et_diff<=0, ""WTF"", et_diff<2, ""0_1m"", et_diff<6, ""1_5m"", et_diff<11, ""2_10m"", et_diff<16, ""3_15m"", et_diff<=65, ""4_60m"", et_diff<=4*60+10, ""5_4h"", et_diff<=24*60+10, ""6_24h"", et_diff<=7*24*60+10, ""7_7d"", et_diff<=30*24*60+10, ""8_30d"", et_diff<=90*24*60+10, ""9_90d"", 1=1, ""10_>90d"") 
| chart count by et_range, u 
| eval Total=AdHocUser + AdHocSaved + Scheduler 
| eventstats sum(AdHocUser) AS uTotal sum(AdHocSaved) AS aTotal, sum(Scheduler) AS sTotal, sum(Total) AS tTotal 
| eval AdHocUserPerc=round((AdHocUser*100)/uTotal,3), AdHocSavedPerc=round((AdHocSaved*100)/aTotal,3), SchedulerPerc=round((Scheduler*100)/sTotal, 3), TotalPerc=round((Total*100)/tTotal, 3) 
| addcoltotals 
| eval et_range=if(isnull(et_range), ""8_Total"", et_range) 
| fields - aTotal sTotal tTotal, uTotal 
| rex mode=sed field=et_range ""s/\d+_(.*)/\1/g"" 
| accum TotalPerc AS TotalPercCumulative 
| eval TotalPercCumulative=if(TotalPercCumulative<101, round(TotalPercCumulative, 1), """")",0,5f62cccb668db2340e11a3cb
"SPL-103","How Long is this Going to Take?","",SPL,"","#How Long is this Going to Take?#
source=history
| stats stdev(dur) as stdev, avg(dur) as avg
| eval soonest=avg-(3*stdev)
| eval latest=avg+(3*stdev)",0,5f62cccb668db2340e11a3cc
"SPL-105","Calculate the relevancy of the search and sort the results in descending order.",relevance,misc,"Calculate the relevancy of the search and sort the results in descending order.","... disk error | relevancy | sort -relevancy",0,5f62cccb668db2340e11a3cd
"SPL-106","Error Search Broken Down by Sourcetype",error,misc,"Error Search Broken Down by Sourcetype","... error OR failed OR severe OR ( sourcetype=* ( 404 OR 500 OR 503 ) )| timechart count by host",0,5f62cccb668db2340e11a3ce
"SPL-107","Return the average for each hour, of any unique field that ends with the string ""lay"" (for example, delay, xdelay, relay, etc)","avg,os,stats",misc,"Return the average for each hour, of any unique field that ends with the string ""lay"" (for example, delay, xdelay, relay, etc)","... |  stats avg(*lay) BY date_hour",0,5f62cccb668db2340e11a3cf
"SPL-108","Save the running total of ""count"" in a field called ""total_count""",accum,misc,"Save the running total of ""count"" in a field called ""total_count""","... | accum count AS total_count",0,5f62cccb668db2340e11a3d0
"SPL-109","Calculate the sums of the numeric fields of each result, and put the sums in the field ""sum""",addtotals,misc,"Calculate the sums of the numeric fields of each result, and put the sums in the field ""sum""","... | addtotals fieldname=sum",0,5f62cccb668db2340e11a3d1
"SPL-110","Return the average (mean) ""size"" for each distinct ""host""",mean,misc,"Return the average (mean) ""size"" for each distinct ""host""","... | chart avg(size) by host",0,5f62cccb668db2340e11a3d2
"SPL-111","Return the ratio of the average (mean) ""size"" to the maximum ""delay"" for each distinct ""host"" and ""user"" pair ","avg,delay,eval,os",misc,"Return the ratio of the average (mean) ""size"" to the maximum ""delay"" for each distinct ""host"" and ""user"" pair ","... | chart eval(avg(size)/max(delay)) by host user",0,5f62cccb668db2340e11a3d3
"SPL-112","Return the the maximum ""delay"" by ""size"", where ""size"" is broken down into a maximum of 10 equal sized buckets","bins,bucket",misc,"Return the the maximum ""delay"" by ""size"", where ""size"" is broken down into a maximum of 10 equal sized buckets","... | chart max(delay) by size bins=10",0,5f62cccb668db2340e11a3d4
"SPL-113","Remove duplicates of results with the same host value",dedup,misc,"Remove duplicates of results with the same host value","... | dedup host",0,5f62cccb668db2340e11a3d5
"SPL-114","For each event where 'count' exists, compute the difference between count and its previous value and store the result in 'countdiff'.","countdiff,delta",misc,"For each event where 'count' exists, compute the difference between count and its previous value and store the result in 'countdiff'.","... | delta count AS countdiff",0,5f62cccb668db2340e11a3d6
"SPL-115","Extracts out values like ""7/01"", putting them into the ""monthday"" attribute","erex,extract,rex",misc,"Extracts out values like ""7/01"", putting them into the ""monthday"" attribute","... | erex monthday examples=""7/01""",0,5f62cccb668db2340e11a3d7
"SPL-116","Comparing equal time ranges in one report. 1 day is 86,400 seconds",compare,special,"Comparing equal time ranges in one report. 1 day is 86,400 seconds","... | eval _time = _time + 86400",0,5f62cccb668db2340e11a3d8
"SPL-117","Extract field/value pairs that are delimited by ""|;"", and values of fields that are delimited by ""=:""","delim,extract",misc,"Extract field/value pairs that are delimited by ""|;"", and values of fields that are delimited by ""=:""","... | extract pairdelim=""|;"", kvdelim=""=:"", auto=f",0,5f62cccb668db2340e11a3d9
"SPL-118","Remove the ""host"" and ""ip"" fields ",fields,misc,"Remove the ""host"" and ""ip"" fields ","... | fields - host, ip",0,5f62cccb668db2340e11a3da
"SPL-119","Return the first 20 results","head,top",misc,"Return the first 20 results","... | head 20",0,5f62cccb668db2340e11a3db
"SPL-120","Highlight the terms ""login"" and ""logout""",highlight,misc,"Highlight the terms ""login"" and ""logout""","... | highlight login,logout",0,5f62cccb668db2340e11a3dc
"SPL-121","View contents of a look up file. In this case, users.csv",inputlookup,misc,"View contents of a look up file. In this case, users.csv","... | inputlookup users.csv",0,5f62cccb668db2340e11a3dd
"SPL-122","Output LookupWrite to ""users.csv"" lookup file (under $SPLUNK_HOME/etc/system/lookups or $SPLUNK_HOME/etc/apps/*/lookups)",output,misc,"Output LookupWrite to ""users.csv"" lookup file (under $SPLUNK_HOME/etc/system/lookups or $SPLUNK_HOME/etc/apps/*/lookups)","... | outputlookup users.csv",0,5f62cccb668db2340e11a3de
"SPL-123","Output the ""_raw"" field of your current search into ""_xml""",output,misc,"Output the ""_raw"" field of your current search into ""_xml""","... | outputtext",0,5f62cccb668db2340e11a3df
"SPL-124","Change any host value that ends with ""localhost"" to ""localhost""","replace,web",misc,"Change any host value that ends with ""localhost"" to ""localhost""","... | replace *localhost with localhost in host",0,5f62cccb668db2340e11a3e0
"SPL-125","Reverse the order of a result set",reverse,misc,"Reverse the order of a result set","... | reverse",0,5f62cccb668db2340e11a3e1
"SPL-126","REX in the Search Bar - <<The field comes out as aaa in the interesting fields section>>. Your regex (between the """") needs to be correct for your sample to extract a value.",rex,misc,"REX in the Search Bar - <<The field comes out as aaa in the interesting fields section>>. Your regex (between the """") needs to be correct for your sample to extract a value.","... | rex field=_raw ""\,\d\d\d\s(?<aaa>[^\s]+)""",0,5f62cccb668db2340e11a3e2
"SPL-127","Run the ""SEARCH"" saved search","saved,search",misc,"Run the ""SEARCH"" saved search","... | savedsearch SEARCH",0,5f62cccb668db2340e11a3e3
"SPL-128","Anonymize the current search results",scrub,misc,"Anonymize the current search results","... | scrub",0,5f62cccb668db2340e11a3e4
"SPL-129","Send search results to the specified email",email,misc,"Send search results to the specified email","... | sendemail to=""youremail@youraddress.com""",0,5f62cccb668db2340e11a3e5
"SPL-130","Sort results by ""ip"" value in ascending order and then by ""url"" value in descending order",sort,misc,"Sort results by ""ip"" value in ascending order and then by ""url"" value in descending order","... | sort ip, -url",0,5f62cccb668db2340e11a3e6
"SPL-131","Remove duplicates of results with the same ""host"" value and return the total count of the remaining results","dc,distinct",misc,"Remove duplicates of results with the same ""host"" value and return the total count of the remaining results","... | stats dc(host)",0,5f62cccb668db2340e11a3e7
"SPL-132","Add the field: ""comboIP"". Values of ""comboIP"" = ""sourceIP"" + ""/"" + ""destIP""",strcat,misc,"Add the field: ""comboIP"". Values of ""comboIP"" = ""sourceIP"" + ""/"" + ""destIP""","... | strcat sourceIP ""/"" destIP comboIP",0,5f62cccb668db2340e11a3e8
"SPL-133","Create a timechart of average ""cpu_seconds"" by ""host"", and remove data (outlying values) that may distort the timechart's axis","os,outlier",misc,"Create a timechart of average ""cpu_seconds"" by ""host"", and remove data (outlying values) that may distort the timechart's axis","... | timechart avg(cpu_seconds) by host | outlier action=tf",0,5f62cccb668db2340e11a3e9
"SPL-134","Build a time series chart of web events by host and fill all empty fields with NULL","",SPL,"Build a time series chart of web events by host and fill all empty fields with NULL","... | timechart count by host | fillnull value=NULL",0,5f62cccb668db2340e11a3ea
"SPL-135","Calculate the average value of ""CPU"" each minute for each ""host""","os,span,timechart",misc,"Calculate the average value of ""CPU"" each minute for each ""host""","... | timechart span=1m avg(CPU) by host",0,5f62cccb668db2340e11a3eb
"SPL-136","Graph the average ""thruput"" of hosts over time","avg,os",misc,"Graph the average ""thruput"" of hosts over time","... | timechart span=5m avg(thruput) by host",0,5f62cccb668db2340e11a3ec
"SPL-137","For the current search, keep only unique result",uniq,misc,"For the current search, keep only unique result","... | uniq",0,5f62cccb668db2340e11a3ed
"SPL-138","Extract field/value pairs from XML formatted data. ""xmlkv"" automatically extracts values between XML tags","extract,xml",misc,"Extract field/value pairs from XML formatted data. ""xmlkv"" automatically extracts values between XML tags","... | xmlkv",0,5f62cccb668db2340e11a3ee
"SPL-139","Add the field: ""comboIP"". Values of ""comboIP"" = ""sourceIP"" + ""/"" + ""destIP"".","catenation,strcat,web",web,"Add the field: ""comboIP"". Values of ""comboIP"" = ""sourceIP"" + ""/"" + ""destIP"".","index=""*""
|  strcat source* ""/"" dest* combo*",0,5f62cccb668db2340e11a3ef
"SPL-140","Day over Day",compare,special,"Day over Day","index=""*"" error earliest=-1d@d latest=@d
| eval Series=""Yesterday""
| eval _time = _time + 86400
| append [ search tag=failure earliest=@d latest=now
| eval Series = ""Today"" ]
| timechart fixedrange=f span=30m count by Series",0,5f62cccb668db2340e11a3f0
"SPL-141","Viewing data together.",compare,special,"Viewing data together.","index=""*"" error earliest=-30d latest=@d
| timechart span=1d count as dailyCount
| stats avg(dailyCount) as AveragePerDay
| appendcols [search error earliest=@d latest=now
| stats count as TodaysCount]",0,5f62cccb668db2340e11a3f1
"SPL-142","Keep the ""host"" and ""ip"" fields, and display them in the order: ""host"", ""ip""",web,web,"Keep the ""host"" and ""ip"" fields, and display them in the order: ""host"", ""ip""","index=""*"" sourcetype=""*access*""
| fields + host, ip",0,5f62cccb668db2340e11a3f2
"SPL-143","Worldmap with unique visitors last 24 hours. Example uses clientip and an ""access"" sourcetype.","map,ui",web,"Worldmap with unique visitors last 24 hours. Example uses clientip and an ""access"" sourcetype.","index=""*"" sourcetype=""*access*""
| iplocation clientip
| stats dc(clientip) by Country
| geom geo_countries featureIdField=""Country"" earliest=-24h",0,5f62cccb668db2340e11a3f3
"SPL-144","For each event, add a count field that represent the number of event seen so far (including that event). i.e., 1 for the first event, 2 for the second, 3, 4 ... and so on",streamstats,web,"For each event, add a count field that represent the number of event seen so far (including that event). i.e., 1 for the first event, 2 for the second, 3, 4 ... and so on","index=""*"" sourcetype=""*access*""
| streamstats count",0,5f62cccb668db2340e11a3f4
"SPL-145","Create a timechart of the count of from ""web"" sources by ""host""",timechart,web,"Create a timechart of the count of from ""web"" sources by ""host""","index=""*"" sourcetype=""*access*""
| timechart count by host",0,5f62cccb668db2340e11a3f5
"SPL-146","Total Unique Client IPs Over Time","unique,web",web,"Total Unique Client IPs Over Time","index=""*"" sourcetype=""*access*""
| timechart distinct_count(FIELD) span=1h",0,5f62cccb668db2340e11a3f6
"SPL-147","Search the access logs, and return the number of hits from the top 100 values of ""referer_domain""","referrer,web",web,"Search the access logs, and return the number of hits from the top 100 values of ""referer_domain""","index=""*"" sourcetype=""*access*""
| top limit=100 referer_domain
| stats sum(count)",0,5f62cccb668db2340e11a3f7
"SPL-148","Bounce Rate (Enters and exits on the same page) (Pie Chart)","bounce,web",web,"Bounce Rate (Enters and exits on the same page) (Pie Chart)","index=""*"" sourcetype=""*access*""
| transaction clientip maxpause=1h keepevicted=t mvlist=t
| eval user_type=case (eventcount=1,""Bounced"", eventcount<=5, ""2-5 pages"", eventcount<=10, ""6-10 pages"")
| top  limit=5000 user_type",0,5f62cccb668db2340e11a3f8
"SPL-149","Detect ShellShock Attempts in Apache Logs",security,web,"Detect ShellShock Attempts in Apache Logs","index=""*"" sourcetype=""*access*"" http_method=POST request=""*{ :;};*"" OR request=""*/bin/*""",0,5f62cccb668db2340e11a3f9
"SPL-150","Condition as Percentage: Cart Conversion",web,web,"Condition as Percentage: Cart Conversion","index=""*"" sourcetype=""*access*"" method=GET
| stats count AS Page_Views, count(eval(action=""purchase"")) AS Actual_Purchases
| eval ""Conversion %"" =((Actual_Purchases*100)/Page_Views)
| rename Page_Views as Views Actual_Purchases as Purchases",0,5f62cccb668db2340e11a3fa
"SPL-151","Password Non Compliance in Windows: Return results for failed attempts to change password, requires App for Windows: 2008 and newer.","windows,wineventlog",security,"Password Non Compliance in Windows: Return results for failed attempts to change password, requires App for Windows: 2008 and newer.","index=""*"" sourcetype=""WinEventLog:Security"" EventCode=4723 Keywords=""Audit Failure"" #(WinEventLog:Security) This/these sourcetype/s must  exist or edit to make search valid.
| eval Date=strftime(_time, ""%Y/%m/%d"")
| rex ""Target\sAccount:\s+Security\sID:.*\\\(?<account>\S+)""
| stats count by Date, account, host | sort - Date",0,5f62cccb668db2340e11a3fb
"SPL-152","Top Referer",referer,web,"Top Referer","index=""*"" sourcetype=*access*
| top referer
| fields referer percent",0,5f62cccb668db2340e11a3fc
"SPL-153","Top User Agent","Agent,User",web,"Top User Agent","index=""*"" sourcetype=*access*
| top useragent",0,5f62cccb668db2340e11a3fd
"SPL-154","Qualys Top 10 Vulnerabilities by Severity",qualys,security,"Qualys Top 10 Vulnerabilities by Severity","index=""*"" sourcetype=qualys_vm_detection HOSTVULN SEVERITY=3 OR 4 OR 5 TYPE=""CONFIRMED"" earliest=-30d@d
| dedup HOST_ID, QID | search STATUS!=""FIXED""
| join QID [search sourcetype=qualys_knowledgebase PATCHABLE=1 ]
| eval Published=strftime(strptime(PUBLISHED_DATETIME, ""%Y-%m-%d""), ""%m/%d/%Y"")
| join HOST_ID [search sourcetype=qualys_vm_detection HOSTSUMMARY OS=""Windows*"" NOT ""Windows Server*""
| where cidrmatch(""10.128.0.0/9"", IP)  ]
|  stats count(HOST_ID) as #_Hosts by QID, Published, TITLE, SEVERITY
| sort  -SEVERITY, 10 -#_Hosts",0,5f62cccb668db2340e11a3fe
"SPL-155","Average Processing Time (field = processing_time - could be whatever field you want)",duration,misc,"Average Processing Time (field = processing_time - could be whatever field you want)","index=""INDEX"" sourcetype=""SOURCETYPE""
| eval processingTime = tonumber(trim(processing_time, ""ms""))
| eval formattedTime = strftime(_time, ""%Y%m%d"")
| eval processingTimeBase = if (formattedTime = ""20121012"", processingTime, null)
| stats avg(processingTimeBase) as ""Average Processing Time""
| rangemap field=""Average Processing Time"" low=0-240 elevated=241-320 severe=321-400 default=severe",0,5f62cccb668db2340e11a3ff
"SPL-156","List of Sourcetypes Sent by Forwarder","forwarder,uf",Sourcetypes,"List of Sourcetypes Sent by Forwarder","index=""_internal""
| where host!=splunk_server
| stats values(series) as Sourcetypes by host",0,5f62cccb668db2340e11a400
"SPL-157","Traffic Volume by Forwarder","forwarder,nodata,traffic","splunk_internal","Traffic Volume by Forwarder","index=""_internal"" source=""*metrics.lo*"" group=tcpin_connections NOT eventType=*
| eval sourceHost=if(isnull(hostname), sourceHost,hostname)
| search sourceHost=***
| timechart per_second(kb) by sourceHost WHERE max in top5 useother=f",0,5f62cccb668db2340e11a401
"SPL-158","List Ports Forwarders are Using","ports,pwn,uf","splunk_internal","List Ports Forwarders are Using","index=""_internal"" source=""*metrics.lo*"" group=tcpin_connections NOT eventType=*
| dedup sourceHost
| stats count by destPort",0,5f62cccb668db2340e11a402
"SPL-159","Introspection  Memory used by SID (Search ID)","memory,sid","splunk_internal","Introspection  Memory used by SID (Search ID)","index=""_introspection"" ""data.process""=splunkd
| timechart max(data.mem_used) by data.search_props.sid usenull=f useother=f",0,5f62cccb668db2340e11a403
"SPL-160","Qualys Hosts not Scanned in 30 days+",qualys,security,"Qualys Hosts not Scanned in 30 days+","index=""qualys"" HOSTVULN earliest=-30d@d STATUS=""RE-OPENED""
| dedup HOST_ID, QID sortby +_time
| join HOST_ID [search index=qualys HOSTSUMMARY OS=""Windows*"" NOT ""Windows Server*""
| where cidrmatch(""10.128.0.0/9"", IP) ]
| timechart span=1d count(QID) by SEVERITY",0,5f62cccb668db2340e11a404
"SPL-161","Doa splunk search over the index you are putting messages into and bucket it up by seconds to get the event per second rate.","_time,bucket,eps,pwn,stats","splunk_internal","Doa splunk search over the index you are putting messages into and bucket it up by seconds to get the event per second rate.","index=*
 | bucket _time span=1s | stats count by _time",0,5f62cccb668db2340e11a405
"SPL-162","json mv extraction","fields,json,rename,rex",mv,"json mv extraction","index=*
 | rename events{}.code AS a_c, events{}.message AS a_m, events{}.timestamp AS a_ts, events{}.priority as a_p # combine mv fields together using mvzip (to get tuples as comma-delim'd strings)
| eval b_combined = mvzip(mvzip(mvzip(a_c, a_m), a_ts), a_p) # get rid of the a_* fields, simply b/c we don't need them clogging up the ui
| fields - a_* # expand out the combined fields
| mvexpand b_combined # extract nicely named fields from the results (using the comma from mvzip as the delimiter)
| rex field=b_combined ""(?<e_c>[^,]*),(?<e_m>[^,]*),(?<e_ts>[^,]*),(?<e_p>[^,]*)"" # get rid of the combined field b/c we don't need it
| fields - b_* # urldecode the field that you care about
| eval e_m = urldecode(e_m)",0,5f62cccb668db2340e11a406
"SPL-163","Sourcetype Searches","",Sourcetypes,"Sourcetype Searches","index=*
 | stats count by sourcetype",0,5f62cccb668db2340e11a407
"SPL-164","Find the top 5 ip addresses that are attempting to attack us. Requires juniper:idp data","security,threat",security,"Find the top 5 ip addresses that are attempting to attack us. Requires juniper:idp data","index=*
sourcetype = ""juniper:idp"" attack*
| top limit=5 src_ip",0,5f62cccb668db2340e11a408
"SPL-165","Extract SQL Insert Params
Extracts fields from a SQL Insert statement so that the values inserted into the database can be manipulated via splunk searches. In this case, it is used in conjunction with splunk stream & mysql, but should work with any source / database technology.","eval,rex,sql,stream,timechart",database,"Extract SQL Insert Params
Extracts fields from a SQL Insert statement so that the values inserted into the database can be manipulated via splunk searches. In this case, it is used in conjunction with splunk stream & mysql, but should work with any source / database technology.","index=*
sourcetype=stream:mysql* query=""insert into*""
| rex ""insert into \S* \((?<aaa>[^)]+)\) values \((?<bbb>[^)]+)\)""
| rex mode=sed field=bbb ""s/\\\\\""//g""
| makemv aaa delim="",""
| makemv bbb delim="",""
| eval a_kvfield = mvzip(aaa, bbb)
| extract jam_kv_extract
| timechart span=1s per_second(m_value) by m_name",0,5f62cccb668db2340e11a409
"SPL-166","Find Rare Processes (windows). Find rarely seen windows processes. Might indicate custom malware.","rare,security,windows",security,"Find Rare Processes (windows). Find rarely seen windows processes. Might indicate custom malware.","index=*
sourcetype=winregistry
| rare process_image",0,5f62cccb668db2340e11a40a
"SPL-167","Malware Detection",malware,security,"Malware Detection","index=*
| convert mktime(_time) as epoch
| sort 0 uri_host,client_ip,epoch
| delta epoch as epoch_delta
| search epoch_delta>0 epoch_delta<30
| chart count over epoch_delta by uri_host",0,5f62cccb668db2340e11a40b
"SPL-168","Convert field timestamp format to Epoch","convert,epoch",SPL,"Convert field timestamp format to Epoch. This does not include the meta data field _time.
Scenario: You have a non timestamp field that you need to convert to epoch time to perform statistics on within splunk. Heres how you do it:","index=*
| eval Epoch_Time=strptime(Field_Date, ""%Y-%m-%d %H:%M:%S"")",0,5f62cccb668db2340e11a40c
"SPL-169","Convert Seconds to Hours Minutes Seconds HHMMSS.
Take any field in splunk that outputs a value in seconds and change it to report in HH:MM:SS format:","convert,time",misc,"Convert Seconds to Hours Minutes Seconds HHMMSS.
Take any field in splunk that outputs a value in seconds and change it to report in HH:MM:SS format:","index=*
| eval HHMMSS=tostring(Field_In_Seconds, ""duration"")
| table HHMMSS",0,5f62cccb668db2340e11a40d
"SPL-170","Are you SURE your time range is correct? (You wouldn't be the first!) Search over all time to double check. Check for lag.",internal,"splunk_internal","Are you SURE your time range is correct? (You wouldn't be the first!) Search over all time to double check. Check for lag.","index=*
| eval time=_time
| eval itime=_indextime
| eval lag=(itime - time)/60
| stats avg(lag), min(lag), max(lag) by index host sourcetype",0,5f62cccb668db2340e11a40e
"SPL-171","Calculate the Difference in time Between two Fields",compare,misc,"Calculate the Difference in time Between two Fields","index=*
| eval timeDiff = strptime(timeField1, ""%Y-%m-%d %H:%M:%S.%3N"") - strptime(timeField2, ""%Y-%m-%d%H:%M:%S.%3N"")
| table timeDiff",0,5f62cccb668db2340e11a40f
"SPL-172","Detect unauthorized admin activity via foreign country.","geoip,map",security,"Detect unauthorized admin activity via foreign country.","index=*
| geoip clientip as clientip
| table _time clientip client_country
| where client_country NOT (""Germany"" OR ""Austria"" OR ""Switzerland"")",0,5f62cccb668db2340e11a410
"SPL-173","Splunk Server's Time",utils,"splunk_internal","Splunk Server's Time","index=*
| head 1
| eval tnow = now()
| fieldformat tnow=strftime(tnow, ""%c %Z"")
| table tnow",0,5f62cccb668db2340e11a411
"SPL-174",Streamstats,streamstats,misc,Streamstats,"index=*
| head 5
| sort _time
| streamstats sum(bytes) as ASimpleSumOfBytes by clientip",0,5f62cccb668db2340e11a412
"SPL-175","Rename the ""_ip"" field as ""IPAddress""",rename,misc,"Rename the ""_ip"" field as ""IPAddress""","index=*
| rename _ip as IPAddress",0,5f62cccb668db2340e11a413
"SPL-176","Time between events","eval,streamstats",misc,"Time between events","index=*
| sort _time
| streamstats current=f global=f window=1 last(_time) as last_ts
| eval time_since_last = _time - last_ts
| fieldformat time_since_last = tostring(time_since_last, ""duration"")",0,5f62cccb668db2340e11a414
"SPL-177","More than a day between events",utils,misc,"More than a day between events","index=*
| sort _time
| streamstats current=f global=f window=1 last(_time) as last_ts
| eval time_since_last = _time - last_ts
| fieldformat time_since_last = tostring(time_since_last, ""duration"")
| where time_since_last > 60*60*24",0,5f62cccb668db2340e11a415
"SPL-178","Detect machines/applications who are potentially infected and have active running malware on it. Even use it to detect fraud for shopping site orders coming from bad IP's. requirements:
machine data with external IP's + IP Reputation App","security,threat",security,"Detect machines/applications who are potentially infected and have active running malware on it. Even use it to detect fraud for shopping site orders coming from bad IP's. requirements:
machine data with external IP's + IP Reputation App","index=*
| stats count by src_ip dst_ip dst_port protocol
| lookup threatscore clientip as dst_ip
| sort threatscore
| where threatscore>0",0,5f62cccb668db2340e11a416
"SPL-179","Machines with Multiple Services.
You can also filter it down with a additional | where ""Different Ports"" > 5.  Replace the wildcard * and or field names to be applicable to your data set(s.)",security,network,"Machines with Multiple Services.
You can also filter it down with a additional | where ""Different Ports"" > 5.  Replace the wildcard * and or field names to be applicable to your data set(s.)","index=*
| stats count by src_ip dst_ip dst_port protocol
| stats dc(dst_port) as ""Different Ports"" by dst_ip",0,5f62cccb668db2340e11a417
"SPL-180","Detect Account Sharing.
Detect Users who login from multiple IP's / User account Sharing
Requires: Login logs with Username + Source IP field extractions","security,windows",security,"Detect Account Sharing.
Detect Users who login from multiple IP's / User account Sharing
Requires: Login logs with Username + Source IP field extractions","index=*
| stats dc(src_ip) as ip_count by user",0,5f62cccb668db2340e11a418
"SPL-181","Figure out how to show an SLA on a current graph",overlay,misc,"Figure out how to show an SLA on a current graph","index=*
| timechart avg(responsetime) as responsetime
| eval SLA = 5",0,5f62cccb668db2340e11a419
"SPL-182","Simple Example: Transaction.  Replace the wildcard * and or field names to be applicable to your data set(s.)",transaction,misc,"Simple Example: Transaction.  Replace the wildcard * and or field names to be applicable to your data set(s.)","index=*
| transaction clientip
| where duration >1
| table clientip  host duration _time",0,5f62cccb668db2340e11a41a
"SPL-183","Group search results that have the same ""host"" and ""cookie"", occur within 30 seconds of each other, and do not have a pause greater than 5 seconds between each event into a transaction.  Replace the wildcard * and or field names to be applicable to your data set(s.)",transaction,misc,"Group search results that have the same ""host"" and ""cookie"", occur within 30 seconds of each other, and do not have a pause greater than 5 seconds between each event into a transaction.  Replace the wildcard * and or field names to be applicable to your data set(s.)","index=*
| transaction host cookie maxspan=30s maxpause=5s",0,5f62cccb668db2340e11a41b
"SPL-184","Failed Attempt to initiate Remote Desktop session: Must have Splunk app for windows installed. Works with Server 2003 and older.",windows,security,"Failed Attempt to initiate Remote Desktop session: Must have Splunk app for windows installed. Works with Server 2003 and older.","index=*  source=WinEventLog:Security sourcetype=WinEventLog:security Logon_Type=10 (EventCode=529 OR EventCode=530 OR EventCode=531 OR EventCode=532 OR EventCode=533 OR EventCode=534 OR EventCode=535 OR EventCode=536 OR EventCode=537 OR EventCode=539)
| eval Date=strftime(_time, ""%Y/%m/%d"")
| stats count by Date, User_Name, Reason, host",0,5f62cccb668db2340e11a41c
"SPL-185","Convert Bytes to Megabytes",convert,web,"Convert Bytes to Megabytes","index=*  sourcetype=""*access*""
| eval megabytes=((bytes/1024)/1024)
| timechart sum(megabytes)",0,5f62cccb668db2340e11a41d
"SPL-186","Sparkline by Client IP",sparkline,web,"Sparkline by Client IP","index=*  sourcetype=""*access*""
| stats sparkline count by clientip | sort -count",0,5f62cccb668db2340e11a41e
"SPL-187","File deletion attempts in Windows, which returns results based on any suer account who attempts to delete a file. This will return both successful and unsuccessful attempts. Requires Splunk App for Windows: 2008 and newer.","windows,wineventlog",security,"File deletion attempts in Windows, which returns results based on any suer account who attempts to delete a file. This will return both successful and unsuccessful attempts. Requires Splunk App for Windows: 2008 and newer.","index=*  sourcetype=""WinEventLog:Security"" EventCode=4660 (Security_ID!=""NT AUTHORITY*"") (Security_ID!=""S-*"")
| eval Date=strftime(_time, ""%Y/%m/%d"")
| stats count by Date, Account_Name, Process_Name, Keywords, host",0,5f62cccb668db2340e11a41f
"SPL-188","File deletion attempts in Windows, which returns results based on any suer account who attempts to delete a file. This will return both successful and unsuccessful attempts. Requires Splunk App for Windows: 2003 and older.","windows,wineventlog",security,"File deletion attempts in Windows, which returns results based on any suer account who attempts to delete a file. This will return both successful and unsuccessful attempts. Requires Splunk App for Windows: 2003 and older.","index=*  sourcetype=""WinEventLog:Security"" EventCode=564 #(WinEventLog:Security) This/these sourcetype/s must  exist or edit to make search valid.
| eval Date=strftime(_time, ""%Y/%m/%d"")
| stats count by Date, Image_File_Name, Type, host
| sort - Date",0,5f62cccb668db2340e11a420
"SPL-189","Password Non Compliance in Windows: Return results for failed attempts to change password, requires App for Windows: 2003 and older.","windows,wineventlog",security,"Password Non Compliance in Windows: Return results for failed attempts to change password, requires App for Windows: 2003 and older.","index=*  sourcetype=""WinEventLog:Security"" EventCode=627 Type=""Failure Audit""
| eval Date=strftime(_time, ""%Y/%m/%d"") | stats count by Date, Target_Account_Name, host
| sort - Date",0,5f62cccb668db2340e11a421
"SPL-190","Console Lock Duration, 2008 and newer.","windows,wineventlog",security,"Console Lock Duration, 2008 and newer.","index=*  sourcetype=WinEventLog:Security (EventCode=4800 OR EventCode=4801) #(WinEventLog:Security) This/these sourcetype/s must  exist or edit to make search valid.
| eval Date=strftime(_time, ""%Y/%m/%d"")
| transaction host Account_Name startswith=EventCode=4800 endswith=EventCode=4801
| eval duration = duration/60
| eval duration=round(duration,2)
| table host, Account_Name, duration, Date
| rename duration as ""Console Lock Duration in Minutes""
| sort - date",0,5f62cccb668db2340e11a422
"SPL-191","Removal of USB storage device. This will detect if any storage device was removed from a Windows machine.",windows,security,"Removal of USB storage device. This will detect if any storage device was removed from a Windows machine.","index=*  sourcetype=WinRegistry key_path=""HKLM\\system\\controlset*\\enum\\usbstor\\*"" process_image=""c:\\Windows\\System32\\svchost.exe"" registry_type=DeleteKey
| eval Date=strftime(_time, ""%Y/%m/%d %H:%M:%S"")
| rex ""key_path.*usbstor\S(?<DeviceType>.*)&ven\S(?<Vendor>.*)&prod\S(?<Product>\S*)&rev\S""
| stats count by Date, host, Vendor, Product, DeviceType
| fields - count
| sort - Date",0,5f62cccb668db2340e11a423
"SPL-192","Simple Outlier Search
Find outliers - hosts that have an error count which is greater than two standard deviations away from the mean.","outliers,security,stdev",security,"Simple Outlier Search
Find outliers - hosts that have an error count which is greater than two standard deviations away from the mean.","index=* ""Failed Password""
| stats count by user
| eventstats avg(count) as avg_count stdev(count) as stdev_count
| where count>(avg_count + 2*stdev_count)
| sort  -count",0,5f62cccb668db2340e11a424
"SPL-193","Find crazy errors.","find,haystack,needle,pwn",special,"Find crazy errors.","index=* err* OR fail* OR crit* OR fatal* OR except*
| rex field=punct ""(?<smallpunct>.{5})""
| eval smallpunct= ""*"" + smallpunct
| stats first(_raw) as example count by smallpunct
| sort -count
| fields smallpunct,count,example",0,5f62cccb668db2340e11a425
"SPL-194","Errors in the last 24 hours",errors,"splunk_internal","Errors in the last 24 hours","index=* error OR failed OR severe OR ( sourcetype=*access* ( 404 OR 500 OR 503 ) )",0,5f62cccb668db2340e11a426
"SPL-195","Single Value: COMPARE",compare,special,"Single Value: COMPARE","index=* error earliest=-30d latest=@d
| timechart span=1h count
| eval Hour = strftime(_time,""%H"")
| stats avg(count) as AverageCount by Hour",0,5f62cccb668db2340e11a427
"SPL-196","Seven Days Over One Day",compare,special,"Seven Days Over One Day","index=* error earliest=-7d@d latest=@d
| eval Series=""Yesterday""
| eval _time = _time + 86400
| append [ search error earliest=@d latest=now
| eval Series = ""Today"" ]
| timechart fixedrange=f span=30m count by Series",0,5f62cccb668db2340e11a428
"SPL-197","Low Disk Space Alert for Windows Servers","disk,windows",infrastructure,"Low Disk Space Alert for Windows Servers","index=* eventtype=hostmon_windows Type=Disk host=""*"" FileSystem=""*"" DriveType=""*""
| dedup host, Name
| eval FreeSpacePct=round(FreeSpaceKB/TotalSpaceKB*100)
| eval TotalSpaceGB=round(TotalSpaceKB/1024/1024)
| eval FreeSpaceGB=round(FreeSpaceKB/1024/1024)
| search FreeSpacePct<10 TotalSpaceGB=""*""
| dedup host, Name, DriveType, TotalSpaceGB, FreeSpaceGB, FreeSpacePct
| table host, Name, DriveType, TotalSpaceGB, FreeSpaceGB, FreeSpacePct
| sort FreeSpacePct",0,5f62cccb668db2340e11a429
"SPL-198","List Hosts added to Splunk by some _time.","index,splunkd,uf","splunk_internal","List Hosts added to Splunk by some _time.","index=* host=*
| stats dc(host) as host by date_month",0,5f62cccb668db2340e11a42a
"SPL-199","Modification to File Permissions in Windows 2008 and newer. Retuns results for modifications of an individual file level permissions. Requires Splunk app for Windows.","windows,wineventlog",security,"Modification to File Permissions in Windows 2008 and newer. Retuns results for modifications of an individual file level permissions. Requires Splunk app for Windows.","index=* source=""WinEventLog:Security"" sourcetype=""WinEventLog:Security"" EventCode=4670 (Security_ID!=""NT AUTHORITY*"") (Security_ID!=""S-*"")
| eval Date=strftime(_time, ""%Y/%m/%d"")
| stats count by Date, Account_Name, Process_Name, Keywords, host
| sort - Date",0,5f62cccb668db2340e11a42b
"SPL-200","Logon Types within a windows environment with logon count.","windows,wineventlog",security,"Logon Types within a windows environment with logon count.","index=* source=""WinEventLog:security"" #(WinEventLog:security) This/these source/s must exist or edit to make search valid.
| eval LogonType=case(Logon_Type=""2"", ""Local Console Access"", Logon_Type=""3"", ""Accessing Network Folders or Files"", Logon_Type=""4"", ""Scheduled Task, Batch File, or Script"", Logon_Type=""5"", ""Service Account"", Logon_Type=""7"", ""Local Console Unlock"", Logon_Type=""8"", ""Network User Logon"", Logon_Type=""9"", ""Program launched with RunAs using /netonly switch"", Logon_Type=""10"", ""Remote Desktop via Terminal Services"", Logon_Type=""11"", ""Mobile Access or Network Domain Connection Resumed"")
| top limit=15 LogonType | eval percent = round(percent,2) . "" %""",0,5f62cccb668db2340e11a42c
"SPL-201","List of legitimate account names in Windows to identify the deviations from norm:",windows,security,"List of legitimate account names in Windows to identify the deviations from norm:","index=* source=""WinEventLog:security"" (Logon_Type=2 OR Logon_Type=7 OR Logon_Type=10) (EventCode=528 OR EventCode=540 OR EventCode=4624)
| rex ""New\sLogon:\s+.*\s+Account\sName:\s+(?<UserName>\S+)"" | eval Account=coalesce(User_Name,UserName)
| stats count by Account | sort - count",0,5f62cccb668db2340e11a42d
"SPL-202","Failed Windows Remote Desktop Connection Attempt: Must have Windows app installed, works with Server 2008 or newer:",windows,security,"Failed Windows Remote Desktop Connection Attempt: Must have Windows app installed, works with Server 2008 or newer:","index=* source=WinEventLog:Security sourcetype=WinEventLog:security Logon_Type=10 EventCode=4625
| eval Date=strftime(_time, ""%Y/%m/%d"")
| rex ""Failed:\s+.*\s+Account\sName:\s+(?<TargetAccount>\S+)\s""
| stats count by Date, TargetAccount, Failure_Reason, host
| sort - Date",0,5f62cccb668db2340e11a42e
"SPL-203","Clearing of Windows Audit Logs","audit,windows",security,"Clearing of Windows Audit Logs","index=* source=WinEventLog:security (EventCode=1102 OR EventCode=517)
| eval Date=strftime(_time, ""%Y/%m/%d"")
| stats count by Client_User_Name, host, index, Date
| sort - Date
| rename Client_User_Name as ""Account Name""",0,5f62cccb668db2340e11a42f
"SPL-204","Clearing of Windows Audit Logs:",windows,security,"Clearing of Windows Audit Logs:","index=* source=WinEventLog:security (EventCode=1102 OR EventCode=517) | eval Date=strftime(_time, ""%Y/%m/%d"")
| stats count by Client_User_Name, host, index, Date
| sort - Date
| rename Client_User_Name as ""Account Name""",0,5f62cccb668db2340e11a430
"SPL-205","Search common event codes for suspicious behavior. Warning, this can take a while to run.","windows,wineventlog",security,"Search common event codes for suspicious behavior. Warning, this can take a while to run.","index=* source=WinEventLog:security User!=SYSTEM User!=""LOCAL SERVICE"" User!=""NETWORK SERVICE""
| eval Trigger=case(EventCode=516, ""Audit Logs Modified"",EventCode=517, ""Audit Logs Modified"",EventCode=612, ""Audit Logs Modified"",EventCode=623, ""Audit Logs Modified"",EventCode=806, ""Audit Logs Modified"",EventCode=807, ""Audit Logs Modified"",EventCode=1101, ""Audit Logs Modified"",EventCode=1102, ""Audit Logs Modified"",EventCode=4612, ""Audit Logs Modified"",EventCode=4621, ""Audit Logs Modified"",EventCode=4694, ""Audit Logs Modified"",EventCode=4695, ""Audit Logs Modified"",EventCode=4715, ""Audit Logs Modified"",EventCode=4719, ""Audit Logs Modified"",EventCode=4817, ""Audit Logs Modified"",EventCode=4885, ""Audit Logs Modified"",EventCode=4902, ""Audit Logs Modified"",EventCode=4906, ""Audit Logs Modified"",EventCode=4907, ""Audit Logs Modified"",EventCode=4912, ""Audit Logs Modified"", EventCode=642, ""Account Modification"",EventCode=646, ""Account Modification"",EventCode=685, ""Account Modification"",EventCode=4738, ""Account Modification"",EventCode=4742, ""Account Modification"",EventCode=4781, ""Account Modification"", EventCode=1102, ""Audit Logs Cleared/Deleted"",EventCode=517, ""Audit Logs Cleared/Deleted"", EventCode=628, ""Passwords Changed"",EventCode=627, ""Passwords Changed"",EventCode=4723, ""Passwords Changed"",EventCode=4724, ""Passwords Changed"", EventCode=528, ""Successful Logons"",EventCode=540, ""Successful Logons"",EventCode=4624, ""Successful Logons"", EventCode=4625, ""Failed Logons"",EventCode=529, ""Failed Logons"",EventCode=530, ""Failed Logons"",EventCode=531, ""Failed Logons"",EventCode=532, ""Failed Logons"",EventCode=533, ""Failed Logons"",EventCode=534, ""Failed Logons"",EventCode=535, ""Failed Logons"",EventCode=536, ""Failed Logons"",EventCode=537, ""Failed Logons"",EventCode=539, ""Failed Logons"", EventCode=576, ""Escalation of Privileges"",EventCode=4672, ""Escalation of Privileges"",EventCode=577, ""Escalation of Privileges"",EventCode=4673, ""Escalation of Privileges"",EventCode=578, ""Escalation of Privileges"",EventCode=4674, ""Escalation of Privileges"")
| stats count by Trigger
| sort - count",0,5f62cccb668db2340e11a431
"SPL-206","Search Common EventCodes (EventIDs) for Suspicious Behavior","suspicious,windows",security,"Search Common EventCodes (EventIDs) for Suspicious Behavior","index=* source=WinEventLog:security User!=SYSTEM User!=""LOCAL SERVICE"" User!=""NETWORK SERVICE"" | eval Trigger=case(EventCode=516, ""Audit Logs Modified"",EventCode=517, ""Audit Logs Modified"",EventCode=612, ""Audit Logs Modified"",EventCode=623, ""Audit Logs Modified"",EventCode=806, ""Audit Logs Modified"",EventCode=807, ""Audit Logs Modified"",EventCode=1101, ""Audit Logs Modified"",EventCode=1102, ""Audit Logs Modified"",EventCode=4612, ""Audit Logs Modified"",EventCode=4621, ""Audit Logs Modified"",EventCode=4694, ""Audit Logs Modified"",EventCode=4695, ""Audit Logs Modified"",EventCode=4715, ""Audit Logs Modified"",EventCode=4719, ""Audit Logs Modified"",EventCode=4817, ""Audit Logs Modified"",EventCode=4885, ""Audit Logs Modified"",EventCode=4902, ""Audit Logs Modified"",EventCode=4906, ""Audit Logs Modified"",EventCode=4907, ""Audit Logs Modified"",EventCode=4912, ""Audit Logs Modified"", EventCode=642, ""Account Modification"",EventCode=646, ""Account Modification"",EventCode=685, ""Account Modification"",EventCode=4738, ""Account Modification"",EventCode=4742, ""Account Modification"",EventCode=4781, ""Account Modification"", EventCode=1102, ""Audit Logs Cleared/Deleted"",EventCode=517, ""Audit Logs Cleared/Deleted"", EventCode=628, ""Passwords Changed"",EventCode=627, ""Passwords Changed"",EventCode=4723, ""Passwords Changed"",EventCode=4724, ""Passwords Changed"", EventCode=528, ""Successful Logons"",EventCode=540, ""Successful Logons"",EventCode=4624, ""Successful Logons"", EventCode=4625, ""Failed Logons"",EventCode=529, ""Failed Logons"",EventCode=530, ""Failed Logons"",EventCode=531, ""Failed Logons"",EventCode=532, ""Failed Logons"",EventCode=533, ""Failed Logons"",EventCode=534, ""Failed Logons"",EventCode=535, ""Failed Logons"",EventCode=536, ""Failed Logons"",EventCode=537, ""Failed Logons"",EventCode=539, ""Failed Logons"", EventCode=576, ""Escalation of Privileges"",EventCode=4672, ""Escalation of Privileges"",EventCode=577, ""Escalation of Privileges"",EventCode=4673, ""Escalation of Privileges"",EventCode=578, ""Escalation of Privileges"",EventCode=4674, ""Escalation of Privileges"") | stats count by Trigger | sort - count",0,5f62cccb668db2340e11a432
"SPL-207","Count of Attackers on Juniper Devices.
The following is a Splunk search query that indicates potential attacks by source IP.","attack,juniper",security,"Count of Attackers on Juniper Devices.
The following is a Splunk search query that indicates potential attacks by source IP.","index=* sourcetype = ""juniper:idp"" attack*
| stats count by src_ip",0,5f62cccb668db2340e11a433
"SPL-208","Add the field: ""comboIP"". Values of ""comboIP"" = """"sourceIP"" + ""/"" + ""destIP""""","field,join",web,"Add the field: ""comboIP"". Values of ""comboIP"" = """"sourceIP"" + ""/"" + ""destIP""""","index=* sourcetype = *access*
| strcat sourceIP ""/"" destIP comboIP",0,5f62cccb668db2340e11a434
"SPL-209","Top Statuses Sparklines","sparkline,status",web,"Top Statuses Sparklines","index=* sourcetype=""*access*""
|  stats count(status) as count sparkline(count) by status_description
|  rename status_description as ""http status code""
|  sort - count",0,5f62cccb668db2340e11a435
"SPL-210","Apache access_logs status code reporting",status,web,"Apache access_logs status code reporting","index=* sourcetype=""*access*""
| chart count(eval(like(status,""2%""))) AS Success, count(eval(like(status,""4%"") OR like(status,""5%""))) AS Error by status",0,5f62cccb668db2340e11a436
"SPL-211","Reports on most used devices / platforms.","devices,usage",web,"Reports on most used devices / platforms.","index=* sourcetype=""*access*""
| dedup useragent
| eval device=useragent
| replace *Windows* with Windows, *Macintosh* with Apple, *Android* with Android, *iPhone* with iPhone, *iPad* with iPad in device
| top limit=5 useother=t device",0,5f62cccb668db2340e11a437
"SPL-212","Average Queue Size","queue,web",web,"Average Queue Size","index=* sourcetype=""*access*""
| eval bytes = bytes / 170
| timechart avg(bytes)",0,5f62cccb668db2340e11a438
"SPL-213","Show Avg Transaction duration",transaction,misc,"Show Avg Transaction duration","index=* sourcetype=""*access*""
| eval bytes = bytes / 20
| eval sla=105
| timechart avg(sla) as SLA avg(bytes) as ""Avg Tx Duration"" span=1m",0,5f62cccb668db2340e11a439
"SPL-214","User Demographics by Region: Geo Map","geo,map,ui,web",web,"User Demographics by Region: Geo Map","index=* sourcetype=""*access*""
| iplocation clientip
| geostats count by Country",0,5f62cccb668db2340e11a43a
"SPL-215","User Demographics by Region: Chloropleth","chloropleth,geo,ui",web,"User Demographics by Region: Chloropleth","index=* sourcetype=""*access*""
| iplocation clientip
| stats count by Country
| geom geo_countries featureIdField=""Country""",0,5f62cccb668db2340e11a43b
"SPL-216","Top Statuses Sparklines","rename,sparkline,status,web",web,"Top Statuses Sparklines","index=* sourcetype=""*access*""
| stats count(status) as count sparkline(count) by status_description
|  rename status_description as ""http status code""
| sort - count",0,5f62cccb668db2340e11a43c
"SPL-217","Find web site status over time.",status,web,"Find web site status over time.","index=* sourcetype=""*access*""
| timechart count by status_type limit=10 usenull=f",0,5f62cccb668db2340e11a43d
"SPL-218","Prediction of traffic based on the Kalman Algorithm.",predict,web,"Prediction of traffic based on the Kalman Algorithm.","index=* sourcetype=""*access*""
| timechart count(bytes) as traffic
| streamstats sum(traffic) as total_traffic
| predict total_traffic as expected_traffic algorithm=LLT future_timespan=14",0,5f62cccb668db2340e11a43e
"SPL-219","Prediction of traffic based on the Kalman Algorithm w/explicit fields assigned to display.",predict,web,"Prediction of traffic based on the Kalman Algorithm w/explicit fields assigned to display.","index=* sourcetype=""*access*""
| timechart count(bytes) as traffic
| streamstats sum(traffic) as total_traffic
| predict total_traffic as expected_traffic algorithm=LLT future_timespan=14
| fields total_traffic, expected_traffic",0,5f62cccb668db2340e11a43f
"SPL-220","Users Percentage of Total Processing Time (Know User Name - $series$)",transaction,web,"Users Percentage of Total Processing Time (Know User Name - $series$)","index=* sourcetype=""*access*""
| transaction username clientip maxspan=20m maxpause=5m
| eval durationCurrentUser = if (username = ""$series$"", duration, null)
| eval eventCountCurrentUser = if (username = ""$series$"", eventcount, null)
| eval durationOtherUsers = if (username != ""$series$"", duration, null)
| eval eventCountOtherUsers = if (username != ""$series$"", eventcount, null)
| stats avg(eventCountCurrentUser), avg(eventCountOtherUsers), avg(durationCurrentUser), avg(durationOtherUsers)",0,5f62cccb668db2340e11a440
"SPL-221","List IPs that had Successful and Failed SSH Attempts","linux,login",security,"List IPs that had Successful and Failed SSH Attempts","index=* sourcetype=""*secure"" process=sshd ""password for""
| rex field=_raw ""(?Accepted|Failed) password for (?\w+) from (?[0-9A-Fa-f:\.]+)""
| eval success=if(result==""Failed"",0,1)
| stats count as total,sum(success) as success by ipaddr
| where total!=success AND success!=0",0,5f62cccb668db2340e11a441
"SPL-222","XML with SPATH Searches for events which contain a field called message",,Other,"XML with SPATH
Searches for events which contain a field called ""message"" that composite field is expanded via a call to spath. Then a value from the resulting expansion is used to find events that contain a date meeting certain criteria.","index=* sourcetype=""SOURCETYPE""
| spath input=FIELD
| where strptime('FIELD.updated_at', ""%Y-%m-%d %H:%M:%S %z"") > strptime(""2013-08-07 00:00:00"", ""%Y-%m-%d %H:%M:%S"")",0,5f62cccb668db2340e11a442
"SPL-223","Escalation of Privs in Windows by User:","windows,wineventlog",security,"Escalation of Privs in Windows by User:","index=* sourcetype=""WinEventLog:Security"" (EventCode=576 OR EventCode=4672 OR EventCode=577 OR EventCode=4673 OR EventCode=578 OR EventCode=4674)
| stats count by user #(user) This/these field/s must exist or edit to make search valid.",0,5f62cccb668db2340e11a443
"SPL-224","Password Changes in Windows environment by user account.","windows,wineventlog",security,"Password Changes in Windows environment by user account.","index=* sourcetype=""WinEventLog:Security"" (EventCode=628 OR EventCode=627 OR EventCode=4723 OR EventCode=4724)
| chart count by user #(user) This/these field/s must exist or edit to make search valid.",0,5f62cccb668db2340e11a444
"SPL-225","Windows failed logons with Average Overlay to identify deviations and anomalies.",windows,security,"Windows failed logons with Average Overlay to identify deviations and anomalies.","index=* sourcetype=""WinEventLog:Security"" (Logon_Type=2 OR Logon_Type=7 OR Logon_Type=10) (EventCode=4625 OR EventCode=529 OR EventCode=530 OR EventCode=531 OR EventCode=532 OR EventCode=533 OR EventCode=534 OR EventCode=535 OR EventCode=536 OR EventCode=537 OR EventCode=539)
| timechart count(EventCode) as count
| eventstats avg(count) as Average
| eval average=round(average,0)
| rename count as ""Failed Logons""",0,5f62cccb668db2340e11a445
"SPL-226","Windows Failed Logons with Average Overlay
This Splunk search will show any failed login attempt and graphically overlay an average value.","overlay,windows",security,"Windows Failed Logons with Average Overlay
This Splunk search will show any failed login attempt and graphically overlay an average value.","index=* sourcetype=""WinEventLog:Security"" (Logon_Type=2 OR Logon_Type=7 OR Logon_Type=10) (EventCode=4625 OR EventCode=529 OR EventCode=530 OR EventCode=531 OR EventCode=532 OR EventCode=533 OR EventCode=534 OR EventCode=535 OR EventCode=536 OR EventCode=537 OR EventCode=539)
| timechart count(EventCode) as count
| eventstats avg(count) as Average | eval average=round(average,0)
| rename count as ""Failed Logons""",0,5f62cccb668db2340e11a446
"SPL-227","Successful Windows Logins with Average Overlay to see deviations and anomalies.",windows,security,"Successful Windows Logins with Average Overlay to see deviations and anomalies.","index=* sourcetype=""WinEventLog:Security"" (Logon_Type=2 OR Logon_Type=7 OR Logon_Type=10) (EventCode=528 OR EventCode=540 OR EventCode=4624)
| timechart count(EventCode) as count
| eventstats avg(count) as Average
| eval average=round(average,0)
| rename count as ""Successful Logons""",0,5f62cccb668db2340e11a447
"SPL-228","Windows 2008 and newer:","access,file,windows",security,"Windows 2008 and newer:","index=* sourcetype=""WinEventLog:Security"" EventCode=4656 Object_Type=File (Security_ID!=""NT AUTHORITY*"") (Security_ID!=""S-*"")
| eval Date=strftime(_time, ""%Y/%m/%d"")
| stats count by Date, Account_Name, Process_Name, Keywords, host",0,5f62cccb668db2340e11a448
"SPL-229","Security Access Granted to an account. 2007/2008 or better.","windows,wineventlog",security,"Security Access Granted to an account. 2007/2008 or better.","index=* sourcetype=""WinEventLog:Security"" EventCode=4717 #(WinEventLog:Security) This/these sourcetype/s must  exist or edit to make search valid.
| eval Date=strftime(_time, ""%Y/%m/%d"")
| stats count by src_user, user, Access_Right, Date, Keywords #(src_user, user, Access_Right, Date, Keywords) This/these field/s must exist or edit to make search valid.
| rename src_user as ""Source Account""
| rename user as ""Target Account""
| rename Access_Right as ""New Rights Granted""",0,5f62cccb668db2340e11a449
"SPL-230","Windows File Access Attempts",access,Other,"Windows File Access Attempts
The following splunk queries will display any file access attempts (successful or failed) by user account. Ensure the Splunk App for Windows is installed grab it here: https://apps.splunk.com/app/742/ Windows 2003 and older:","index=* sourcetype=""WinEventLog:Security"" EventCode=560 Object_Type=File
| eval Date=strftime(_time, ""%Y/%m/%d"")
| eval UserName=coalesce(Primary_User_Name, Client_User_Name)
| search UserName!=""*$"" AND UserName!=""NETWORK SERVICE""
| stats count by Date, Image_File_Name, UserName, Type, host
| sort - Date",0,5f62cccb668db2340e11a44a
"SPL-231","Security Access Granted to an account. 2003 or older.","windows,wineventlog",security,"Security Access Granted to an account. 2003 or older.","index=* sourcetype=""WinEventLog:Security"" EventCode=621 Account_Modified!=""%{*""
| eval Date=strftime(_time, ""%Y/%m/%d"")
| stats count by User_Name, Account_Modified, Access_Granted, Date, action |rename User_Name as ""Source Account""
| rename Account_Modified as ""Target Account""
| rename Access_Granted as ""New Rights Granted""",0,5f62cccb668db2340e11a44b
"SPL-232","Failed Attempt to Login to a Disabled Account","disabled,security,windows",security,"Failed Attempt to Login to a Disabled Account","index=* sourcetype=""WinEventLog:security"" EventCode=4625 (Sub_Status=""0xc0000072"" OR Sub_Status=""0xC0000072"") Security_ID!=""NULL SID"" Account_Name!=""*$""
| eval Date=strftime(_time, ""%Y/%m/%d"")
| rex ""Which\sLogon\sFailed:\s+\S+\s\S+\s+\S+\s+Account\sName:\s+(?<facct>\S+)""
| eval Date=strftime(_time, ""%Y/%m/%d"")
| stats count by Date, facct, host, Keywords
| rename facct as ""Target Account"" host as Host Keywords as Status count as Count",0,5f62cccb668db2340e11a44c
"SPL-233","Real Time IIS Web Site Connections
Assuming JSESSIONID is auto-extracted, run the following REAL-TIME search (choose your window, I typically go with 5 minutes)",iis,web,"Real Time IIS Web Site Connections
Assuming JSESSIONID is auto-extracted, run the following REAL-TIME search (choose your window, I typically go with 5 minutes)","index=* sourcetype=""iis""
| stats dc(JSESSIONID)",0,5f62cccb668db2340e11a44d
"SPL-234","Return only anomalous event.  Replace the wildcard * and or field names to be applicable to your data set(s.)",anomalies,misc,"Return only anomalous event.  Replace the wildcard * and or field names to be applicable to your data set(s.)","index=* sourcetype=*
| anomalies",0,5f62cccb668db2340e11a44e
"SPL-235","More than a day between events
Add a field to each event which is the time between this event and the previous one.
The only field required here is _time.",duration,misc,"More than a day between events
Add a field to each event which is the time between this event and the previous one.
The only field required here is _time.","index=* sourcetype=*
| sort _time
| streamstats current=f global=f window=1 last(_time) as last_ts
| eval time_since_last = _time - last_ts
| fieldformat time_since_last = tostring(time_since_last, ""duration"")
| where time_since_last > 60*60*24",0,5f62cccb668db2340e11a44f
"SPL-236","Predict: Example 2.  Replace the wildcard * and or field names to be applicable to your data set(s.)",predict,misc,"Predict: Example 2.  Replace the wildcard * and or field names to be applicable to your data set(s.)","index=* sourcetype=*
| timechart span=""1m"" count AS foo
| predict foo as fubar algorithm=LL upper90=high lower97=low future_timespan=10 holdback=20",0,5f62cccb668db2340e11a450
"SPL-237","Predict: Example.  Replace the wildcard * and or field names to be applicable to your data set(s.)",predict,misc,"Predict: Example.  Replace the wildcard * and or field names to be applicable to your data set(s.)","index=* sourcetype=*
| timechart span=1d count(file) as count
| predict count",0,5f62cccb668db2340e11a451
"SPL-238","Time between events
Add a field to each event which is the time between this event and the previous one.
The only field required here is _time.",duration,misc,"Time between events
Add a field to each event which is the time between this event and the previous one.
The only field required here is _time.","index=* sourcetype=*  Error
| sort _time
| streamstats current=f global=f window=1 last(_time) as last_ts
| eval time_since_last = _time - last_ts
| fieldformat time_since_last = tostring(time_since_last, ""duration"")",0,5f62cccb668db2340e11a452
"SPL-239","Avg Value for 24 hours over 30 days compared with todays value- optimized searches",compare,special,"Avg Value for 24 hours over 30 days compared with todays value- optimized searches","index=* sourcetype=* error earliest=-30d latest=@h
| timechart span=1h count
| eval StartTime=relative_time(now(),""-24h@h"")
| eval Series=if(_time>=StartTime,""TodaysCount"",""AverageCount"")
| eval Hour = strftime(_time,""%H"")
| chart avg(count) by Hour Series",0,5f62cccb668db2340e11a453
"SPL-240","Events processed by Web Servers / load balance?",trouble,web,"Events processed by Web Servers / load balance?","index=* sourcetype=*access*
earliest=-7d@d  latest=now
| timechart count by host",0,5f62cccb668db2340e11a454
"SPL-241","Gets vs Posts","gets,posts",web,"Gets vs Posts","index=* sourcetype=*access*
| chart count(eval(method=""GET"")) AS GET,count(eval(method=""POST"")) AS POST",0,5f62cccb668db2340e11a455
"SPL-242","Search Web / Total KB / # of Unique IPs. Replace the wildcard * and or field names to be applicable to your data set(s.)",stats,web,"Search Web / Total KB / # of Unique IPs. Replace the wildcard * and or field names to be applicable to your data set(s.)","index=* sourcetype=*access*
| eval kb=bytes/1024
|  stats sum(kb) dc(clientip)
|  rename sum(kb) AS ""Total KB"" dc(FIELD) AS ""Unique Customers""",0,5f62cccb668db2340e11a456
"SPL-243","Keep the ""host"" and ""ip"" fields, and display them in the order: ""host"", ""ip""","field,show",web,"Keep the ""host"" and ""ip"" fields, and display them in the order: ""host"", ""ip""","index=* sourcetype=*access*
| fields + host, ip",0,5f62cccb668db2340e11a457
"SPL-244","Return the least common values of the ""url"" field.","rare,url",web,"Return the least common values of the ""url"" field.","index=* sourcetype=*access*
| rare url",0,5f62cccb668db2340e11a458
"SPL-245","Return values of ""URL"" that contain the string ""404"" or ""303"" but not both.","diff,errors",SPL,"Return values of ""URL"" that contain the string ""404"" or ""303"" but not both.","index=* sourcetype=*access*
| set diff [search 404 | fields url] [search 303 | fields url]",0,5f62cccb668db2340e11a459
"SPL-246","A ""transaction"" search using the ""stats"" command instead. Its less resources and more flexibility.","duration,stats,web",web,"A ""transaction"" search using the ""stats"" command instead. Its less resources and more flexibility.","index=* sourcetype=*access*
| stats min(_time) AS earliest max(_time) AS latest by FIELD
| eval duration=latest-earliest | stats min(duration) max(duration) avg(duration)",0,5f62cccb668db2340e11a45a
"SPL-247","Top Users",sparkline,web,"Top Users","index=* sourcetype=*access*
| stats sparkline count by username
| sort -count
| head 10",0,5f62cccb668db2340e11a45b
"SPL-248","Create a timechart of the count of from ""web"" sources by ""host""",host,web,"Create a timechart of the count of from ""web"" sources by ""host""","index=* sourcetype=*access*
| timechart count by host",0,5f62cccb668db2340e11a45c
"SPL-249","Total Unique Client IPs Over Time",unique,web,"Total Unique Client IPs Over Time","index=* sourcetype=*access*
| timechart distinct_count(clientip) span=1h",0,5f62cccb668db2340e11a45d
"SPL-250","Search the access logs, and return the number of hits from the top 100 values of ""referer_domain","referer,url",web,"Search the access logs, and return the number of hits from the top 100 values of ""referer_domain","index=* sourcetype=*access*
| top limit=100 referer_domain
| stats sum(count)",0,5f62cccb668db2340e11a45e
"SPL-251","Return the 20 most common values of the ""url"" field.",url,web,"Return the 20 most common values of the ""url"" field.","index=* sourcetype=*access*
| top limit=20 url",0,5f62cccb668db2340e11a45f
"SPL-252","Session Hijacking report/alert","iis,transaction",security,"Session Hijacking report/alert","index=* sourcetype=*access*
| transaction JSESSIONID  #(JSESSIONID) This/these field/s must exist or edit to make search valid.
| where mvcount(clientip)>1  #(clientip) This/these field/s must exist or edit to make search valid.
| table clientip, JSESSIONID",0,5f62cccb668db2340e11a460
"SPL-253","Bounce Rate (Enters and exits on the same page)",transaction,web,"Bounce Rate (Enters and exits on the same page)","index=* sourcetype=*access*
| transaction clientip maxpause=1h keepevicted=t mvlist=t
| eval user_type=case (eventcount=1,""Bounced"", eventcount<=5, ""2-5 pages"", eventcount<=10, ""6-10 pages"")
| top limit=5000 user_type",0,5f62cccb668db2340e11a461
"SPL-254","Hits by host for last 7 days.","hits,host",web,"Hits by host for last 7 days.","index=* sourcetype=*access* earliest = -7d@d latest = now
| timechart count by host",0,5f62cccb668db2340e11a462
"SPL-255","Hits by Host without Internal access for last 7 days.","access,host",web,"Hits by Host without Internal access for last 7 days.","index=* sourcetype=*access* earliest = -7d@d latest = now clientip != 192*
| timechart count by host",0,5f62cccb668db2340e11a463
"SPL-256","Traffic with Bad HTTP status for last 7 days.",status,web,"Traffic with Bad HTTP status for last 7 days.","index=* sourcetype=*access* earliest = -7d@d latest = now status>300
| timechart count BY status",0,5f62cccb668db2340e11a464
"SPL-257","Top pages by bad HTTP status for last 7 days.","bad,status",web,"Top pages by bad HTTP status for last 7 days.","index=* sourcetype=*access* earliest = -7d@d latest = now status>=300
| stats dc(clientip) as ""unique ips"" count as ""total count"" by uri, status",0,5f62cccb668db2340e11a465
"SPL-258","Unique Visitors",unique,web,"Unique Visitors","index=* sourcetype=*access* earliest=-10d@d latest=now
| timechart dc(clientip) AS unique_visitors by host",0,5f62cccb668db2340e11a466
"SPL-259","Who has accessed in the last 7 days.",host,web,"Who has accessed in the last 7 days.","index=* sourcetype=*access* earliest=-7d@d latest=now
| timechart count by host",0,5f62cccb668db2340e11a467
"SPL-260","Traffic with Good HTTP status for last 7 days.",status,web,"Traffic with Good HTTP status for last 7 days.","index=* sourcetype=*access* earliest=-7d@d latest=now status>100 status<300
| timechart count BY status",0,5f62cccb668db2340e11a468
"SPL-261","Account Enabled in Windows from a previously disabled state",windows,Other,"Account Enabled in Windows from a previously disabled state. Must have the Splunk app for Windows installed: Windows Server 2008 and newer.","index=* sourcetype=WinEventLog:Security (EventCode=4722) #(WinEventLog:Security) This/these sourcetype/s must  exist or edit to make search valid.
| eval Date=strftime(_time, ""%Y/%m/%d"") |rex ""ID:\s+\w+\\\(?<sourceaccount>\S+)\s+""
| rex ""Account:\s+Security\sID:\s+\w+\\\(?<targetaccount>\S+)\s+""
| stats count by Date, sourceaccount, targetaccount, Keywords, host
| rename sourceaccount as ""Source Account""
| rename targetaccount as ""Target Account""
| sort - Date",0,5f62cccb668db2340e11a469
"SPL-262","Accounts deleted within 24 hours of creation",wineventlog,Security,"Accounts deleted within 24 hours of creation: 2008 or better, requires the Splunk app for Windows","index=* sourcetype=WinEventLog:Security (EventCode=4726 OR EventCode=4720)
|eval Date=strftime(_time, ""%Y/%m/%d"")
|rex ""Subject:\s+\w+\s\S+\s+\S+\s+\w+\s\w+:\s+(?<SourceAccount>\S+)""
| rex ""Target\s\w+:\s+\w+\s\w+:\s+\S+\s+\w+\s\w+:\s+(?<DeletedAccount>\S+)""
| rex ""New\s\w+:\s+\w+\s\w+:\s+\S+\s+\w+\s\w+:\s+(?<NewAccount>\S+)""
| eval SuspectAccount=coalesce(DeletedAccount,NewAccount)
| transaction SuspectAccount startswith=""EventCode=4720"" endswith=""EventCode=4726"" |eval duration=round(((duration/60)/60)/24, 2)
| eval Age=case(duration<=1, ""Critical"", duration>1 AND duration<=7, ""Warning"", duration>7, ""Normal"")
| table Date, index, host, SourceAccount, SuspectAccount, duration, Age
| rename duration as ""Days Account was Active"" | sort + ""Days Account was Active""",0,5f62cccb668db2340e11a46a
"SPL-263","Time between rights granted and rights revoked: 2003 and older.","windows,wineventlog",security,"Time between rights granted and rights revoked: 2003 and older.","index=* sourcetype=WinEventLog:Security (EventCode=608 OR EventCode=609)
| rex ""Message=User\sRight\sAssigned:\s+User\sRight:\s+(?\w+)""
| rex ""Message=User\sRight\sRemoved:\s+User\sRight:\s+(?\w+)""
| eval Rights=coalesce(RightGranted,RightRemoved)
| eval status=case(EventCode=608, ""New Rights Granted by:"", EventCode=609, ""Rights Removed by:"")
| transaction Rights user startswith=""Assigned"" endswith=""Removed""
| where duration > 0
| eval duration = duration/60 |eval n=round(duration,2)
| eval Date=strftime(_time, ""%Y/%m/%d"")
| table Date, host, status, User, user, Rights, n
| rename User as ""Source Account""
| rename user as ""Target Account""
| rename n as ""Minutes between Rights Granted Then Removed""
| sort - date",0,5f62cccb668db2340e11a46b
"SPL-264","Account Enabled in Windows from a previously disabled state","windows,wineventlog",Security,"Account Enabled in Windows from a previously disabled state. Must have the Splunk app for Windows installed: Windows Server 2003 and older.","index=* sourcetype=WinEventLog:Security (EventCode=626) #(WinEventLog:Security) This/these sourcetype/s must  exist or edit to make search valid.
| eval Date=strftime(_time, ""%Y/%m/%d"")
| stats count by Date, Caller_User_Name, Target_Account_Name, Type, host #(Date, Caller_User_Name, Target_Account_Name, Type, host) This/these field/s must exist or edit to make search valid.
| sort - Date",0,5f62cccb668db2340e11a46c
"SPL-265","Accounts deleted within 24 hours of creation","windows,wineventlog",Security,"Accounts deleted within 24 hours of creation: 2003 or older, requires the Splunk app for Windows","index=* sourcetype=WinEventLog:Security (EventCode=630 OR EventCode=624) |eval Date=strftime(_time, ""%Y/%m/%d"") | transaction Target_Account_Name startswith=""EventCode=624"" endswith=""EventCode=630"" |eval duration=round(((duration/60)/60)/24, 2) | eval Age=case(duration<=1, ""Critical"", duration>1 AND duration<=7, ""Warning"", duration>7, ""Normal"")| table Date, index, host, Caller_User_Name, Target_Account_Name, duration, Age | rename duration as ""Days Account was Active"" | sort - Date",0,5f62cccb668db2340e11a46d
"SPL-266","Accounts Deleted via EventIDs that Correspond with Post XP/2003 Operating Systems",windows,Security,"Accounts Deleted via EventIDs that Correspond with Post XP/2003 Operating Systems.
This query will search for accounts deleted via EventIDs that correspond with post XP/2003 operating systems. It will output the admin account, account deleted, details about the action, and the machine that the account deletion took place on.","index=* sourcetype=WinEventLog:Security (EventCode=630)
| eval Date=strftime(_time, ""%Y/%m/%d"")
| stats count by User, Target_Account_Name, name, host, index Date
| rename User as ""Administrator Account""
| rename Target_Account_Name as ""Account Name Deleted""
| rename name as ""Detailed Information""
| rename host as ""Computer the Account was Created on""
| rename index as ""Index of origin""| sort - Date",0,5f62cccb668db2340e11a46e
"SPL-267","Unusual outbound activity using a high number of DNS requests occurring from a particular client compared to a baseline. Its possible advanced threat communication (instruction, stealing data) via the DNS protocol is being used.",dns,security,"Unusual outbound activity using a high number of DNS requests occurring from a particular client compared to a baseline. Its possible advanced threat communication (instruction, stealing data) via the DNS protocol is being used.","index=* sourcetype=dns       #(dns) Make sure that this/these sourcetype/s exist or edit to make search valid.
| stats count(clientip) AS Requests by clientip #(clientip) This/these field/s must exist or edit to make search valid.
| sort - Requests",0,5f62cccb668db2340e11a46f
"SPL-268","Unusual outbound activity using a High number of same-sized DNS requests from an internal host, patterns of same-sized DNS requests which can evidence advanced threat communication (instruction/data theft) using DNS.",dns,security,"Unusual outbound activity using a High number of same-sized DNS requests from an internal host, patterns of same-sized DNS requests which can evidence advanced threat communication (instruction/data theft) using DNS.","index=* sourcetype=dns #(dns) Make sure that this/these sourcetype/s exist or edit to make search valid.
| eval Length=len(query)
| stats count(clientip) by Length #(clientip) This/these field/s must exist or edit to make search valid.
| sort  Length",0,5f62cccb668db2340e11a470
"SPL-269","Total Unique Browsers detected in IIS logs.
The following Splunk search query will show a count of unique browsers (calculation to include version) that hit a given website within IIS logs:",iis,web,"Total Unique Browsers detected in IIS logs.
The following Splunk search query will show a count of unique browsers (calculation to include version) that hit a given website within IIS logs:","index=* sourcetype=iis
| stats dc(cs_User_Agent)",0,5f62cccb668db2340e11a471
"SPL-270","Repeated Unsuccessful Logon Attempts in Linux","fail,linux_secure,login",security,"Repeated Unsuccessful Logon Attempts in Linux","index=* sourcetype=linux_secure
| eval Date=strftime(_time, ""%Y/%m/%d"")
| rex "".*:\d{2}\s(?<hostname>\S+)""
| rex ""gdm\S+\sauthentication\s(?<status>\w+)""
| rex ""\suser[^'](?<User>\S+\w+)""
| search status=failure
| stats count as fails by Date, User, hostname
| eval ""Alert Level""=case(fails>=50, ""Critical"", fails<50 AND fails>=20, ""Warning"", fails<20, ""Normal"")
| sort - fails
| rename fails as ""Failed Logon Attempts""
| rename User as ""Account in Question""",0,5f62cccb668db2340e11a472
"SPL-271","Number of hosts the root account was detected on.","linux_secure",security,"Number of hosts the root account was detected on.","index=* sourcetype=linux_secure
| rex "".*:\d{2}\s(?<hostname>\S+)""
| rex ""\suser[^'](?<User>\S+\w+)""
| search User=""root""
| stats dc(hostname)",0,5f62cccb668db2340e11a473
"SPL-272","Number of Hosts the Root Account was Detected on.
The following splunk query example will return the total number of hosts the Root account was detected on  in a given time range *NOTE* if the host field is being autoextracted (for instance if you are using a universal forwarder) you will not need the regex command and can call upon the auto extracted fieldname []","hosts,root",security,"Number of Hosts the Root Account was Detected on.
The following splunk query example will return the total number of hosts the Root account was detected on  in a given time range *NOTE* if the host field is being autoextracted (for instance if you are using a universal forwarder) you will not need the regex command and can call upon the auto extracted fieldname []","index=* sourcetype=linux_secure
| rex "".*:\d{2}\s(?<hostname>\S+)""
| rex ""\suser[^'](?<User>\S+\w+)""
| search User=""root"" | stats dc(hostname)",0,5f62cccb668db2340e11a474
"SPL-273","List of hosts in a Linux Environment. If you are using a universal forwarder, this field will be autoextracted as ""host"".","linux_secure",security,"List of hosts in a Linux Environment. If you are using a universal forwarder, this field will be autoextracted as ""host"".","index=* sourcetype=linux_secure
| rex "".*:\d{2}\s(?<hostname>\S+)""
| stats count by hostname",0,5f62cccb668db2340e11a475
"SPL-274","Top 10 most active hosts in a Linux Environment: If using a universal forwarder, rex isn't needed, this will be extracted as ""host"".","linux_secure,rex",security,"Top 10 most active hosts in a Linux Environment: If using a universal forwarder, rex isn't needed, this will be extracted as ""host"".","index=* sourcetype=linux_secure
| rex "".*:\d{2}\s(?<hostname>\S+)""
| top limit=10 hostname",0,5f62cccb668db2340e11a476
"SPL-275","Count of Unique users in a linux environment","linux_secure",security,"Count of Unique users in a linux environment","index=* sourcetype=linux_secure
| rex ""\suser[^'](?<User>\S+\w+)""
| stats dc(User)",0,5f62cccb668db2340e11a477
"SPL-276","Top 10 most active users in Linux","linux_secure",security,"Top 10 most active users in Linux","index=* sourcetype=linux_secure
| rex ""\suser[^'](?<User>\S+\w+)""
| top limit=10 User",0,5f62cccb668db2340e11a478
"SPL-277","Linux Logons: Failed","fail,linux,login",security,"Linux Logons: Failed","index=* sourcetype=linux_secure
| rex ""\w{3}\s\d{1,2}\s\d{2}:\d{2}:\d{2}\s\S+\s(?<session>gdm-\w+)\S:\s""
| search session=gdm-password
| rex ""\w{3}\s\d{1,2}\s\d{2}:\d{2}:\d{2}\s(?<hostname>\S+)\s.+\Sgdm-password:auth\S:\s(?<authstatus>\w+\s\w+);\s.+user=(?<username>\S+)""
| search authstatus=""authentication failure""
| timechart count(username)",0,5f62cccb668db2340e11a479
"SPL-278","Linux Logons: Successful","linux_secure",security,"Linux Logons: Successful","index=* sourcetype=linux_secure
| rex ""\w{3}\s\d{1,2}\s\d{2}:\d{2}:\d{2}\s\S+\s(?<session>gdm-\w+)\S:\s""
| search session=gdm-password
| rex ""\w{3}\s\d{1,2}\s\d{2}:\d{2}:\d{2}\s(?<hostname>\S+)\s.+\Sgdm-password:auth\S:\s(?<authstatus>\w+\s\w+);\s.+user=(?<username>\S+)""
| search authstatus=""authentication success""
| timechart count(username)",0,5f62cccb668db2340e11a47a
"SPL-279","List of user accounts in a linux environment:","linux_secure",security,"List of user accounts in a linux environment:","index=* sourcetype=linux_secure #(linux_secure) This/these sourcetype/s exist or edit to make search valid.
| rex ""\suser[^'](?<User>\S+\w+)""
| stats count by User",0,5f62cccb668db2340e11a47b
"SPL-280","Escaltion of Privs via SU in Linux:","linux_secure",security,"Escaltion of Privs via SU in Linux:","index=* sourcetype=linux_secure source=""/var/log/*"" ""su: ("" #(linux_secure) This/these sourcetype/s exist or edit to make search valid.
| eval Date=strftime(_time, ""%Y/%m/%d"")
| rex "".*:\d{2}\s(?<hostname>\S+)""
| rex ""su:\s\Sto\sroot\S\s(?<SU>\S+)""
| stats count by Date, hostname, SU
| rename count as ""Occurrences""
| rename SU as ""Account with Escalated Privileges"" | sort - Date",0,5f62cccb668db2340e11a47c
"SPL-281","Real Time Users","realtime,tag,users,web",web,"Real Time Users","index=* tag=web
| timechart dc(clientip) AS unique_visitors by host",0,5f62cccb668db2340e11a47d
"SPL-282","Does a distinct on data by its shape (punct). punct is the skeleton of the event.",punct,misc,"Does a distinct on data by its shape (punct). punct is the skeleton of the event.","index=INDEX sourcetype=SOURCETYPE
| dedup punct",0,5f62cccb668db2340e11a47e
"SPL-283","Rare Punctuation by Host","punct,rare",special,"Rare Punctuation by Host","index=INDEX sourcetype=SOURCETYPE
| err* OR fail* OR crit* OR fatal* OR except* | rex field=punct ""(?<smallpunct>.{5})""
| eval smallpunct= ""*"" + smallpunct
| stats first(_raw) as example count by smallpunct
| sort -count | fields smallpunct,count,example",0,5f62cccb668db2340e11a47f
"SPL-284","Request Duration Deviation Critical (processing_time)",duration,web,"Request Duration Deviation Critical (processing_time)","index=INDEX sourcetype=SOURCETYPE
| eval processingTime = tonumber(trim(processing_time, ""ms""))
| eval formattedTime = strftime(_time, ""%Y%m%d"")
| eval processingTimeBase = if (formattedTime = ""20121012"", processingTime, null)
| eval processingTimeNow = if (formattedTime = ""20121013"", processingTime, null)
| stats avg(processingTimeBase) as avgProcessingTimeBase, avg(processingTimeNow) as avgProcessingTimeNow by request_type
| eval diff = avgProcessingTimeNow - avgProcessingTimeBase
| eval pctChange = round(diff / avgProcessingTimeBase, 3) * 100
| where pctChange > 10000",0,5f62cccb668db2340e11a480
"SPL-285","Find the count of a number of times something happened for ACTORX VS ALLACTORS and show the ACTORCOUNT and its percentage to the whole.","count,percentage",misc,"Find the count of a number of times something happened for ACTORX VS ALLACTORS and show the ACTORCOUNT and its percentage to the whole.","index=INDEX sourcetype=SOURCETYPE
| eventstats count as ""total_count""
| eventstats count as ""variable_count"" by YOURVARIABLE
| eval percent=(variable_count/total_count)*100
| stats values(variable_count), values(percent) as percent by YOURVARIABLE",0,5f62cccb668db2340e11a481
"SPL-286","Deriving Total Bytes",convert,misc,"Deriving Total Bytes","index=INDEX sourcetype=SOURCETYPE
| stats sum(total_bytes) as TotalBytes
| eval MB=(TotalBytes)/1048576",0,5f62cccb668db2340e11a482
"SPL-287","Compute the product of the average ""CPU"" and average ""MEM"" each minute for each ""host""","cpu,mem,os,timechart",misc,"Compute the product of the average ""CPU"" and average ""MEM"" each minute for each ""host""","index=INDEX sourcetype=SOURCETYPE
| timechart span=1m
| eval(avg(CPU) * avg(MEM)) by host",0,5f62cccb668db2340e11a483
"SPL-288","Timewrap. Use this after a 'timechart' command, and compare week-over-week. Or use 'h' (hour), 'w' (week), 'm' (month), 'q' (quarter), 'y' (year).  Replace the wildcard * and or field names to be applicable to your data set(s.)","command,timewrap",misc,"Timewrap. Use this after a 'timechart' command, and compare week-over-week. Or use 'h' (hour), 'w' (week), 'm' (month), 'q' (quarter), 'y' (year).  Replace the wildcard * and or field names to be applicable to your data set(s.)","index=INDEX sourcetype=SOURCETYPE
| timewrap 1w",0,5f62cccb668db2340e11a484
"SPL-289","Punct example:2","error,punct,pwn",misc,"Punct example:2","index=INDEX sourcetype=SOURCETYPE  err* OR fail* OR crit* OR fatal* OR except*
| rex field=punct ""(?<smallpunct>.{5})""
| eval smallpunct= ""*"" + smallpunct
| stats first(_raw) as example count by smallpunct
| sort -count
| fields smallpunct,count,example",0,5f62cccb668db2340e11a485
"SPL-290","What you Don't Know.
(Outputting of known events to a .csv file)
Search #2  Scheduled to compare recent errors with table of known errors: I tagged all errors that I found as known and then the search became:
err* OR fail* OR crit* OR down NOT tag=known","errors,known,output",special,"What you Don't Know.
(Outputting of known events to a .csv file)
Search #2  Scheduled to compare recent errors with table of known errors: I tagged all errors that I found as known and then the search became:
err* OR fail* OR crit* OR down NOT tag=known","index=INDEX sourcetype=SOURCETYPE FIELD=*
| dedup FIELD
| search NOT [inputlookup known_errors.csv
| fields +
| dedup FIELD]",0,5f62cccb668db2340e11a486
"SPL-291","What you Don't Know.
(Outputting of known events to a .csv file)
Search #1  Scheduled to populate ""known errors"" table.","errors,known,output",special,"What you Don't Know.
(Outputting of known events to a .csv file)
Search #1  Scheduled to populate ""known errors"" table.","index=INDEX sourcetype=SOURCETYPE FIELD=*
| fields + FIELD
| dedup FIELD
| outputlookup known_errors.csv",0,5f62cccb668db2340e11a487
"SPL-292","Punct example:1","error,punct",misc,"Punct example:1","index=INDEX sourcetype=SOURCETYPE err* OR fail* OR crit* OR down OR fatal OR except*
| rare punct",0,5f62cccb668db2340e11a488
"SPL-293","Unusual/short file names used by hackers to avoid detection","endpoint,system",security,"Unusual/short file names used by hackers to avoid detection","index=YOURINDEX
| eval file_length=len(file)       #(file) This/these field/s must exist or edit to make search valid.
| where file_length < 4",0,5f62cccb668db2340e11a489
"SPL-294","Process List via Tasklist in Microsoft Windows or Linux ps command.",process,security,"Process List via Tasklist in Microsoft Windows or Linux ps command.","index=YOURINDEX
| stats dc(host) by process
| sort dc(host)",0,5f62cccb668db2340e11a48a
"SPL-295","Splunk Server Restart Duration","duration,pwn,splunkd","splunk_internal","Splunk Server Restart Duration","index=_audit (action=""splunkShuttingDown"" OR action=""splunkStarting"")
| eval Date=strftime(_time, ""%Y/%m/%d"") | transaction splunk_server startswith=action=""splunkShuttingDown"" endswith=action=""splunkStarting""
| eval duration=round(duration/60, 2)
| table Date splunk_server duration
| rename duration as ""Splunk Restart Duration"" splunk_server as ""Splunk Server""",0,5f62cccb668db2340e11a48b
"SPL-296","User training for overall search best practices (e.g. specifying indexes/sourcetypes, when wildcards are appropriate, and using proper time ranges).","audit,search","splunk_internal","User training for overall search best practices (e.g. specifying indexes/sourcetypes, when wildcards are appropriate, and using proper time ranges).","index=_audit [|rest /services/server/info splunk_server=local
| fields host]  action=search user=* user!=splunk-system-user search_id=* (info=granted OR info=completed)
|rex field=apiStartTime ""'(?<start_time>[^']+)'""
|rex field=apiEndTime ""'(?<end_time>[^']+)'""
|rex ""search\=(?<search_string>.+)\,\sautojoin""
|eval range=if(start_time==""ZERO_TIME"",""All Time"", tostring(strptime(end_time, ""%a %b %d %H:%M:%S %Y"") - strptime(start_time, ""%a %b %d %H:%M:%S %Y""),""duration""))
|eval range2=if(start_time==""ZERO_TIME"",""All Time"", strptime(end_time, ""%a %b %d %H:%M:%S %Y"") - strptime(start_time, ""%a %b %d %H:%M:%S %Y""))
|stats max(event_count) AS event_count values(start_time) AS ""Search Earliest"" values(end_time) AS ""Search Latest"" count values(range) AS range values(range2) AS range2 values(search) AS Search values(user) AS User max(total_run_time) AS run_time(sec) by search_id savedsearch_name
| convert ctime(*Time) ctime(""Search Start"") ctime(""Search End"")
|where count>1 |rename search_id AS SID range AS ""Search Range""
| eval ""Run Time""=tostring('run_time(sec)',""duration"")
| eval ""Overran?""=if('run_time(sec)'>range2,""Overran its range!!!"", ""NO"")
| eval SID = trim(SID, ""'"")
| table SID savedsearch_name event_count ""Search Earliest"" ""Search Latest"" ""Search Range"" Search User ""run_time(sec)"" ""Overran?"" ""Run Time""
| sort - ""Run Time""",0,5f62cccb668db2340e11a48c
"SPL-297","Shows users by search time","audit,user","splunk_internal","Shows users by search time","index=_audit action=search (id=* OR search_id=*)
| eval search_id = if(isnull(search_id), id, search_id)
| replace '*' with * in search_id
| rex ""search='(?<search>.*?)', autojoin""
| search search_id!=scheduler_*
| convert num(total_run_time)
| rex ""\,\s+user=(?<user>\S+),""
| eval user = if(user=""n/a"", null(), user)
| stats min(_time) as _time first(user) as user max(total_run_time) as total_run_time first(search) as search by search_id host
| search search=search* search!=*_internal* search!=*_audit*
| stats median(total_run_time) as ""Median search time"" perc95(total_run_time) as ""95th Percentile search time"" sum(total_run_time) as ""Total search time"" count as ""Search count"" max(_time) as ""Last use"" by user host
| fieldformat ""Last use"" = strftime('Last use', ""%F %T.%Q %:z"")
| rename host AS ""Search Head""
| sort - ""Median search time""",0,5f62cccb668db2340e11a48d
"SPL-298","Splunk Query Count by users","count,pwn,users","splunk_internal","Splunk Query Count by users","index=_audit search=* NOT (search_id='scheduler* OR search_id='Summary*) user=admin
| timechart span=1d count by user usenull=f",0,5f62cccb668db2340e11a48e
"SPL-299","Internal Splunk User Modifications.
This query will search the internal audit sourcetype of splunk and report on any user modification attempts, both success and fail.",audit,"splunk_internal","Internal Splunk User Modifications.
This query will search the internal audit sourcetype of splunk and report on any user modification attempts, both success and fail.","index=_audit sourcetype=audittrail action=edit_user
| eval Date=strftime(_time, ""%Y/%m/%d"")
| where user!=object
| stats count by user, info, object, Date
| rename user as ""Authenticated User""
| rename info as ""Success Status""
| rename object as ""Modified Account""
| sort - count",0,5f62cccb668db2340e11a48f
"SPL-300","Splunk User Search Activity","pwn,user","splunk_internal","Splunk User Search Activity","index=_audit splunk_server=local action=search (id=* OR search_id=*)
| eval search_id = if(isnull(search_id), id, search_id)
| replace '*' with * in search_id
| rex ""search='search\s(?<search>.*?)',\sautojoin""| search search_id!=scheduler_*
| convert num(total_run_time) | eval user = if(user=""n/a"", null(), user)
| stats min(_time) as _time first(user) as user max(total_run_time) as total_run_time first(search) as search by search_id
| search search!=*_internal*  search!=*_audit*
| chart sum(total_run_time) as ""Total search time"" count as ""Search count"" max(_time) as ""Last use"" by user
| fieldformat ""Last use"" = strftime('Last use', ""%F %T.%Q"")",0,5f62cccb668db2340e11a490
"SPL-301","Shows what user did what over time and what was the outcome","audit,user","splunk_internal","Shows what user did what over time and what was the outcome","index=_audit | table _time user action info",0,5f62cccb668db2340e11a491
"SPL-302","Splunk Errors","errors,splunkd","splunk_internal","Splunk Errors","index=_internal  error  NOT debug source=*splunkd.log*",0,5f62cccb668db2340e11a492
"SPL-303","Top Five Sourcetypes","",Sourcetypes,"Top Five Sourcetypes","index=_internal (source=*/metrics.log* OR source=*\\metrics.log*) group=per_sourcetype_thruput
| chart sum(kb) by series
| sort -sum(kb)
| head 5",0,5f62cccb668db2340e11a493
"SPL-304","Calculate Event Data Sizes","event,pwn","splunk_internal","Calculate Event Data Sizes","index=_internal earliest=""-d@d"" latest=""@d""
| fieldsummary
| rex field=values max_match=100 ""value\"":\""(?<foo>[^\""]*)\"",""
| mvexpand foo
| eval foo_len=len(foo)
| rex field=field ""^(?!date|punct|host|hostip|index|linecount|source|sourcetype|timeendpos|timestartpos|splunk_server)(?<Field>.*)""
| stats max(foo_len) as Bytes values(foo) as Values by Field,count
| eval SpaceMB=(Bytes*count)/1024/1023
| rename count as Count
| table Field Bytes Count SpaceMB
| sort -SpaceMB",0,5f62cccb668db2340e11a494
"SPL-305","Comparing Stats Time Over Time","bin,compare,stats",misc,"Comparing Stats Time Over Time","index=_internal earliest=-48h latest=-24h
| bin _time span=10m
| stats count by _time
| eval window=""yesterday""
| append
[search index=_internal earliest=-24h
| bin _time span=10m
| stats count by _time
| eval window=""today""
| eval _time=(_time-(60*60*24))]
| timechart span=10m sum(count) by window",0,5f62cccb668db2340e11a495
"SPL-306","Number of users who can run real-time searches.","audit,search,user","splunk_internal","Number of users who can run real-time searches.","index=_internal host=acdc-sec-splk-shcp2.cdc.gov source=*metrics.log group=search_concurrency ""system total"" NOT user=*
| timechart max(active_realtime_searches) AS ""Max Real-Time Searches""",0,5f62cccb668db2340e11a496
"SPL-307","Counted against license",license,"splunk_internal","Counted against license","index=_internal source=* license_usage.log type=Usage
| stats sum(b) as bytes by date_wday, date_mday, date_month, idx
| eval GB = round(bytes/1024/1024/1024,5)
| table date_wday, date_mday, date_month, GB, idx",0,5f62cccb668db2340e11a497
"SPL-308","Splunk License Usage Over the Last 30 Days",license,"splunk_internal","Splunk License Usage Over the Last 30 Days","index=_internal source=*license_usage.log type=""RolloverSummary"" earliest=-30d@d
| eval _time=_time - 43200
| bin _time span=1d
| stats latest(b) AS b by slave, pool, _time
| timechart span=1d sum(b) AS ""volume"" fixedrange=false
| join type=outer _time [search index=_internal source=*license_usage.log type=""RolloverSummary"" earliest=-30d@d
| eval _time=_time - 43200
| bin _time span=1d
| stats latest(stacksz) AS ""stack size"" by _time]
| fields - _timediff
| foreach * [eval FIELD=round('FIELD'/1024/1024/1024, 3)]",0,5f62cccb668db2340e11a498
"SPL-309","License Usage Data Cube",license,"splunk_internal","License Usage Data Cube","index=_internal source=*license_usage.log type=""Usage""
| eval h=if(len(h)=0 OR isnull(h),""(SQUASHED)"",h)
| eval s=if(len(s)=0 OR isnull(s),""(SQUASHED)"",s)
| eval idx=if(len(idx)=0 OR isnull(idx),""(UNKNOWN)"",idx)
| bin _time span=1d
| stats sum(b) as b by _time, pool, s, st, h, idx",0,5f62cccb668db2340e11a499
"SPL-310","Top 5 License Consuming Hosts.
The following Splunk search query will return the top five licensing consuming hosts:","license,pwn","splunk_internal","Top 5 License Consuming Hosts.
The following Splunk search query will return the top five licensing consuming hosts:","index=_internal source=*license_usage.log type=""Usage""
| stats sum(b) AS volume by h
| eval  GB=round(volume/1024/1024/1024,5)
| table h GB
| sort 5 - GB",0,5f62cccb668db2340e11a49a
"SPL-311","License Usage by Index per Day.
The following Splunk search query will output license usage for each index for each day for the week to date. It will also output an average for each index over the course of the given time period.","license,pwn","splunk_internal","License Usage by Index per Day.
The following Splunk search query will output license usage for each index for each day for the week to date. It will also output an average for each index over the course of the given time period.","index=_internal source=*license_usage.log type=""Usage"" splunk_server=* earliest=-1w@d
| eval Date=strftime(_time, ""%Y/%m/%d"")
| eventstats sum(b) as volume by idx, Date
| eval MB=round(volume/1024/1024,5)
| timechart first(MB) AS volume by idx",0,5f62cccb668db2340e11a49b
"SPL-312","Data Consumption",license,"splunk_internal","Data Consumption","index=_internal source=*license_usage.log type=Usage
| eval GB = b/1024/1024/1024
| timechart sum(GB) as GBytes
| streamstats sum(GBytes) as GB_Used
| predict GB_Used as GB_Expected algorithm=LLT future_timespan=14
| fields  Gbytes",0,5f62cccb668db2340e11a49c
"SPL-313","Spread out scheduled searches.","audit,search","splunk_internal","Spread out scheduled searches.","index=_internal source=*metrics.log group=searchscheduler
| timechart partial=false span=10m sum(dispatched) AS Started sum(skipped) AS Skipped",0,5f62cccb668db2340e11a49d
"SPL-314","Are my forwarders connecting to my receiver?",inputs,Other,"Are my forwarders connecting to my receiver? Which IP addresses are connecting to
Splunk as inputs, and how many times is each IP logged in metrics.log?","index=_internal source=*metrics.log* tcpin_connections
| stats count by sourceIp",0,5f62cccb668db2340e11a49e
"SPL-315","To measure the delay between the time stamp of the events and the indexing time (the time that the indexer receives and processes the events), use the following method: Look at the delay per host for the Splunk internal logs.","delay,pwn","splunk_internal","To measure the delay between the time stamp of the events and the indexing time (the time that the indexer receives and processes the events), use the following method: Look at the delay per host for the Splunk internal logs.","index=_internal source=*splunkd.log*
| eval delay_sec=_indextime-_time
| timechart min(delay_sec) avg(delay_sec) max(delay_sec) by host
",0,5f62cccb668db2340e11a49f
"SPL-316","Base for Summary Indexing: Dashboard Optimization","indexing,optimization,summary",misc,"Base for Summary Indexing: Dashboard Optimization","index=_internal source=*splunkd_access.log
| bucket _time span=1h
| sistats avg(some) by _time, method, status
| addinfo
| collect index=",0,5f62cccb668db2340e11a4a0
"SPL-317","Search to end all errors.
Identifies frequently occurring errors in your splunk instance. LSS knocking out the top 10 on this list will make your splunk instance very happy.","errors,pwn","splunk_internal","Search to end all errors.
Identifies frequently occurring errors in your splunk instance. LSS knocking out the top 10 on this list will make your splunk instance very happy.","index=_internal sourcetype=""splunkd"" log_level=""ERROR""
| stats sparkline count dc(host) as hosts last(_raw) as last_raw_msg values(sourcetype) as sourcetype last(_time) as last_msg_time first(_time) as first_msg_time values(index) as index by punct
| eval delta=round((first_msg_time-last_msg_time),2)
| eval msg_per_sec=round((count/delta),2)
| convert ctime(last_msg_time) ctime(first_msg_time)
| table last_raw_msg count hosts sparkline msg_per_sec sourcetype index first_msg_time last_msg_time delta
| sort -count",0,5f62cccb668db2340e11a4a1
"SPL-318","Detailed list of Errors Per Host Detailed list of Errors Per Host.
The following Splunk search will return a detailed list (by message) of errors associated with hosts running a universal forwarder:","error,errors,host,pwn,rest,splunkd","splunk_internal","Detailed list of Errors Per Host Detailed list of Errors Per Host.
The following Splunk search will return a detailed list (by message) of errors associated with hosts running a universal forwarder:","index=_internal sourcetype=""splunkd"" log_level=""ERROR""
| stats sparkline count dc(host) as uniqhosts last(message) as message last(_time) as last first(_time) as first by punct
| convert ctime(last) ctime(first)
| table message count uniqhosts sparkline first last
| sort -count
| rename message as ""Error Output"" count as Count uniqhosts as ""Number of Hosts"" first as ""First Occurance"" last as ""Most Recent Occurance""",0,5f62cccb668db2340e11a4a2
"SPL-319","Ensure no scheduled searches are running on indexers.","audit,searches","splunk_internal","Ensure no scheduled searches are running on indexers.","index=_internal sourcetype=scheduler result_count host!=acdc-sec-splk-shcp*
| extract pairdelim="","", kvdelim=""="", auto=f
| stats avg(result_count) min(result_count) max(result_count), sparkline(avg(result_count)) AS result_sparkline avg(run_time) min(run_time) max(run_time) sum(run_time) values(host) AS hosts count AS execution_count by savedsearch_name, app
| rename savedsearch_name AS title
| makemv delim="","" values(host)
| eval host_count=mvcount(hosts)
| makemv delim="","" hosts
| where app!=""TA-fire_brigade"" AND host_count > 1
| sort - ""avg(run_time)""",0,5f62cccb668db2340e11a4a3
"SPL-320","Average Splunk Web requests by hour","activity,congestion,pwn,user",SPL,"Average Splunk Web requests by hour.
This query is pretty awesome! It helped enlighten us to exactly when our splunk infrastructure is being hit with users.","index=_internal sourcetype=splunk_web_access
 [ rest / splunk_server=local
 | fields splunk_server
 | rename splunk_server as host ]
 | bin _time span=1d
 | stats count by date_hour _time
 | appendpipe [ fields _time
 | dedup _time
 | eval date_hour=mvrange(0,24,1)
 | eval count=0
 | mvexpand date_hour ]
 | stats sum(count) as count by date_hour _time
 | stats avg(count) as avg by date_hour
 | sort date_hour",0,5f62cccb668db2340e11a4a4
"SPL-321","Large number of knowledge objects being pushed to the shcluster.",audit,"Knowledge_Objects ","Large number of knowledge objects being pushed to the shcluster.","index=_internal sourcetype=splunkd component=DistributedBundleReplicationManager bundle_file_size=*
| rex field=bundle_file_size ""(?<bundle_size>\d+)""
| eval bundle_size_mb=bundle_size/1024
| stats count max(bundle_size_mb) by host",0,5f62cccb668db2340e11a4a5
"SPL-322","License Usage Forecast Model.
The following query can be used for Splunk license capacity planning. It is only a prediction based on your current ingestion rate, and attempts to predict what your usage will be over the next 120 days. It is recommended not to use all time in your search, as the predict command takes quite a bit of []",license,"splunk_internal","License Usage Forecast Model.
The following query can be used for Splunk license capacity planning. It is only a prediction based on your current ingestion rate, and attempts to predict what your usage will be over the next 120 days. It is recommended not to use all time in your search, as the predict command takes quite a bit of []","index=_internal todaysbytesindexed startdaysago=60
| eval GB_Indexed = todaysBytesIndexed/1024/1024/1024
| timechart span=1d avg(""GB_Indexed"")
| predict avg(""GB_Indexed"") future_timespan=120 as ""Forecast Index Rate""
| rename avg(""GB_Indexed"") as ""Current Index Rate""",0,5f62cccb668db2340e11a4a6
"SPL-323",silly,coffee,misc,silly,"index=beerme earliest=@d+17h+15m latest=now item=beer OR item=wine OR item=liquor
| lookup nutritioninfo item OUTPUT alcohol_pct
| stats sum(eval((alcohol_pct/100)*qty) as oz_alcohol",0,5f62cccb668db2340e11a4a7
"SPL-104","The idea is to tie ESA emails together by message id.",email,GMC,"The idea is to tie ESA emails together by message id.","index=email
| transaction internal_message_id dcid icid maxevents=100 maxspan=30s endswith=""Message finished""",0,5f62cccb668db2340e11a4a8
"SPL-325","Qualys Active OS Vuln Count",qualys,security,"Qualys Active OS Vuln Count","index=qualys HOSTVULN SEVERITY=3 OR 4 OR 5 TYPE=""CONFIRMED"" earliest=-30d@d
| dedup HOST_ID, QID | search STATUS!=""FIXED""
| join QID [search index=qualys QID_INFO PATCHABLE=1]
| join HOST_ID [search index=qualys HOSTSUMMARY: OS=""Windows*"" NOT ""Windows Server*""
| where cidrmatch(""10.128.0.0/9"", IP) ]
| stats count(QID) as #_Vulns by OS | sort -#_Vulns | addcoltotals #_Vulns",0,5f62cccb668db2340e11a4a9
"SPL-326","To measure the delay between the time stamp of the events and the indexing time (the time that the indexer receives and processes the events), use the following method: Look at the delay in seconds per source for a particular host.
",delay,"splunk_internal","To measure the delay between the time stamp of the events and the indexing time (the time that the indexer receives and processes the events), use the following method: Look at the delay in seconds per source for a particular host.
","source=mysource host=myhost
| eval delay_sec=_indextime-_time
| timechart min(delay_sec) avg(delay_sec) max(delay_sec) by source",0,5f62cccb668db2340e11a4aa
"SPL-327","Index Sizes","pwn,rest","splunk_internal","Index Sizes","| REST /services/data/indexes
| eval currentDBSizeMB=tostring(currentDBSizeMB, ""commas"")
| eval totalEventCount=tostring(totalEventCount, ""commas"")
| eval frozenTimePeriodInHours=(frozenTimePeriodInSecs/60/60)
| table title splunk_server currentDBSizeMB frozenTimePeriodInHours maxTime minTime totalEventCount",0,5f62cccb668db2340e11a4ab
"SPL-328","View audit trail information stored in the local audit index.",audit,"splunk_internal","View audit trail information stored in the local audit index.","| audit",0,5f62cccb668db2340e11a4ac
"SPL-329","Check indexers to see if web access is available","access,web","splunk_internal","Check indexers to see if web access is available","| btool web
| where app!=""learned"" AND ([| inputlookup assets.csv where search_group=""dmc_customgroup_Indexer""
| stats count by host
| fields + host
| rename host AS sos_server
| format])
|  stats dc(app) AS app_count count AS stanza_count sum(linecount) AS setting_count by sos_server
| eventstats mode(stanza_count) AS mode_st mode(setting_count) AS mode_lc mode(app_count) AS mode_app
| eval Status=if(mode_st!=stanza_count OR mode_lc!=setting_count OR mode_app!=app_count,""elevated!!!deviation found"", ""low!!!ok"")
| eval ""Application Deviation""=app_count-mode_app
| eval ""Setting Deviation""=setting_count-mode_lc
| eval ""Stanza Deviation""=stanza_count-mode_st
| fields - mode*
| rename sos_server AS Host app_count AS ""Unique Applications"" stanza_count AS ""Stanza Count"" setting_count AS ""Setting Count""
| sort Status",0,5f62cccb668db2340e11a4ad
"SPL-330","Get a high level summary of your indexes (must be run on the indexer):",index,"splunk_internal","Get a high level summary of your indexes (must be run on the indexer):","| dbinspect",0,5f62cccb668db2340e11a4ae
"SPL-331","Combine dbinspect and REST api data for buckets. The dbinspect API doesn't return consistent information about the size of buckets.","addinfo,append,dbinspect,meta","splunk_internal","Combine dbinspect and REST api data for buckets. The dbinspect API doesn't return consistent information about the size of buckets.","| dbinspect index=*
| foreach *
    [eval dbinspect_FIELD = 'FIELD']
| table dbinspect_*
| append    [
	| rest splunk_server_group=dmc_group_cluster_master ""/services/cluster/master/buckets""
	| foreach *
	    [eval rest_api_FIELD = 'FIELD']
| table rest_api_*    ]
| eval bucketId=if(isNull(rest_api_title),dbinspect_bucketId,rest_api_title)
| stats values(*) as * by bucketId
| foreach rest_api_peers.*.*    [eval rest_api_<<MATCHSEG2>>=""""]
| foreach rest_api_peers.*.*    [eval rest_api_<<MATCHSEG2>>=if (""<<MATCHSEG1>>""=dbinspect_bucketId,'FIELD','<<MATCHSEG2>>')]
| fields - rest_api_peers.*",0,5f62cccb668db2340e11a4af
"SPL-332","Returns information about the buckets in the Splunk index that you specify Returns information about the buckets in the Splunk index that you specify.","audit,buckets,dbinspect","splunk_internal","Returns information about the buckets in the Splunk index that you specify Returns information about the buckets in the Splunk index that you specify.","| dbinspect index=_internal span=1d",0,5f62cccb668db2340e11a4b0
"SPL-333","Create a field whose name is the value of another field.",field,"splunk_internal","Create a field whose name is the value of another field.","| eval {aName}=aValue",0,5f62cccb668db2340e11a4b1
"SPL-334","Count number of events of Splunk processes","events,splunkd","splunk_internal","Count number of events of Splunk processes","| eventcount index=_internal",0,5f62cccb668db2340e11a4b2
"SPL-335","Search to show Raw Data Size, Size of Data on the Disk, and Compression Ratio overall","disk,indexes,pwn","splunk_internal","Search to show Raw Data Size, Size of Data on the Disk, and Compression Ratio overall","| eventcount summarize=false index=* | dedup index | fields index
| map maxsearches=100 search=""|dbinspect index=\""$index$\""| fields rawSize, sizeOnDiskMB, eventCount | table rawSize, sizeOnDiskMB, eventCount""
| stats sum(rawSize) AS rawTotal, sum(sizeOnDiskMB) AS diskTotalinMB, sum(eventCount) AS Total_Events
| eval rawTotalinMB=(rawTotal / 1024 / 1024)
| eval compression=(diskTotalinMB / rawTotalinMB * 100)
| eval Compression_Ratio=tostring(round((100 - compression),2)) + ""%""
| eval Raw_Total_MB=tostring(round(rawTotalinMB,2),""commas"")
| eval OnDisk_Total_MB=tostring(round(diskTotalinMB,4),""commas"")
| eval Total_Events=tostring(Total_Events,""commas"")
| table Total_Events, Raw_Total_MB, OnDisk_Total_MB, Compression_Ratio",0,5f62cccb668db2340e11a4b3
"SPL-336","Indexes an event counts within an app",events,"splunk_internal","Indexes an event counts within an app","| eventcount summarize=false index=* | dedup index | fields index count",0,5f62cccb668db2340e11a4b4
"SPL-337","Clears browser cache.",cache,dev,"Clears browser cache.","| extract reload=t",0,5f62cccb668db2340e11a4b5
"SPL-338","How to move a field through time for prediction purposes.
Align a future value with the features in the past based on some time delta (Time to Decision, Time to Action) for machine learning or predictive analytics in general.","learning,machine,predictive,streamstats",analytics,"How to move a field through time for prediction purposes.
Align a future value with the features in the past based on some time delta (Time to Decision, Time to Action) for machine learning or predictive analytics in general.","| inputlookup SOMECSV
| reverse
| streamstats window=1 current=f first(RemoteAccess) as RemoteAccessFromFuture
| reverse
| ...",0,5f62cccb668db2340e11a4b6
"SPL-339","Create a Normal Curve","bin,eval,makeresults,stats",analytics,"Create a Normal Curve","| makeresults count=50000
| eval r = random() / (pow(2,31)-1)
| eval r2 = random() / (pow(2,31)-1)
| eval normal = sqrt(-2 * ln(r)) * cos(2 * pi() * r2)
| bin normal span=0.1
| stats count by normal
| makecontinuous normal",0,5f62cccb668db2340e11a4b7
"SPL-340","Metadata Searches",meta,"splunk_internal","Metadata Searches","| metadata index=* type=sources",0,5f62cccb668db2340e11a4b8
"SPL-341","Find out what hosts (or sources or sourcetypes) have sent data to Splunk:","hosts,splunkd","splunk_internal","Find out what hosts (or sources or sourcetypes) have sent data to Splunk:","| metadata type=hosts",0,5f62cccb668db2340e11a4b9
"SPL-342","Convert ctime(*Time) to make the epoch time readable:",epoch,"splunk_internal","Convert ctime(*Time) to make the epoch time readable:","| metadata type=hosts
 | convert ctime(*Time)",0,5f62cccb668db2340e11a4ba
"SPL-343","Find Future Time Descrepencies by Host",predict,special,"Find Future Time Descrepencies by Host","| metadata type=hosts index=*
| where lastTime > now()
| eval secondsInFuture=lastTime-now()
| eval hrInFuture=round(secondsInFuture/3600,1)
| sort -secondsInFuture
| table host secondsInFuture hrInFuture",0,5f62cccb668db2340e11a4bb
"SPL-344","What hosts (not forwarder/TCP inputs) have logged an event to Splunk in the last 10 minutes? (Including rangemap.)","hosts,nodata","splunk_internal","What hosts (not forwarder/TCP inputs) have logged an event to Splunk in the last 10 minutes? (Including rangemap.)","| metadata type=hosts index=INDEX
| eval diff=now()-recentTime
| where diff < 600
| convert ctime(*Time)
| stats count
| rangemap field=count low=800-2000 elevated=100-799 high=50-99 server=0-49",0,5f62cccb668db2340e11a4bc
"SPL-345","Hosts within an index Index meta data","host,hosts,index,internal,meta","splunk_internal","Hosts within an index Index meta data","| metadata type=hosts index=_internal",0,5f62cccb668db2340e11a4bd
"SPL-346","List of Host Names without Fully Qualified Domain Names","dns,pwn,security",os,"List of Host Names without Fully Qualified Domain Names","| metadata type=hosts | rex field=host ""(?<shortHost>[^.]+)$"" | rex field=host ""(?<shortHost>[^.]+)\.""
| dedup shortHost
| table shortHost",0,5f62cccb668db2340e11a4be
"SPL-347","Sourcetypes within an index","index,sourcetype","splunk_internal","Sourcetypes within an index","| metadata type=sourcetypes index=""INDEX""",0,5f62cccb668db2340e11a4bf
"SPL-348","Data feed status delay by over 30 minutes.","audit,forwarder","splunk_internal","Data feed status delay by over 30 minutes.","| metadata type=sourcetypes index=*
| search
    [| inputlookup sta_all_sourcetypes.csv
    | fields sourcetype ]
| sort - totalCount
| eval Delay=now()-recentTime
| rangemap default=severe field=Delay low=0-1800
| convert ctime(recentTime) AS ""Last Indexed""
| table range, sourcetype, ""Last Indexed"", Delay, totalCount
| eval Delay=tostring(Delay,""duration"")
| eval totalCount=tostring(totalCount, ""commas"")
| rename totalCount AS Events, range AS Status sourcetype AS Sourcetype
| sort + ""Last Indexed""
| where Status=""severe"" AND NOT match(Sourcetype, ""-(\d+|too_small)$"")",0,5f62cccb668db2340e11a4c0
"SPL-349","Return the values of ""sourcetypes"" for events in the non internal indexes.",sourcetype,"splunk_internal","Return the values of ""sourcetypes"" for events in the non internal indexes.","| metadata type=sourcetypes index=* NOT _internal",0,5f62cccb668db2340e11a4c1
"SPL-350","Return the values of ""sourcetypes"" for events in the ""_internal"" index.",sourcetype,"splunk_internal","Return the values of ""sourcetypes"" for events in the ""_internal"" index.","| metadata type=sourcetypes index=_internal",0,5f62cccb668db2340e11a4c2
"SPL-351","REST Call for Memory & CPU usage on Splunk Servers",REST,"Resource_Usage","REST Call for Memory & CPU usage on Splunk Servers","| rest  /services/server/status/resource-usage/hostwide
| eval cpu_count = if(isnull(cpu_count), ""N/A"", cpu_count)
| eval cpu_usage = cpu_system_pct + cpu_user_pct | eval mem_used_pct = round(mem_used / mem * 100 , 2)
| eval mem_used = round(mem_used, 0) | eval mem = round(mem, 0) |eval mem=tostring(mem, ""commas"")
| eval mem_used=tostring(mem_used, ""commas"")
| fields splunk_server, cpu_count, cpu_usage, mem, mem_used, mem_used_pct
| sort - cpu_usage, -mem_used
| rename splunk_server AS Instance, cpu_count AS ""CPU Cores"", cpu_usage AS ""CPU Usage (%)"", mem AS ""Physical Memory Capacity (MB)"", mem_used AS ""Physical Memory Usage (MB)"", mem_used_pct AS ""Physical Memory Usage (%)""",0,5f62cccb668db2340e11a4c3
"SPL-352","List of fired alerts in Splunk","alerts,pwn","splunk_internal","List of fired alerts in Splunk","| rest /services/alerts/fired_alerts splunk_server=local
| table eai:acl.owner eai:acl.app id title triggered_alert_count",0,5f62cccb668db2340e11a4c4
"SPL-353","Show all currently logged in users","pwn,rest,users","splunk_internal","Show all currently logged in users","| rest /services/authentication/current-context
| search NOT username=splunk-system-user
| table username roles updated",0,5f62cccb668db2340e11a4c5
"SPL-354","Permissions for splunk users
Another view for which splunk user can do what in your splunk environment","permissions,pwn,splunkd","splunk_internal","Permissions for splunk users
Another view for which splunk user can do what in your splunk environment","| rest /services/authentication/users
| mvexpand roles
| table realname, title, roles, email
| join roles [ rest /services/authorization/roles
| rename title as roles
| search srchIndexesAllowed=*
| table roles srchIndexesAllowed]",0,5f62cccb668db2340e11a4c6
"SPL-355","Look for a specific index .","indexes,rest","splunk_internal","Look for a specific index .","| rest /services/data/indexes
| stats sum(totalEventCount) as Events dc(splunk_server) as NumServers by title",0,5f62cccb668db2340e11a4c7
"SPL-356","List of Props.conf Extractions","props,pwn,rest","splunk_internal","List of Props.conf Extractions","| rest /services/data/props/extractions
| table title type value attribute",0,5f62cccb668db2340e11a4c8
"SPL-357","List of extractions in transforms.conf","rest,transforms","splunk_internal","List of extractions in transforms.conf","| rest /services/data/transforms/extractions
| table title eai:appName REGEX FORMAT updated",0,5f62cccb668db2340e11a4c9
"SPL-358","REST Call for a list of Lookup Files","lookup,lookups,rest","splunk_internal","REST Call for a list of Lookup Files","| rest /services/data/transforms/lookups
| table eai:acl.app eai:appName filename title fields_list updated id",0,5f62cccb668db2340e11a4ca
"SPL-359","Detect Clock Skew. If delta is anything other than about 00:00:01 (which is easy to account for when processing a lot of indexers), you may have clock skew.",utils,"splunk_internal","Detect Clock Skew. If delta is anything other than about 00:00:01 (which is easy to account for when processing a lot of indexers), you may have clock skew.","| rest /services/server/info
| eval updated_t=round(strptime(updated, ""%Y-%m-%dT%H:%M:%S%z""))
| eval delta_t=now()-updated_t
| eval delta=tostring(abs(delta_t), ""duration"")
| table serverName, updated, updated_t, delta, delta_t",0,5f62cccb668db2340e11a4cb
"SPL-360","REST Call for Splunk Server Role Status","pwn,role,server,status","splunk_internal","REST Call for Splunk Server Role Status","| rest /services/server/introspection | table title splunk_server status updated",0,5f62cccb668db2340e11a4cc
"SPL-361","Splunk Objects With Permissions Granted to Non-existent Roles","objects,permissions,pwn","splunk_internal","Splunk Objects With Permissions Granted to Non-existent Roles","| rest /servicesNS/-/-/admin/directory count=0 splunk_server=local
 | fields eai:acl.app, eai:acl.owner, eai:acl.perms.*, eai:acl.sharing, eai:location, title
 | eval perms=mvappend('eai:acl.perms.read','eai:acl.perms.write')
 | fields - eai:acl.perms.*
 | mvexpand perms
 | where perms!=""*"" AND NOT
 [
 | rest /servicesNS/-/-/authorization/roles count=0 splunk_server=local
 | fields title
 | rename title as perms
 ]",0,5f62cccb668db2340e11a4cd
"SPL-362","Clears browser cache.",dev,dev,"Clears browser cache.","| rest /servicesNS/-/-/admin/monitor/_reload(splunkURL)/en-us/debug/refresh",0,5f62cccb668db2340e11a4ce
"SPL-363","Clears browser cache.",dev,dev,"Clears browser cache.","| rest /servicesNS/-/-/configs/conf-props/_reload",0,5f62cccb668db2340e11a4cf
"SPL-364","Percentage of Daily License Usage.
This Splunk search query will indicate the percentage of license used for the current day. This is already shown in the licensing tab under settings, however this query is extracted if you would want to use it within a dashboard or any other reason.",license,"splunk_internal","Percentage of Daily License Usage.
This Splunk search query will indicate the percentage of license used for the current day. This is already shown in the licensing tab under settings, however this query is extracted if you would want to use it within a dashboard or any other reason.","| rest splunk_server=* /services/licenser/pools
| rename title AS Pool
| search [rest splunk_server=* /services/licenser/groups
| search is_active=1
| eval stack_id=stack_ids
| fields stack_id]
| eval quota=if(isnull(effective_quota),quota,effective_quota)
| eval ""% used""=round(used_bytes/quota*100,2)
| fields ""% used""",0,5f62cccb668db2340e11a4d0
"SPL-365","Hard Disk Usage and Information on Splunk Server.
The following Splunk Query will utilize a | REST call to gather information related to disk usage on your Splunk server(s). The following has been modified from the Distributed Management Console to be more generic for a copy, paste, and search example.","disk,rest,splunkd","splunk_internal","Hard Disk Usage and Information on Splunk Server.
The following Splunk Query will utilize a | REST call to gather information related to disk usage on your Splunk server(s). The following has been modified from the Distributed Management Console to be more generic for a copy, paste, and search example.","| rest splunk_server=* /services/server/status/partitions-space
| eval free = if(isnotnull(available), available, free)
| eval usage = round((capacity - free) / 1024, 2) | eval capacity = round(capacity / 1024, 2)
| eval compare_usage = usage."" / "".capacity | eval pct_usage = round(usage / capacity * 100, 2)
| stats first(fs_type) as fs_type first(compare_usage) as compare_usage first(pct_usage) as pct_usage by mount_point, splunk_server
| rename mount_point as ""Mount Point"", fs_type as ""File System Type"", compare_usage as ""Disk Usage (GB)"", capacity as ""Capacity (GB)"", pct_usage as ""Disk Usage (%)"" splunk_server as ""Splunk Server""
| sort - ""Splunk Server""",0,5f62cccb668db2340e11a4d1
"SPL-366","Memory Usage and Information on Splunk Server",MEM,"Resource_Usage","Memory Usage and Information on Splunk Server","| rest splunk_server=* /services/server/status/resource-usage/hostwide
| stats first(normalized_load_avg_1min) as load_average first(cpu_system_pct) as system, first(cpu_user_pct) as user first(mem) AS mem first(mem_used) AS mem_used by splunk_server
| fields splunk_server mem mem_used
| eval pctmemused=round((mem_used/mem)*100).""%""
| table splunk_server pctmemused
| rename splunk_server as ""Splunk Server"" pctmemused as ""Percent of Memory Used""",0,5f62cccb668db2340e11a4d2
"SPL-367","Memory Usage and Information on Splunk Server",memory,"splunk_internal","Memory Usage and Information on Splunk Server","| rest splunk_server=* /services/server/status/resource-usage/hostwide
| stats first(normalized_load_avg_1min) as load_average first(cpu_system_pct) as system, first(cpu_user_pct) as user first(mem) AS mem first(mem_used) AS mem_used by splunk_server | fields splunk_server mem mem_used
| eval pctmemused=round((mem_used/mem)*100).""%""
| table splunk_server pctmemused
| rename splunk_server as ""Splunk Server"" pctmemused as ""Percent of Memory Used""",0,5f62cccb668db2340e11a4d3
"SPL-368","Address unnecessarily frequent scheduled searches and overall unnecessary searches.","audit,searches","splunk_internal","Address unnecessarily frequent scheduled searches and overall unnecessary searches.","| rest splunk_server=* /servicesNS/-/-/admin/savedsearch/ earliest_time=-0s@s latest_time=+2d@d search=""is_scheduled=1"" search=""disabled=0""
| table splunk_server eai:acl.app eai:acl.owner cron_schedule title scheduled_times
| mvexpand scheduled_times
| rename scheduled_times as _time eai:acl.app as app eai:acl.owner as user title as search
| stats count(search) as count by search cron_schedule app
| sort 20 -count",0,5f62cccb668db2340e11a4d4
"SPL-369","Search to show what apps are ready to be updated",app,"splunk_internal","Search to show what apps are ready to be updated","| rest splunk_server=local /services/apps/local
| search update.version=* | table title version update.version",0,5f62cccb668db2340e11a4d5
"SPL-370","Splunk License Gauge",license,"splunk_internal","Splunk License Gauge","| rest splunk_server=local /services/licenser/pools
| rename title AS Pool
| search [rest splunk_server=local /services/licenser/groups
| search is_active=1
| eval stack_id=stack_ids
| fields stack_id]
| join type=outer stack_id [rest splunk_server=local /services/licenser/stacks | eval stack_id=title
| eval stack_quota=quota | fields stack_id stack_quota]
| stats sum(used_bytes) as used max(stack_quota) as total
| eval usedGB=round(used/1024/1024/1024,3)
| eval totalGB=round(total/1024/1024/1024,3)
| eval gauge_base=0
| eval gauge_danger=totalGB*0.8
| eval gauge_top=totalGB+0.001
| gauge usedGB gauge_base gauge_danger totalGB gauge_top",0,5f62cccb668db2340e11a4d6
"SPL-371","Get information on all indexes.","_internal","splunk_internal","Get information on all indexes.","| rest splunk_server=local /servicesNS/-/-/configs/conf-indexes
| rename eai:appName as app eai:acl.sharing as sharing
| table app sharing author title homePath coldPath thawedPath frozenTimePeriodInSecs maxDataSize maxHotBuckets maxTotalDataSizeMB
| foreach * [eval FIELD = if(len(FIELD)>0, 'FIELD', ""-"")]
| join app type=left [| rest splunk_server=local /servicesNS/-/-/apps/local
| rename title as app label as app_label
| table app app_label]
| eval app_label = if(isnotnull(app_label), app_label, app)",0,5f62cccb668db2340e11a4d7
"SPL-372","Dashboards that have not been viewed in over 21 days or are orphaned.","audit,dashboard","splunk_internal","Dashboards that have not been viewed in over 21 days or are orphaned.","| rest splunk_server=local /servicesNS/-/-/data/ui/views
| stats count values(eai:acl.sharing) values(eai:acl.owner) AS owner by title, eai:acl.app
| rename eai:acl.app AS app
| eval last_view_time_days_ago=-1
| eval last_view_time_days_ago_pretty=""no views in last 30 days""
| join type=outer title app
    [ search index=""_internal"" sourcetype=splunk_web_access GET app earliest=-30d@d
    | rex ""GET /[^/]+/app/(?<app>[^/ ?]+)/(?<title>[^\/\?\s]+)""
    | search app=* AND title=* AND user=* AND user!=""-""
    | stats latest(_time) AS last_view_time latest(user) AS last_user by app, title
    | eval last_view_time_days_ago=round(abs(now()-last_view_time),0)
    | eval last_view_time_days_ago_pretty=tostring(last_view_time_days_ago, ""duration"")
    | convert ctime(last_view_time)]
| where last_view_time_days_ago > (60*60*24*21) OR last_view_time_days_ago=-1",0,5f62cccb668db2340e11a4d8
"SPL-373","Review alerts that are not returning results to ensure ""no results"" is the expected/desired outcome.","alerts,audit","splunk_internal","Review alerts that are not returning results to ensure ""no results"" is the expected/desired outcome.","| rest splunk_server=local /servicesNS/-/-/saved/searches
| where is_scheduled=1 AND disabled=0
| stats values(splunk_server) by title, eai:acl.owner, eai:acl.app, cron_schedule
| join type=outer title
    [ search index=_internal sourcetype=scheduler result_count earliest=-30d@d
    | extract pairdelim="","", kvdelim=""="", auto=f
    | stats avg(result_count) min(result_count) max(result_count), sparkline(avg(result_count)) AS sparkline avg(run_time) by savedsearch_name
    | rename savedsearch_name AS title]
| makemv delim="","" setsv=true sparkline
| where 'max(result_count)' = 0
| sort - avg(run_time)
| search title!=""Missing Data*"" (eai:acl.app=search OR eai:acl.app=CDC-*)",0,5f62cccb668db2340e11a4d9
"SPL-374","Multiple indexes getting full without reaching retention policy.","audit,index","splunk_internal","Multiple indexes getting full without reaching retention policy.","| rest splunk_server_group=dmc_group_indexer /services/data/indexes search=""totalEventCount!=0""
| eval coldPath.maxDataSizeMB=if('coldPath.maxDataSizeMB' = 0, null(), 'coldPath.maxDataSizeMB')
| eval homePath.maxDataSizeMB=if('homePath.maxDataSizeMB' = 0, null(), 'homePath.maxDataSizeMB')
| eval roof=min((coalesce('homePath.maxDataSizeMB', 4294967295) + coalesce('coldPath.maxDataSizeMB', 4294967295)), maxTotalDataSizeMB)
| eval span=tostring(currentDBSizeMB) + "" / "" + tostring(roof) + "" MB""
| eval PercentFull=tostring(round(currentDBSizeMB * 100 / roof)) + ""%""
| eval ""Total Events""=tostring(totalEventCount,""commas"")
| stats first(span) AS ""Capacity vs Limit"" by splunk_server title minTime maxTime ""Total Events"" PercentFull
| rename splunk_server AS Indexer title AS Index minTime AS ""Oldest Event"" maxTime AS ""Newest Event""
| table Indexer Index ""Capacity vs Limit"" ""Oldest Event"" ""Newest Event"" ""Total Events"" PercentFull
| sort Index, Indexer, -PercentFull
| where match(PercentFull, ""^(10|9|8).%"")",0,5f62cccb668db2340e11a4da
"SPL-375","Forwarder Diagnostics  Last time Data Was Received by Index and Sourcetype.",trouble,"splunk_internal","Forwarder Diagnostics  Last time Data Was Received by Index and Sourcetype.","| tstats latest(_time) as Latest by host sourcetype index
| eval current=now()
| eval Minimum_Age=round(((current-Latest)/60)/60,2)
| rangemap field=Minimum_Age default=Critical Normal=0-0.5 Elevated=0.5-2 Warning=2-4
| eval stIDX=tostring(index) + "" -- "" + tostring(sourcetype)
| stats values(stIDX) as ""Index -- Sourcetype"" list(Latest) as ""Latest Event"" list(Minimum_Age) as Minimum_Age list(range) as Threshold by host
| convert ctime(""Latest Event"")
| eventstats avg(Minimum_Age) as average by host
| eval average=round(average,2)
| sort - average
| rename Minimum_Age as ""Hours Since Last Communication"" average as ""Average Time in Hours Since Last Communication""",0,5f62cccb668db2340e11a4db
"SPL-376","WEB CIM data model predict web request durations","cim,predict",misc,"WEB CIM data model predict web request durations","| tstats summariesonly=t perc95(web_request.wDuration) AS estPC95, perc90(web_request.wDuration) AS estPC90, perc50(web_request.wDuration) AS estPC50 from datamodel=""web"" where (nodename=""web_request"") groupby ""_time"" span=1m
| fields _time, estPC*",0,5f62cccb668db2340e11a4dc
"SPL-377","Typeahead values for an index.",typeahead,"splunk_internal","Typeahead values for an index.","| typeahead prefix=source count=10 index=_internal",0,5f62cccb668db2340e11a4dd
"GMC-042","Jobs with Duplicate search strings","GMC,Duplicates,Health_Assessments","Scheduled_Jobs","","| from lookup:splunk_rest_saved_searches_sh_kv_store_lookup
| where is_scheduled=1 AND disabled=0 AND ! savedsearch_name LIKE ""%_ScheduledView_%""
| search NOT app IN (splunk_instance_monitoring)
| fields shcluster_label app author savedsearch_name savedsearch_search
| stats values(*) As * count by savedsearch_search
| where count > 1
| sort 0 - count
| table shcluster_label app author savedsearch_name count savedsearch_search",0,5f695f6f668db21d69524481
"GMC-043","Job Naming Convention Based on GMC Identity data","GMC,Naming_Convention","Scheduled_Jobs","naming convention and used Logic to determine Ranking of 1-10, where 1 has the highest priority.  1-10 gives us full flexibility and better than low/medium/high because users normally will choose either high or super high","| from lookup:splunk_rest_saved_searches_sh_kv_store_lookup 
| where is_scheduled=1 AND disabled=0 AND shcluster_label = ""*"" 
| search NOT app IN (splunk_instrumentation, splunk_monitoring_console, splunk_archiver, simple_xml_examples, *global_monitoring_console, Centrify, Code42ForSplunk, SA-nix, Splunk_TA_*, cisco-app-ACI, splunk_app_*, website_monitoring, analysis_of_splunkbase_apps, chargeback) 
| `get_identity_info(author)` 
| stats Last(emp_lob2) as emp_lob2 Last(emp_dep) as Department by shcluster_label app sharing author savedsearch_type savedsearch_name 
| eval savedsearch_name_org=savedsearch_name 
| eval savedsearch_name=upper(trim(savedsearch_name)) 
| rex field=emp_lob2 mode=sed ""s/\s+/-/g"" 
| rex field=savedsearch_name mode=sed ""s/\s+/-/g"" 
| rex field=savedsearch_name mode=sed ""s/[^[:ascii:]]//g"" 
| rex field=savedsearch_name mode=sed ""s/[^a-zA-Z_\d-]/-/g"" 
| rex field=emp_lob2 mode=sed ""s/[^a-zA-Z_\d-]/-/g"" 
| rex field=savedsearch_name mode=sed ""s/-{2,}/-/g"" 
| rex field=emp_lob2 mode=sed ""s/-{2,}/-/g"" 
| eval savedsearch_name=trim(savedsearch_name,""-"") , emp_lob2=trim(emp_lob2,""-"") 
| eval Ranking = case(
    Match(savedsearch_name,""DEVELOPMENT""), ""9"",
    Match(savedsearch_name,""REPORT""), ""9"",
    Match(savedsearch_name,""TEST""), ""9"",
    Match(savedsearch_name,""WARNING|WARN""), ""6"",
    Match(savedsearch_name,""SECURITY"") OR Match(emp_lob2,""Cybersecurity""), ""1"",
    Match(savedsearch_name,""ALERT""), ""2"",
    Match(savedsearch_name,""ERROR""), ""3"",
    Match(savedsearch_name,""_SCHEDULEVIEW_""), ""6"",
    Match(savedsearch_name,""CLAIM""), ""4"",
    Match(savedsearch_name,""PROD""), ""6"",
    Match(savedsearch_name,""FAIL""), ""5"",
    Match(savedsearch_name,""COVID19""), ""2"",
    Match(savedsearch_name,""PAYMENT|BILLING""), ""3"",
    Match(savedsearch_name,""POLICY""), ""4"",
    Match(savedsearch_name,""CRITICAL""), ""2"",
    Match(savedsearch_name,""LOGON|ACCOUNT|AGENCY""), ""3"",
    Match(savedsearch_name,""AKAMAI""), ""3"",
    Match(savedsearch_name,""TIMEOUT|TIMED-OUT""), ""3"",
    Match(savedsearch_name,""MEMORY""), ""3"",
    Match(savedsearch_name,""STUCK|EXCEPTION""), ""3"",
    Match(savedsearch_name,""404""), ""3"",
    Match(savedsearch_name,""FIREWALL""), ""3"",
    Match(savedsearch_name,""FINANCE|STOPPED|CLEARED|VOIDED""), ""3"",
    Match(savedsearch_name,""MAJOR|DOWN|ON-FIRE|NOT-RUNNING|UNAVAILABLE""), ""3"",
    Match(savedsearch_name,""MINOR""), ""5"",
    true(), 10) 
| eval New_savedsearch_name = Ranking . "":"" . emp_lob2 . "":"" . savedsearch_name 
| stats count by Ranking New_savedsearch_name savedsearch_name_org",0,5f69607b668db21d69524482
"GMC-044","Report on Splunk Server Environment","Assets,Ulimits,Memory,CPU,Health_Assessments",Infrastructure,"Generates a report on all configured Splunk Instances with complete detail information about the hardware specs","| from lookup:splunk_rest_assets_kv_store_lookup 
| eval isForwarding = if (match(Splunk_Roles, ""indexer""), ""N/A"", isForwarding) 
| eval Memory = round (physicalMemoryMB / 1024, 2) 
| table _time *_label Splunk_Instance serverName Splunk_Roles host* version build guid cpu_arch numberOfCores numberOfVirtualCores Memory os_* startup_time isForwarding ulimits_* ulimits_stack_size transparent_* appServerPorts dfsDisabled dfsMasterPort enableSplunkWebSSL httpport kvStoreDisabled kvStorePort mgmtHostPort minFreeSpace sessionTimeout startwebserver trustedIP SPLUNK_* rtsearch_enabled mode master_uri master_guid kvStoreStatus *",0,5f741103668db21c9550c7f1
"GMC-045","Report on Splunk Search Head Cluster Node configuration details","GMC,SHC,Clustering,Health_Assessments",Infrastructure,"","| from lookup:splunk_rest_shcluster_config_shc_kv_store_lookup 
| table shcluster_label Splunk_Instance mode conf_deploy_fetch_url adhoc_searchhead replication_factor replication_port replication_use_ssl async_replicate_on_proxy register_replication_address captain_is_adhoc_searchhead decommission_search_jobs_wait_secs dynamic_captain heartbeat_period manual_detention max_peer_rep_load percent_peers_to_restart ping_flag preferred_captain quiet_period rolling_restart cxn_timeout heartbeat_timeout rcv_timeout send_timeout rep_cxn_timeout rep_max_rcv_timeout rep_max_send_timeout rep_rcv_timeout rep_send_timeout restart_timeout *",0,5f7411fb668db21c9550c7f2
"GMC-046","Report on Splunk Search Head Concurrency Settings","GMC,SHC,Concurrency,Health_Assessments",Infrastructure,"","| from lookup:splunk_rest_admin_search_concurrency_settings_handler_sh_kv_store_lookup 
| table _time shcluster_label Splunk_Instance max_hist_scheduled_searches base_max_searches max_searches_per_cpu max_searches_perc max_hist_searches max_auto_summary_searches auto_summary_perc max_rt_scheduled_searches max_rt_searches max_rt_search_multiplier",0,5f7412ff668db21c9550c7f3
"GMC-047","Report on Assets Mount Points & Capacity","Capacity,Disk,Health_Assessments",Infrastructure,"","index=_introspection sourcetype=splunk_disk_objects component=Partitions search_group=*
| rename data.* as * , host As Splunk_Instance 
| fields _time Splunk_Instance mount_point fs_type available capacity free 
| eval free = if(isnotnull(available), available, free) 
| `get_idxcluster_label(Splunk_Instance)` 
| fillnull value=""Undefined"" idxcluster_label 
| stats latest(*) as * by idxcluster_label Splunk_Instance mount_point 
| `gmc_mb2human(capacity,2)` 
| `gmc_mb2human(free,2)` 
| rename free As free_MB capacity As capacity_MB 
| table idxcluster_label Splunk_Instance mount_point fs_type capacity_GB free_GB",0,5f741432668db21c9550c7f4
"GMC-048","Report on all data being forwarded by UFs with sourcetypes configuration details","Sourcetypes,DataOnboarding,UF,Health_Assessments",Sourcetypes,"","| tstats count dc(source) As Num_Sources where index=* AND earliest=-4h@h by index sourcetype host 
| rename host As uf 
| join uf 
    [ search index=_internal sourcetype=splunkd (search_group=dmc_group_indexer OR host=idx-i-*) fwdType=uf earliest=-15m@m 
    | rename hostname As uf 
    | fields uf ] 
| stats count As Num_Events Last(Num_Sources) As Num_Sources dc(uf) As Num_UFs by index sourcetype 
| `get_sourcetype_info(sourcetype)` 
| fillnull value=""auto"" KV_MODE 
| fillnull value=""128"" MAX_TIMESTAMP_LOOKAHEAD 
| fillnull value=""0"" EVENT_BREAKER_ENABLE 
| fillnull value=""1"" ANNOTATE_PUNCT LEARN_MODEL SHOULD_LINEMERGE LEARN_SOURCETYPE BREAK_ONLY_BEFORE_DATE ADD_EXTRA_TIME_FIELDS AUTO_KV_JSON PREFIX_SOURCETYPE 
| fillnull value=""10000"" TRUNCATE 
| fillnull value=""^"" TIME_PREFIX 
| fillnull value=""([\r\n]+)"" LINE_BREAKER 
| fillnull value=""\r\n"" EVENT_BREAKER 
| fillnull value=""/etc/datetime.xml"" DATETIME_CONFIG 
| fillnull value=""not-set"" INDEXED_EXTRACTIONS 
| fillnull value=""UTF-8"" CHARSET 
| fillnull value=""endpoint_md5"" CHECK_METHOD 
| fillnull value=""1000"" DEPTH_LIMIT 
| fillnull value=""100"" LINE_BREAKER_LOOKBEHIND 
| fillnull value=""100000"" MATCH_LIMIT 
| fillnull value=""2000"" MAX_DAYS_AGO 
| fillnull value=""2"" MAX_DAYS_HENCE 
| fillnull value=""3600"" MAX_DIFF_SECS_AGO 
| fillnull value=""604800"" MAX_DIFF_SECS_HENCE 
| table index sourcetype Num_UFs Num_Sources Num_Events app author category updated sharing LINE_BREAKER SHOULD_LINEMERGE TRUNCATE TIME_PREFIX TIME_FORMAT MAX_TIMESTAMP_LOOKAHEAD TZ EVENT_BREAKER_ENABLE EVENT_BREAKER KV_MODE LEARN_MODEL LEARN_SOURCETYPE MUST_BREAK_AFTER BREAK_ONLY_BEFORE",0,5f748dba668db21c9550c7f5
"GMC-049","Cloud Search Head Cluster Members Job Execution details with Skip Ratio","Skips,Health_Assessments","Scheduled_Jobs","This search only looks at the Stack SHC Members excluding the captain and does the calculation","index=customer_internal sourcetype=scheduler stack=<Stack Name> host=sh*.splunkcloud.com shcluster_member=1 status IN (success,skipped) earliest=-4h@h latest=-0h@h search_type!=*_acceleration 
| timechart span=5m
    count(eval(status==""success"")) AS COMP_EXEC
    count(eval(status==""skipped"")) AS Skipped_EXEC
    count(eval(status==""success"" OR status==""skipped"")) AS TOT_EXEC 
| eval Skip_Ratio = round ( ( Skipped_EXEC / TOT_EXEC ) * 100, 0) 
| fields - TOT_EXEC",0,5f762fc1668db21c9550c7f6
"GMC-050","Report on user successful logins or user logged in and active",User,SPL,"","host=< Search Heads to search> ( (index=_audit sourcetype=audittrail) AND (user=* ""action=login attempt"" info=succeeded) ) OR (user=* NOT user IN (""n/a"",splunk-system-user) action=search info=granted search_id!=""rsa_*"" search=*) OR (index=_internal sourcetype=splunkd_ui_access useragent=* status=200 user!=""-"" ) 
| eval search_type = if(match(search_id, ""\d{10}\.\d+(_[0-9A-F]{8}-[0-9A-F]{4}-[0-9A-F]{4}-[0-9A-F]{4}-[0-9A-F]{12})?$""), ""adhoc"", ""other"") 
| search info=""succeeded"" OR search_type=""adhoc"" OR (index=_internal sourcetype=splunkd_ui_access useragent=* status=200 user!=""-"")",0,5f763cb8668db21c9550c7f7
"GMC-051","Report on Role Configurations","Roles,RBAC,User,Health_Assessments",Infrastructure,"","| inputlookup splunk_rest_authorization_roles_sh_kv_store_lookup 
| table shcluster_label title
    srchJobsQuota imported_srchJobsQuota cumulativeSrchJobsQuota 
    rtSrchJobsQuota imported_rtSrchJobsQuota cumulativeRTSrchJobsQuota 
    srchDiskQuota imported_srchDiskQuota 
    imported_roles grantable_roles splunk_role_map ldap_group_type ldap_group_name auth_type 
    defaultApp deleteIndexesAllowed 
    srchFilter imported_srchFilter
    srchTimeWin imported_srchTimeWin 
    srchIndexesAllowed imported_srchIndexesAllowed srchIndexesDefault imported_srchIndexesDefault",0,5f767a76668db21c9550c7f8
"GMC-052","Report on Dashboards being used","Dashboards,Health_Assessments",Dashboards,"","host=<ITSI Search Heads> index=_internal sourcetype=splunk_web_access method=GET status=200 user!=""-"" 
| fields _time host search_group app view user spent 
| stats earliest(_time) As Earliest_Access latest(_time) As Latest_Access Values(user) As User BY app view 
| rename view As Dashboard_Name 
| convert ctime(*_Access) 
| table app Dashboard_Name User Earliest_Access Latest_Access",0,5f76812d668db21c9550c7f9
"GMC=059","Report om Indexer Cluster Configurations","Indexers,Cluster","Indexer_Cluster","","| inputlookup splunk_rest_cluster_config_idx_kv_store_lookup 
| stats Last(*) As * Last(_time) As _time by idxcluster_label 
| table _time idxcluster_label forwarderdata_rcv_port guid mode access_logging_for_heartbeats allowed_hbmiss_count cxn_timeout decommission_node_force_timeout decommission_search_jobs_wait_secs disabled forwarderdata_use_ssl frozen_notifications_per_batch heartbeat_period heartbeat_timeout manual_detention max_auto_service_interval max_fixup_time_ms max_peer_build_load max_peer_rep_load max_peer_sum_rep_load max_peers_to_download_bundle max_primary_backups_per_service notify_scan_min_period notify_scan_period percent_peers_to_restart ping_flag quiet_period rcv_timeout register_forwarder_address register_replication_address register_search_address remote_storage_upload_timeout rep_cxn_timeout rep_max_rcv_timeout rep_max_send_timeout rep_rcv_timeout rep_send_timeout replication_factor replication_port replication_use_ssl report_remote_storage_bucket_upload_to_targets reporting_delay_period restart_timeout search_factor search_files_retry_timeout send_timeout service_interval site warm_bucket_replication_pre_upload",0,5f769848668db21c243feef1
"GMC-053","Jobs with Duplicate Names","Duplicates,Health_Assessments","Scheduled_Jobs","","| from lookup:splunk_rest_saved_searches_sh_kv_store_lookup
| where is_scheduled=1 AND disabled=0 AND ! savedsearch_name LIKE ""%_ScheduledView_%""
| search NOT app IN (splunk_instance_monitoring,splunk_instrumentation)
| fields shcluster_label app author savedsearch_name savedsearch_search
| stats values(*) As * count by savedsearch_name
| where count > 1
| sort 0 - count
| table shcluster_label app author savedsearch_name count savedsearch_search",0,5f777bc0668db21c243feef2
"GMC-054","Report on indexer queue fill-up","Indexer,Queues,Health_Assessments","Indexer_Cluster","","| rest splunk_server_group=dmc_group_indexer splunk_server_group=""*"" /services/server/introspection/queues 
| search title=parsingQueue* OR title=aggQueue* OR title=typingQueue* OR title=indexQueue* 
| eval fill_perc=round(current_size_bytes / max_size_bytes * 100,2) 
| fields splunk_server, title, fill_perc 
| rex field=title ""(?<queue_name>^\w+)(?:\.(?<pipeline_number>\d+))?"" 
| eval fill_perc = if(isnotnull(pipeline_number), ""pset"".pipeline_number."": "".fill_perc, fill_perc) 
| chart values(fill_perc) over splunk_server by queue_name 
| eval pset_count = mvcount(parsingQueue) 
| join type=outer splunk_server 
    [| rest splunk_server_group=dmc_group_indexer splunk_server_group=""*"" /services/server/introspection/indexer 
    | eval average_KBps = round(average_KBps, 0) 
    | eval status = if((reason == ""."") OR (reason == """") OR isnull(reason), status, status."": "".reason) 
    | fields splunk_server, average_KBps, status] 
| fields splunk_server pset_count average_KBps status parsingQueue aggQueue typingQueue indexQueue 
| sort -average_KBps 
| rename splunk_server as Instance, pset_count as ""Pipeline Set Count"", average_KBps as ""Indexing Rate (KB/s)"", status as ""Status"", parsingQueue as ""Parsing Queue Fill Ratio (%)"", aggQueue as ""Aggregation Queue Fill Ratio (%)"", ""typingQueue"" as ""Typing Queue Fill Ratio (%)"", indexQueue as ""Indexing Queue Fill Ratio (%)""",0,5f77e328668db21c243feef3
"GMC-055","Persistent High Index Queue","Indexer,Queues,Health_Assessments","Indexer_Cluster","","(index=_internal source=*metrics.log sourcetype=splunkd group=queue (name=aggqueue OR name=indexqueue OR name=parsingqueue OR name=typingqueue)) 
| eval ingest_pipe=if(isnotnull(ingest_pipe),ingest_pipe,""none"") 
| search ingest_pipe=* 
| eval max=if(isnotnull(max_size_kb),max_size_kb,max_size), curr=if(isnotnull(current_size_kb),current_size_kb,current_size), fill_perc=round(((curr / max) * 100),2) 
| bin _time span=3m 
| stats MAX(fill_perc) as maxQueue by _time host name 
| where maxQueue>90 
| stats count as highQueueCount, values(maxQueue) as maxQueue by host name 
| where highQueueCount>15 
| rename name as data_path, host as dest, highQueueCount as count 
| eval meta_alert_name=""Persistent High Index Queue""",0,5f77e74c668db21c243feef4
"GMC-056","Blocked Queues","Indexer,Queues,Health_Assessments","Indexer_Cluster","","index=_internal source=*metrics.log sourcetype=splunkd group=queue 
| eval max=if(isnotnull(max_size_kb),max_size_kb,max_size) 
| eval curr=if(isnotnull(current_size_kb),current_size_kb,current_size) 
| eval fill_perc=round((curr/max)*100,2) 
| where fill_perc>=99.0 
| bucket _time span=1m 
| stats count as blockedcount by host name _time 
| eval name=case(name==""aggqueue"",""2 - Aggregation Queue"",name==""indexqueue"",""4 - Indexing Queue"",name==""parsingqueue"",""1 - Parsing Queue"",name==""typingqueue"",""3 - Typing Queue"", 1=1, name) 
| eval blockedpercentage=((blockedcount*100)/2) 
| rex field=host ""^.*\.(?<ddc>\w+)\.expertcity.com"" 
| eval dc=coalesce(ddc,""NoFQDN"") 
| eval dc-queue=dc+""-""+name 
| chart useother=F avg(blockedpercentage) as blocked_percentage by _time, dc-queue",0,5f77e774668db21c243feef5
"GMC-057","Report on aborted Jobs related to Workload Management Rules deployed","Workload,Abort,Health_Assessments","Scheduled_Jobs","","index=_internal sourcetype=splunkd component=WorkloadManager 
| rex ""workload\s+rule\s+(?<workload_rule>.*?)\."" 
| rex ""The\s+search\s+(?<sid>.*?)\s"" 
| fields _time host sid workload_rule event_message 
| join sid 
    [ search index=_internal sourcetype=scheduler sid=* 
    | fields _time host sid user app savedsearch_name scheduled_time dispatch_time workload_pool] 
| stats count As Num_Aborts latest(_time) As _time latest(*) As * By app user savedsearch_name 
| `get_saved_searches_info(savedsearch_name)` 
| `strftime_format(_time)` 
| `strftime_format(updated)` 
| table _time savedsearch_name workload_rule workload_pool event_message app savedsearch_type cron_schedule updated allow_skew dispatch_earliest_time dispatch_latest_time Num_Aborts",0,5f78dd8e668db25f33344d91
"GMC-058","Report on All Splunk Messages Across the entire environment in the past 24 Hours","Errors,Messages,Health_Assessments",Health,"","index=`gmc_setup_summary_index` search_name=""splunk_rest_messages_sh_summary_tracker"" earliest=-24h@h latest=now 
| stats 
    Latest(*) As *
    Latest(timeCreated_epochSecs) As timeCreated
    By server message 
| `strftime_format(timeCreated)` 
| table timeCreated search_name server message help message_alternate severity",0,5f78f4ba668db25f33344d92
"GMC-059","Generate a list of all App Names executing jobs on the Indexer Cluster from the ITSI SHC","ITSI,Health_Assessments","Scheduled_Jobs","Note: remove ""data.search_props.search_head""=<Search Head Cluster Hosts> to report on all Apps across the Cluster coming in from every search head in the environment.","host=<Indexer Cluster Hosts> ""data.search_props.search_head""=<Search Head Cluster Hosts> index=_introspection sourcetype=splunk_resource_usage component=PerProcess earliest=-24h@h 
| rename ""data.*"" as ""*"", ""search_props.*"" as ""*"" 
| stats values(app) As Apps
| eval Apps=mvjoin(Apps,"","")",0,5f79ffe9668db25f33344d93
"GMC-060","Normalized CPU Usage of searches running on the Indexer Tier originating on the ITSI SHC","ITSI,Health_Assessments","Scheduled_Jobs","Normalized CPU %: Percentage of CPU usage across all cores. 100% is equivalent to all CPU resources on the machine.
Note: replace <Search Head Cluster> with a value that will find searches originating from the ITSI search cluster.  This is usually the host name of all SH Cluster Members, you can use a wild card.  Do the same for host but this needs to be all indexers in production.","host=<Indexer Cluster Hosts> ""data.search_props.search_head""=<Search Head Cluster Hosts> index=_introspection sourcetype=splunk_resource_usage component=PerProcess earliest=-24h@h 
| fields _time data.* host 
| rename ""data.*"" as ""*"", ""search_props.*"" as ""*"" 
| eval app_type=case(
    match(app,""ITSI|SA-ITOA|SA-UserAccess|itsi""), ""ITSI Apps"",
    match(app,""splunk_app_infrastructure""), ""Infrastructure App"",
    match(app,""Splunk_ML_Toolkit""), ""MLTK App"",
    match(app,""custom_app""), ""Custom Apps"",
    true(), ""Other Apps"") 
| timechart span=5m Avg(normalized_pct_cpu) AS AvgNormCPU Perc90(normalized_pct_cpu) As P90NormCPU Perc95(normalized_pct_cpu) As P95NormCPU
| foreach AvgNormCPU P90NormCPU P95NormCPU 
    [ eval <<FIELD>>=round('<<FIELD>>', 2)]",0,5f7a0035668db25f33344d94
"GMC-061","Normalized CPU Usage of searches running on the Indexer Tier originating on the ITSI SHC Splitting by App Types","ITSI,Health_Assessments","Scheduled_Jobs","","host=<Indexer Cluster Hosts> ""data.search_props.search_head""=<Search Head Cluster Hosts> index=_introspection sourcetype=splunk_resource_usage component=PerProcess earliest=-24h@h 
| fields _time data.* host 
| rename ""data.*"" as ""*"", ""search_props.*"" as ""*"" 
| eval app_type=case(
    match(app,""ITSI|SA-ITOA|SA-UserAccess|itsi""), ""ITSI Apps"",
    match(app,""splunk_app_infrastructure""), ""Infrastructure App"",
    match(app,""Splunk_ML_Toolkit""), ""MLTK App"",
    match(app,""custom_app""), ""Custom Apps"",
    true(), ""Other Apps"") 
| timechart span=5m Avg(normalized_pct_cpu) AS AvgNormCPU Perc90(normalized_pct_cpu) As P90NormCPU Perc95(normalized_pct_cpu) As P95NormCPU By app_type
| foreach AvgNormCPU P90NormCPU P95NormCPU 
    [ eval <<FIELD>>=round('<<FIELD>>', 2)]",0,5f7a0067668db25f33344d95
"GMC-062","Normalized CPU Usage of searches running on the Indexer Tier from everywhere Splitting by Search Head","ITSI,Health_Assessments","Scheduled_Jobs","ITSI vs the whole world","host=<Indexer Cluster Hosts> index=_introspection sourcetype=splunk_resource_usage component=PerProcess earliest=-24h@h 
| fields _time data.* host 
| rename ""data.*"" as ""*"", ""search_props.*"" as ""*"" 
| eval app_type=case(
    match(app,""ITSI|SA-ITOA|SA-UserAccess|itsi""), ""ITSI Apps"",
    match(app,""splunk_app_infrastructure""), ""Infrastructure App"",
    match(app,""Splunk_ML_Toolkit""), ""MLTK App"",
    match(app,""custom_app""), ""Custom Apps"",
    true(), ""Other Apps"") 
| timechart span=5m Avg(normalized_pct_cpu) AS AvgNormCPU Perc90(normalized_pct_cpu) As P90NormCPU Perc95(normalized_pct_cpu) As P95NormCPU By search_head
| foreach AvgNormCPU P90NormCPU P95NormCPU 
    [ eval <<FIELD>>=round('<<FIELD>>', 2)]",0,5f7a008f668db25f33344d96
"GMC-063","Normalized CPU Usage of searches running on the Indexer Tier from everywhere Splitting by App Type","ITSI,Health_Assessments","Scheduled_Jobs","ITSI vs the whole world","host=<Indexer Cluster Hosts> index=_introspection sourcetype=splunk_resource_usage component=PerProcess earliest=-24h@h 
| fields _time data.* host 
| rename ""data.*"" as ""*"", ""search_props.*"" as ""*"" 
| eval app_type=case(
    match(app,""ITSI|SA-ITOA|SA-UserAccess|itsi""), ""ITSI Apps"",
    match(app,""splunk_app_infrastructure""), ""Infrastructure App"",
    match(app,""Splunk_ML_Toolkit""), ""MLTK App"",
    match(app,""custom_app""), ""Custom Apps"",
    true(), ""Other Apps"") 
| timechart span=5m Avg(normalized_pct_cpu) AS AvgNormCPU Perc90(normalized_pct_cpu) As P90NormCPU Perc95(normalized_pct_cpu) As P95NormCPU By app_type
| foreach AvgNormCPU P90NormCPU P95NormCPU 
    [ eval <<FIELD>>=round('<<FIELD>>', 2)]",0,5f7a016c668db25f33344d97
"GMC-064","Scheduled Jobs on the ITSI SHC cluster","ITSI,Health_Assessments","Scheduled_Jobs","ITSI Scheduled Alerts & Reports across the entire ITSI SHC cluster.
Reporting on all Jobs that are scheduled to run on the ITSI Search Head Cluster (SHC)","
| rest splunk_server=<Search Head Cluster Hosts> /servicesNS/-/-/saved/searches timeout=0 earliest_time=-24h@h latest_time=-0h@h search=""is_scheduled=1 AND disabled=0""
| eval savedsearch_type=if((NOT 'action'==""*"" AND NOT alert.track==""*"" AND NOT alert_condition==""*"" AND 'alert_type'==""always""),""report"",""alert"") 
| rename splunk_server As Splunk_Instance eai:acl.app As app title As savedsearch_name eai:acl.sharing As sharing 
| fields Splunk_Instance app author sharing savedsearch_name savedsearch_type description is_scheduled disabled search cron_schedule next_scheduled_time realtime_schedule schedule_priority schedule_window updated allow_skew 
| stats 
    Values(*) As *
    BY app savedsearch_name 
| eval updated = strptime(updated,""%Y-%m-%dT%H:%M:%S%z"") ,updated = strftime(updated, ""%A %B %d, %Y %I:%M:%S %p %Z"") , next_scheduled_time=strptime(next_scheduled_time,""%Y-%m-%d %H:%M:%S %Z""), next_scheduled_time = strftime(next_scheduled_time, ""%A %B %d, %Y %I:%M:%S %p %Z"") 
| table savedsearch_name updated disabled is_scheduled savedsearch_type app sharing author cron_schedule next_scheduled_time realtime_schedule schedule_priority schedule_window allow_skew description search",0,5f7a01cd668db25f33344d98
"GMC-065","ITSI Scheduled Jobs Cron Scheduler Pie Chart","ITSI,Health_Assessments","Scheduled_Jobs","Analyze the results of the search in Pie Chart visualizations and tune Job schedules to stagger appropriately.
Here is an example of staggering 5 minute interval jobs:
1-59/5 * * * *
2-59/5 * * * *
3-59/5 * * * *
4-59/5 * * * *

Rerun the search after you make the adjustments to see the new data and apply additional tunings as necessary.
For 1 minute interval jobs, reconfigure to run every 5minutes instead and stagger using the same process above.","| rest splunk_server=<Search Head Cluster Hosts> /servicesNS/-/-/saved/searches timeout=0 earliest_time=-24h@h latest_time=-0h@h search=""is_scheduled=1 AND disabled=0""
| rename splunk_server As Splunk_Instance eai:acl.app As app title As savedsearch_name eai:acl.sharing As sharing 
| stats 
    Values(cron_schedule) As cron_schedule
    BY app savedsearch_name 
| stats count by cron_schedule",0,5f7a0218668db25f33344d99
"GMC-066","Run Time Across All ITSI Jobs Across the entire ITSI Cluster","ITSI,Health_Assessments","Scheduled_Jobs","Review overall Run Time across all jobs to check if we have any unusual spikes in run times in the last 24 hours:","host=<Search Head Cluster Hosts> index=_internal sourcetype=scheduler status=completed earliest=-24h@h
| fields _time host app run_time savedsearch_name
| timechart Max(run_time) As MaxRunTime Avg(run_time) As AvgRunTime span=1h
| foreach MaxRunTime AvgRunTime [ eval <<FIELD>>=round('<<FIELD>>', 2)]",0,5f7a02a3668db25f33344d9a
"GMC-067","Run Time Across All ITSI Jobs Across the entire ITSI Cluster by App & Job Name","ITSI,Health_Assessments","Scheduled_Jobs","Check if we have any unusual long running jobs and then zoom in on a particular job to make sure the behavior in the last 24 hours:","host=<Search Head Cluster Hosts> index=_internal sourcetype=scheduler status=completed earliest=-24h@h
| fields _time host app run_time savedsearch_name
| stats Max(run_time) As MaxRunTime Avg(run_time) As AvgRunTime by app savedsearch_name
| foreach MaxRunTime AvgRunTime [ eval <<FIELD>>=round('<<FIELD>>', 2)]
| sort 0 - MaxRunTime",0,5f7a02e7668db25f33344d9b
"GMC-068","Run Time Across All ITSI Jobs Across the entire ITSI Cluster(Specific Job Name)","ITSI,Health_Assessments","Scheduled_Jobs","Select the Job with the highest MaxRunTime and review its run time overtime in the last 24 hours:","host=<Search Head Cluster Hosts> savedsearch_name=""Indicator - Shared - 5d772a556e65145ad9069c94 - ITSI Search"" index=_internal sourcetype=scheduler status=completed earliest=-24h@h latest=-0h@h
| fields _time host app run_time savedsearch_name 
| timechart Max(run_time) As MaxRunTime Avg(run_time) As AvgRunTime span=1h
| foreach MaxRunTime AvgRunTime [ eval <<FIELD>>=round('<<FIELD>>', 2)]",0,5f7a0309668db25f33344d9c
"GMC-069","Report on all Bundle enforcer blacklist by host & app","SearchBundle,Health_Assessments","Configuration_Files","","index=gmc_summary sourcetype=""splunk:config:btool:distsearch"" 
| rex ""etc/((apps|master-apps|slave-apps)/)?[^/]+/(default|local)/(?<file>\w+\.conf)\s+\[(?<stanza>.+?)\]"" 
| multikv noheader=t 
| rex ""(?<SPLUNK_HOME>.*?)/etc/(?<app_folder>apps|master-apps|system|slave-apps)/((?<app>.*)/)?(?<directory>default|local)/(?<file>\w+\.conf)"" 
| search stanza=bundleEnforcerBlacklist app_folder!=system Column_2=""*/*"" 
| stats count by host app stanza Column_2 
| rex field=Column_2 ""(?<name>.*)\s*=\s*(?<blacklist_pattern>.*)"" 
| table host app name blacklist_pattern",0,5f7a7977668db25f33344d9d
"GMC-070","Report on indexes and sourcetypes with no data coming in","Forwarding,Health_Assessments",SPL,"Find Indexes and sourcetypes that hasn't been receiving data from the forwarding tier","| tstats latest(_time) as Latest by host sourcetype index 
| eval current=now() 
| eval Minimum_Age=round(((current-Latest)/60)/60,2) 
| rangemap field=Minimum_Age default=Critical Normal=0-0.5 Elevated=0.5-2 Warning=2-4 
| eval stIDX=tostring(index) + "" -- "" + tostring(sourcetype) 
| stats values(stIDX) as ""Index -- Sourcetype"" list(Latest) as ""Latest Event"" list(Minimum_Age) as Minimum_Age list(range) as Threshold by host 
| convert ctime(""Latest Event"") 
| eventstats avg(Minimum_Age) as average by host 
| eval average=round(average,2) 
| sort - average 
| rename Minimum_Age as ""Hours Since Last Communication"" average as ""Average Time in Hours Since Last Communication""",0,5f7b249f668db25f33344d9e
"GMC-071","Splunk .conf configuration syntax errors","Config_Files,Health_Assessments","Configuration_Files",".conf file syntax errors within the environment.  Recommended to review and correct syntax errors identified to ensure system is functioning as expected.","index=_internal sourcetype=splunkd CASE(WARN) TERM(IniFile) 
| rex ""IniFile - (?<file>[^,]+),(?<msg>.*$)"" 
| stats count dc(host) As Num_Hosts last(host) As Last_Host values(msg) As Error_Message by file",0,5f7bd876668db20d5e1730b1
"GMC-072","Indexer connectivity issues","Connectivity,Health_Assessments","Indexer_Cluster","cannot establish connection to given indexer.  As a result, this indexer has considerably less data compared to its peers, this misconfiguration results in performance issues.
Recommended to review routing/firewall configuration to ensure on-prem forwarders are able to connect to said indexer.","index=_internal sourcetype=splunkd component=TcpOutputProc TERM(WARN) ip=* connection timed out 
| rename ip As Indexer 
| stats Values(event_message) As event_message Values(host) As Hosts dc(host) As Num_Hosts Latest(_time) As _time by Indexer",0,5f7bda07668db20d5e1730b2
"GMC-073","Analyze Scheduler using the Metrics component in _internal","ITSI,Health_Assessments,Skips",Scheduler,"Set the shcluster_label to the either the Search head Cluster or a standalone Search Head.
Then proceed and select a few metrics to report on from the list of fields.","index=_internal sourcetype=splunkd component=Metrics group=searchscheduler search_group=dmc_group_search_head earliest=-4h@h latest=-0h@h 
| `get_shcluster_label(host)` 
| search host=""*"" AND shcluster_label=""shcluster1"" 
| fields _time actions_triggered completed delayed delegated delegated_scheduled delegated_waiting dispatched eligible max_lag max_running max_runtime shc_max_hist_searches shc_max_rt_searches shc_max_sched_auto_summary shc_max_sched_hist_searches shc_max_sched_rt_searches skipped total_lag total_runtime window_max_lag window_total_lag 
| fields _time shc_* skipped 
| timechart Span=5m
    Max(*) As * 
| foreach * 
    [ eval <<FIELD>>=Round('<<FIELD>>', 2)]",0,5f7c886f668db20d5e1730b3
"GMC-075","Index Buckets Statistics","Buckets,Index,Health_Assessments","Indexer_Cluster","Report on the following:
1. Unusually high number of Buckets.
2. Indexes with Excess Bucket Copies
3. Indexes with Excess Searchable Copies","| rest /services/cluster/master/indexes `gmc_setup_cluster_master_rest` 
| stats last(splunk_server) as host max(index_size) as index_size max(num_buckets) as num_buckets max(total_excess_bucket_copies) as total_excess_bucket_copies max(total_excess_searchable_copies) as total_excess_searchable_copies by title 
| rename title as index_name 
| eval _time=now() 
| fields _time host index_name index_size num_buckets total_excess_bucket_copies total_excess_searchable_copies",0,5f7cb9cc668db20d5e1730b4
"GMC-076","Analyze Search Bundle Size and Replication Elapsed Time","Bundle,Health_Assessments","Search_Head_Cluster","Report unusual bundle size and elapsed times.","index=_internal sourcetype=splunkd component=DistributedBundleReplicationManager bundle_replication_mode=baseline earliest=-24h@h latest=now 
| `get_shcluster_label(host)` 
| fields _time shcluster_label bundle_file_name bundle_size elapsed_ms replication_id 
| eval bundle_size_org=bundle_size 
| rex field=bundle_size mode=sed ""s/KB|MB//g"" 
| eval bundle_size_MB=case(match(bundle_size_org, ""KB""), round(bundle_size/1024), match(bundle_size_org, ""MB""), round(bundle_size)) 
| eval elapsed_s=round(elapsed_ms/1000,2) 
| stats latest(*) as * latest(_time) As _time by shcluster_label replication_id 
| sort 0 - _time 
| table _time shcluster_label replication_id bundle_file_name bundle_size_MB elapsed_s 
| timechart Max(elapsed_s) As elapsed_s Max(bundle_size_MB) As bundle_size_MB by shcluster_label",0,5f7ccac1668db20d5e1730b5
"GMC-077","ITSI Rules Engine Real-Time Job Impact on the platform",ITSI,"Scheduled_Jobs","","index=_introspection sourcetype=splunk_resource_usage component=PerProcess data.search_props.label=itsi_event_grouping 
| rename data.* as * , search_props.* as * 
| fields _time host mem_used normalized_pct_cpu t_count read_mb written_mb fd_used elapsed page_faults pct_cpu pct_memory app delta_scan_count label mode pid ppid process process_type provenance role scan_count sid status type user 
| fields _time host mem_used normalized_pct_cpu fd_used t_count page_faults read_mb written_mb scan_count pid 
| timechart span=5m
    Max(mem_used) as mem_used 
    Max(normalized_pct_cpu) as normalized_pct_cpu
    Max(fd_used) as fd_used
    Max(t_count) as t_count
    Max(page_faults) as page_faults
    Max(read_mb) as read_mb
    Max(written_mb) as written_mb
    Max(scan_count) as scan_count",0,5f810a6c668db20d5e1730b6
"GMC-078","Report on Job Disk Quota Size and Time To Live Information","TTL,Health_Assessments","Scheduled_Jobs","For more info on Dispatch folder:
https://docs.splunk.com/Documentation/Splunk/latest/Search/Dispatchdirectoryandsearchartifacts","index=`gmc_setup_summary_index` search_name=splunk_rest_search_jobs_sh_summary_tracker provenance=scheduler Search_State != Running label!=_ACCELERATE_* NOT app IN (splunk_archiver,*global_monitoring_console) 
| table shcluster_label search_id_normalized Search_State searchEarliestTime searchLatestTime pid app label ttl owner priority provenance delegate diskUsage doneProgress eventAvailableCount eventCount isEventsPreviewEnabled isPreviewEnabled isRemoteTimeline meanPreviewPeriod numPreviews resultCount resultIsStreaming resultPreviewCount runDuration sampleRatio sampleSeed scanCount searchCanBeEventType runtime_auto_cancel runtime_auto_pause error_messages 
| stats Max(diskUsage) As diskUsage latest(*) as * by shcluster_label label app owner ttl Search_State 
| eval diskUsageGB=round(diskUsage/1024/1024/1024,2) , ttl_hours=round(ttl/60/60,0), ttl_days=round(ttl/60/60/24,0) 
| `get_saved_searches_info(shcluster_label,app,label)` 
| `get_identity_info(owner)` 
| `cron_descriptor(cron_schedule)` 
| fields shcluster_label owner emp_name emp_last emp_email app label description actions dispatch_earliest_time dispatch_latest_time cron_schedule dispatch_ttl ttl ttl_hours ttl_days diskUsage diskUsageGB Search_State cron_schedule_described 
| makemv delim="","" actions 
| join actions type=left 
    [ search index=`gmc_setup_summary_index` search_name=splunk_rest_alert_actions_summary_data 
    | fields shcluster_label Splunk_Instance app disabled title label description sharing ttl updated priority 
    | rename title as actions, ttl As action_ttl description As action_description ] 
| rename ttl As final_ttl 
| sort 0 - diskUsage 
| table shcluster_label owner emp_name emp_last emp_email app label Search_State diskUsage diskUsageGB actions action_description dispatch_earliest_time dispatch_latest_time cron_schedule cron_schedule_described dispatch_ttl action_ttl final_ttl ttl_hours ttl_days description",0,5f84d10c668db246fa775a85
